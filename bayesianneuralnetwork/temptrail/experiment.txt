loss is
Optimizing variational parameters...
Iteration 0 lower bound 21491.1685777
Iteration 1 lower bound 11160.4690332
Iteration 2 lower bound 5228.56721036
Iteration 3 lower bound 2459.42543292
Iteration 4 lower bound 1405.33151751
Iteration 5 lower bound 1097.33700889
Iteration 6 lower bound 1094.59487908
Iteration 7 lower bound 1174.64658825
Iteration 8 lower bound 1233.31140405
Iteration 9 lower bound 1219.7609222
Iteration 10 lower bound 1151.02826488
Iteration 11 lower bound 1049.60509756
Iteration 12 lower bound 963.852363511
Iteration 13 lower bound 911.775155253
Iteration 14 lower bound 887.802944464
Iteration 15 lower bound 872.604086113
Iteration 16 lower bound 842.320490689
Iteration 17 lower bound 805.58686956
Iteration 18 lower bound 739.277432412
Iteration 19 lower bound 679.126341056
Iteration 20 lower bound 623.951352912
Iteration 21 lower bound 607.311744917
Iteration 22 lower bound 601.710381221
Iteration 23 lower bound 597.715355173
Iteration 24 lower bound 564.103471667
Iteration 25 lower bound 512.165540894
Iteration 26 lower bound 486.386700993
Iteration 27 lower bound 466.511603283
Iteration 28 lower bound 477.875536921
Iteration 29 lower bound 447.926984656
Iteration 30 lower bound 428.063181237
Iteration 31 lower bound 397.881992708
Iteration 32 lower bound 376.569689213
Iteration 33 lower bound 378.404319272
Iteration 34 lower bound 375.391496204
Iteration 35 lower bound 372.677028911
Iteration 36 lower bound 346.026874188
Iteration 37 lower bound 324.589154973
Iteration 38 lower bound 295.16196408
Iteration 39 lower bound 287.594780304
Iteration 40 lower bound 308.354603623
Iteration 41 lower bound 275.20005046
Iteration 42 lower bound 275.536240803
Iteration 43 lower bound 238.324522154
Iteration 44 lower bound 241.654171463
Iteration 45 lower bound 233.688157446
Iteration 46 lower bound 222.572442408
Iteration 47 lower bound 219.080344605
Iteration 48 lower bound 187.73140392
Iteration 49 lower bound 182.670322525
Iteration 50 lower bound 176.820553469
Iteration 51 lower bound 171.774655478
Iteration 52 lower bound 166.344305865
Iteration 53 lower bound 132.788347961
Iteration 54 lower bound 145.468214806
Iteration 55 lower bound 125.953953053
Iteration 56 lower bound 105.119366702
Iteration 57 lower bound 117.19763984
Iteration 58 lower bound 94.5198807
Iteration 59 lower bound 106.273843604
Iteration 60 lower bound 124.071954061
Iteration 61 lower bound 66.2576501806
Iteration 62 lower bound 89.5702916553
Iteration 63 lower bound 89.8996104033
Iteration 64 lower bound 87.59775081
Iteration 65 lower bound 70.4539076598
Iteration 66 lower bound 65.6706730053
Iteration 67 lower bound 66.0970005262
Iteration 68 lower bound 70.9024802925
Iteration 69 lower bound 76.1534711813
Iteration 70 lower bound 66.5984099443
Iteration 71 lower bound 59.4855039791
Iteration 72 lower bound 43.8252877996
Iteration 73 lower bound 42.0351826644
Iteration 74 lower bound 42.7960069797
Iteration 75 lower bound 41.1207320353
Iteration 76 lower bound 33.068637326
Iteration 77 lower bound 32.9164503294
Iteration 78 lower bound 40.8058819011
Iteration 79 lower bound 42.7974325979
Iteration 80 lower bound 39.7049173279
Iteration 81 lower bound 35.838143782
Iteration 82 lower bound 29.9202719453
Iteration 83 lower bound 19.184103458
Iteration 84 lower bound 11.944031611
Iteration 85 lower bound 24.1257039662
Iteration 86 lower bound 21.6081801696
Iteration 87 lower bound 18.3459631966
Iteration 88 lower bound 30.141293524
Iteration 89 lower bound 0.236434945181
Iteration 90 lower bound 6.53686371384
Iteration 91 lower bound -4.13122928508
Iteration 92 lower bound 0.637927502159
Iteration 93 lower bound 0.670671967961
Iteration 94 lower bound 15.0297485336
Iteration 95 lower bound 1.94350063568
Iteration 96 lower bound 5.57891894105
Iteration 97 lower bound 11.1450247362
Iteration 98 lower bound -18.9101673353
Iteration 99 lower bound 5.80037378661
Iteration 100 lower bound -5.15857109527
Iteration 101 lower bound 2.52994392187
Iteration 102 lower bound -2.21105774916
Iteration 103 lower bound -9.17220139714
Iteration 104 lower bound -12.0951457957
Iteration 105 lower bound 1.46487861127
Iteration 106 lower bound 12.1848533908
Iteration 107 lower bound 0.672040694807
Iteration 108 lower bound -3.27451917875
Iteration 109 lower bound 3.32745895361
Iteration 110 lower bound 9.18181522616
Iteration 111 lower bound -15.7885734048
Iteration 112 lower bound -22.5107410093
Iteration 113 lower bound -27.9575916986
Iteration 114 lower bound -28.0281882646
Iteration 115 lower bound -34.7240031542
Iteration 116 lower bound -11.5301533797
Iteration 117 lower bound -16.057942387
Iteration 118 lower bound -22.2779943317
Iteration 119 lower bound -33.6908332837
Iteration 120 lower bound -33.8340840423
Iteration 121 lower bound -32.670476018
Iteration 122 lower bound -18.3147926321
Iteration 123 lower bound -33.3074774923
Iteration 124 lower bound -9.34333763858
Iteration 125 lower bound -33.3673949945
Iteration 126 lower bound -41.7525292193
Iteration 127 lower bound -41.6746193684
Iteration 128 lower bound -36.8556837828
Iteration 129 lower bound -31.4706993979
Iteration 130 lower bound -41.8704349107
Iteration 131 lower bound -50.3755950014
Iteration 132 lower bound -41.7037056399
Iteration 133 lower bound -43.9660192837
Iteration 134 lower bound -47.3795353535
Iteration 135 lower bound -44.4893709425
Iteration 136 lower bound -40.1327001793
Iteration 137 lower bound -45.2150375362
Iteration 138 lower bound -51.043661637
Iteration 139 lower bound -45.0005038409
Iteration 140 lower bound -48.9802408835
Iteration 141 lower bound -45.1604183855
Iteration 142 lower bound -52.1197494967
Iteration 143 lower bound -48.308365473
Iteration 144 lower bound -48.4673179593
Iteration 145 lower bound -48.3172215711
Iteration 146 lower bound -54.337440153
Iteration 147 lower bound -55.9806626672
Iteration 148 lower bound -54.8939794023
Iteration 149 lower bound -53.1283437024
Iteration 150 lower bound -36.76552838
Iteration 151 lower bound -62.9640598018
Iteration 152 lower bound -51.2251061412
Iteration 153 lower bound -52.059863633
Iteration 154 lower bound -49.1268118206
Iteration 155 lower bound -57.4516882714
Iteration 156 lower bound -46.5222487028
Iteration 157 lower bound -55.9481095433
Iteration 158 lower bound -61.3444947255
Iteration 159 lower bound -61.3223869839
Iteration 160 lower bound -57.9095354838
Iteration 161 lower bound -60.2864085815
Iteration 162 lower bound -39.3227436103
Iteration 163 lower bound -59.4734762866
Iteration 164 lower bound -53.0859338874
Iteration 165 lower bound -50.2014863814
Iteration 166 lower bound -56.6578528433
Iteration 167 lower bound -63.5970053096
Iteration 168 lower bound -71.8512334993
Iteration 169 lower bound -68.7198581731
Iteration 170 lower bound -55.5408874134
Iteration 171 lower bound -79.1518909295
Iteration 172 lower bound -56.5004199506
Iteration 173 lower bound -59.9126711737
Iteration 174 lower bound -59.3788278352
Iteration 175 lower bound -77.4609636699
Iteration 176 lower bound -71.8347877401
Iteration 177 lower bound -77.4407107135
loss is
Optimizing variational parameters...
Iteration 0 lower bound 21491.1685777
Iteration 1 lower bound 11160.4690332
Iteration 2 lower bound 5228.56721036
Iteration 3 lower bound 2459.42543292
Iteration 4 lower bound 1405.33151751
Iteration 5 lower bound 1097.33700889
Iteration 6 lower bound 1094.59487908
Iteration 7 lower bound 1174.64658825
Iteration 8 lower bound 1233.31140405
Iteration 9 lower bound 1219.7609222
Iteration 10 lower bound 1151.02826488
Iteration 11 lower bound 1049.60509756
Iteration 12 lower bound 963.852363511
Iteration 13 lower bound 911.775155253
Iteration 14 lower bound 887.802944464
Iteration 15 lower bound 872.604086113
Iteration 16 lower bound 842.320490689
Iteration 17 lower bound 805.58686956
Iteration 18 lower bound 739.277432412
Iteration 19 lower bound 679.126341056
Iteration 20 lower bound 623.951352912
Iteration 21 lower bound 607.311744917
Iteration 22 lower bound 601.710381221
Iteration 23 lower bound 597.715355173
Iteration 24 lower bound 564.103471667
Iteration 25 lower bound 512.165540894
Iteration 26 lower bound 486.386700993
Iteration 27 lower bound 466.511603283
Iteration 28 lower bound 477.875536921
Iteration 29 lower bound 447.926984656
Iteration 30 lower bound 428.063181237
Iteration 31 lower bound 397.881992708
Iteration 32 lower bound 376.569689213
Iteration 33 lower bound 378.404319272
Iteration 34 lower bound 375.391496204
Iteration 35 lower bound 372.677028911
Iteration 36 lower bound 346.026874188
Iteration 37 lower bound 324.589154973
Iteration 38 lower bound 295.16196408
Iteration 39 lower bound 287.594780304
Iteration 40 lower bound 308.354603623
Iteration 41 lower bound 275.20005046
Iteration 42 lower bound 275.536240803
Iteration 43 lower bound 238.324522154
Iteration 44 lower bound 241.654171463
Iteration 45 lower bound 233.688157446
Iteration 46 lower bound 222.572442408
Iteration 47 lower bound 219.080344605
Iteration 48 lower bound 187.73140392
Iteration 49 lower bound 182.670322525
Iteration 50 lower bound 176.820553469
Iteration 51 lower bound 171.774655478
Iteration 52 lower bound 166.344305865
Iteration 53 lower bound 132.788347961
Iteration 54 lower bound 145.468214806
Iteration 55 lower bound 125.953953053
Iteration 56 lower bound 105.119366702
Iteration 57 lower bound 117.19763984
Iteration 58 lower bound 94.5198807
Iteration 59 lower bound 106.273843604
Iteration 60 lower bound 124.071954061
Iteration 61 lower bound 66.2576501806
Iteration 62 lower bound 89.5702916553
Iteration 63 lower bound 89.8996104033
Iteration 64 lower bound 87.59775081
Iteration 65 lower bound 70.4539076598
Iteration 66 lower bound 65.6706730053
Iteration 67 lower bound 66.0970005262
Iteration 68 lower bound 70.9024802925
Iteration 69 lower bound 76.1534711813
Iteration 70 lower bound 66.5984099443
Iteration 71 lower bound 59.4855039791
Iteration 72 lower bound 43.8252877996
Iteration 73 lower bound 42.0351826644
Iteration 74 lower bound 42.7960069797
Iteration 75 lower bound 41.1207320353
Iteration 76 lower bound 33.068637326
Iteration 77 lower bound 32.9164503294
Iteration 78 lower bound 40.8058819011
Iteration 79 lower bound 42.7974325979
Iteration 80 lower bound 39.7049173279
Iteration 81 lower bound 35.838143782
Iteration 82 lower bound 29.9202719453
Iteration 83 lower bound 19.184103458
Iteration 84 lower bound 11.944031611
Iteration 85 lower bound 24.1257039662
Iteration 86 lower bound 21.6081801696
Iteration 87 lower bound 18.3459631966
Iteration 88 lower bound 30.141293524
Iteration 89 lower bound 0.236434945181
Iteration 90 lower bound 6.53686371384
Iteration 91 lower bound -4.13122928508
Iteration 92 lower bound 0.637927502159
Iteration 93 lower bound 0.670671967961
Iteration 94 lower bound 15.0297485336
Iteration 95 lower bound 1.94350063568
Iteration 96 lower bound 5.57891894105
Iteration 97 lower bound 11.1450247362
Iteration 98 lower bound -18.9101673353
Iteration 99 lower bound 5.80037378661
Iteration 100 lower bound -5.15857109527
Iteration 101 lower bound 2.52994392187
Iteration 102 lower bound -2.21105774916
Iteration 103 lower bound -9.17220139714
Iterationloss is
Optimizing variational parameters...
Iteration 0 lower bound 21491.1685777
Iteration 1 lower bound 11160.4690332
Iteration 2 lower bound 5228.56721036
Iteration 3 lower bound 2459.42543292
Iteration 4 lower bound 1405.33151751
Iteration 5 lower bound 1097.33700889
Iteration 6 lower bound 1094.59487908
Iteration 7 lower bound 1174.64658825
Iteration 8 lower bound 1233.31140405
Iteration 9 lower bound 1219.7609222
Iteration 10 lower bound 1151.02826488
Iteration 11 lower bound 1049.60509756
Iteration 12 lower bound 963.852363511
Iteration 13 lower bound 911.775155253
Iteration 14 lower bound 887.802944464
Iteration 15 lower bound 872.604086113
Iteration 16 lower bound 842.320490689
Iteration 17 lower bound 805.58686956
Iteration 18 lower bound 739.277432412
Iteration 19 lower bound 679.126341056
Iteration 20 lower bound 623.951352912
Iteration 21 lower bound 607.311744917
Iteration 22 lower bound 601.710381221
Iteration 23 lower bound 597.715355173
Iteration 24 lower bound 564.103471667
Iteration 25 lower bound 512.165540894
Iteration 26 lower bound 486.386700993
Iteration 27 lower bound 466.511603283
Iteration 28 lower bound 477.875536921
Iteration 29 lower bound 447.926984656
Iteration 30 lower bound 428.063181237
Iteration 31 lower bound 397.881992708
Iteration 32 lower bound 376.569689213
Iteration 33 lower bound 378.404319272
Iteration 34 lower bound 375.391496204
Iteration 35 lower bound 372.677028911
Iteration 36 lower bound 346.026874188
Iteration 37 lower bound 324.589154973
Iteration 38 lower bound 295.16196408
Iteration 39 lower bound 287.594780304
Iteration 40 lower bound 308.354603623
Iteration 41 lower bound 275.20005046
Iteration 42 lower bound 275.536240803
Iteration 43 lower bound 238.324522154
Iteration 44 lower bound 241.654171463
Iteration 45 lower bound 233.688157446
Iteration 46 lower bound 222.572442408
Iteration 47 lower bound 219.080344605
Iteration 48 lower bound 187.73140392
Iteration 49 lower bound 182.670322525
Iteration 50 lower bound 176.820553469
Iteration 51 lower bound 171.774655478
Iteration 52 lower bound 166.344305865
Iteration 53 lower bound 132.788347961
Iteration 54 lower bound 145.468214806
Iteration 55 lower bound 125.953953053
Iteration 56 lower bound 105.119366702
Iteration 57 lower bound 117.19763984
Iteration 58 lower bound 94.5198807
Iteration 59 lower bound 106.273843604
Iteration 60 lower bound 124.071954061
Iteration 61 lower bound 66.2576501806
Iteration 62 lower bound 89.5702916553
Iteration 63 lower bound 89.8996104033
Iteration 64 lower bound 87.59775081
Iteration 65 lower bound 70.4539076598
Iteration 66 lower bound 65.6706730053
Iteration 67 lower bound 66.0970005262
Iteration 68 lower bound 70.9024802925
Iteration 69 lower bound 76.1534711813
Iteration 70 lower bound 66.5984099443
Iteration 71 lower bound 59.4855039791
Iteration 72 lower bound 43.8252877996
Iteration 73 lower bound 42.0351826644
Iteration 74 lower bound 42.7960069797
Iteration 75 lower bound 41.1207320353
Iteration 76 lower bound 33.068637326
Iteration 77 lower bound 32.9164503294
Iteration 78 lower bound 40.8058819011
Iteration 79 lower bound 42.7974325979
Iteration 80 lower bound 39.7049173279
Iteration 81 lower bound 35.838143782
Iteration 82 lower bound 29.9202719453
Iteration 83 lower bound 19.184103458
Iteration 84 lower bound 11.944031611
Iteration 85 lower bound 24.1257039662
Iteration 86 lower bound 21.6081801696
Iteration 87 lower bound 18.3459631966
Iteration 88 lower bound 30.141293524
Iteration 89 lower bound 0.236434945181
Iteration 90 lower bound 6.53686371384
Iteration 91 lower bound -4.13122928508
Iteration 92 lower bound 0.637927502159
Iteration 93 lower bound 0.670671967961
Iteration 94 lower bound 15.0297485336
Iteration 95 lower bound 1.94350063568
Iteration 96 lower bound 5.57891894105
Iteration 97 lower bound 11.1450247362
Iteration 98 lower bound -18.9101673353
Iteration 99 lower bound 5.80037378661
Iteration 100 lower bound -5.15857109527
Iteration 101 lower bound 2.52994392187
Iteration 102 lower bound -2.21105774916
Iteration 103 lower bound -9.17220139714
Iteration 104 lower bound -12.0951457957
Iteration 105 lower bound 1.46487861127
Iteration 106 lower bound 12.1848533908
Iteration 107 lower bound 0.672040694807
Iteration 108 lower bound -3.27451917875
Iteration 109 lower bound 3.32745895361
Iteration 110 lower bound 9.18181522616
Iteration 111 lower bound -15.7885734048
Iteration 112 lower bound -22.5107410093
Iteration 113 lower bound -27.9575916986
Iteration 114 lower bound -28.0281882646
Iteration 115 lower bound -34.7240031542
Iteration 116 lower bound -11.5301533797
Iteration 117 lower bound -16.057942387
Iteration 118 lower bound -22.2779943317
Iteration 119 lower bound -33.6908332837
Iteration 120 lower bound -33.8340840423
Iteration 121 lower bound -32.670476018
Iteration 122 lower bound -18.3147926321
Iteration 123 lower bound -33.3074774923
Iteration 124 lower bound -9.34333763858
Iteration 125 lower bound -33.3673949945
Iteration 126 lower bound -41.7525292193
Iteration 127 lower bound -41.6746193684
Iteration 128 lower bound -36.8556837828
Iteration 129 lower bound -31.4706993979
Iteration 130 lower bound -41.8704349107
Iteration 131 lower bound -50.3755950014
Iteration 132 lower bound -41.7037056399
Iteration 133 lower bound -43.9660192837
Iteration 134 lower bound -47.3795353535
Iteration 135 lower bound -44.4893709425
Iteration 136 lower bound -40.1327001793
Iteration 137 lower bound -45.2150375362
Iteration 138 lower bound -51.043661637
Iteration 139 lower bound -45.0005038409
Iteration 140 lower bound -48.9802408835
Iteration 141 lower bound -45.1604183855
Iteration 142 lower bound -52.1197494967
Iteration 143 lower bound -48.308365473
Iteration 144 lower bound -48.4673179593
Iteration 145 lower bound -48.3172215711
Iteration 146 lower bound -54.337440153
Iteration 147 lower bound -55.9806626672
Iteration 148 lower bound -54.8939794023
Iteration 149 lower bound -53.1283437024
Iteration 150 lower bound -36.76552838
Iteration 151 lower bound -62.9640598018
Iteration 152 lower bound -51.2251061412
Iteration 153 lower bound -52.059863633
Iteration 154 lower bound -49.1268118206
Iteration 155 lower bound -57.4516882714
Iteration 156 lower bound -46.5222487028
Iteration 157 lower bound -55.9481095433
Iteration 158 lower bound -61.3444947255
Iteration 159 lower bound -61.3223869839
Iteration 160 lower bound -57.9095354838
Iteration 161 lower bound -60.2864085815
Iteration 162 lower bound -39.3227436103
Iteration 163 lower bound -59.4734762866
Iteration 164 lower bound -53.0859338874
Iteration 165 lower bound -50.2014863814
Iteration 166 lower bound -56.6578528433
Iteration 167 lower bound -63.5970053096
Iteration 168 lower bound -71.8512334993
Iteration 169 lower bound -68.7198581731
Iteration 170 lower bound -55.5408874134
Iteration 171 lower bound -79.1518909295
Iteration 172 lower bound -56.5004199506
Iteration 173 lower bound -59.9126711737
Iteration 174 lower bound -59.3788278352
Iteration 175 lower bound -77.4609636699
Iteration 176 lower bound -71.8347877401
Iteration 177 lower bound -77.4407107135
Iteration 178 lower bound -64.0461134716
Iteration 179 lower bound -83.4196909708
Iteration 180 lower bound -67.536096239
Iteration 181 lower bound -50.0439663497
Iteration 182 lower bound -64.3016457655
Iteration 183 lower bound -80.813427511
Iteration 184 lower bound -78.4690591741
Iteration 185 lower bound -55.9891439606
Iteration 186 lower bound -59.9901406516
Iteration 187 lower bound -68.9996832181
Iteration 188 lower bound -80.1284360547
Iteration 189 lower bound -69.1466862255
Iteration 190 lower bound -80.9897528972
Iteration 191 lower bound -77.8421839123
Iteration 192 lower bound -74.7575908988
Iteration 193 lower bound -85.7167394407
Iteration 194 lower bound -80.3418143298
Iteration 195 lower bound -65.8035067233
Iteration 196 lower bound -84.4786015852
Iteration 197 lower bound -86.1693558801
Iteration 198 lower bound -98.5675332008
Iteration 199 lower bound -76.0340063064
Iteration 200 lower bound -79.4543215307
Iteration 201 lower bound -93.6953055748
Iteration 202 lower bound -83.7406677305
Iteration 203 lower bound -82.5545779319
Iteration 204 lower 104 lower bound -12.0951457957
Iteration 105 lower bound 1.46487861127
Iteration 106 lower bound 12.1848533908
Iteration 107 lower bound 0.672040694807
Iteration 108 lower bound -3.27451917875
Iteration 109 lower bound 3.32745895361
Iteration 110 lower bound 9.18181522616
Iteration 111 lower bound -15.7885734048
Iteration 112 lower bound -22.5107410093
Iteration 113 lower bound -27.9575916986
Iteration 114 lower bound -28.0281882646
Iteration 115 lower bound -34.7240031542
Iteration 116 lower bound -11.5301533797
Iteration 117 lower bound -16.057942387
Iteration 118 lower bound -22.2779943317
Iteration 119 lower bound -33.6908332837
Iteration 120 lower bound -33.8340840423
Iteration 121 lower bound -32.670476018
Iteration 122 lower bound -18.3147926321
Iteration 123 lower bound -33.3074774923
Iteration 124 lower bound -9.34333763858
Iteration 125 lower bound -33.3673949945
Iteration 126 lower bound -41.7525292193
Iteration 127 lower bound -41.6746193684
Iteration 128 lower bound -36.8556837828
Iteration 129 lower bound -31.4706993979
Iteration 130 lower bound -41.8704349107
Iteration 131 lower bound -50.3755950014
Iteration 132 lower bound -41.7037056399
Iteration 133 lower bound -43.9660192837
Iteration 134 lower bound -47.3795353535
Iteration 135 lower bound -44.4893709425
Iteration 136 lower bound -40.1327001793
Iteration 137 lower bound -45.2150375362
Iteration 138 lower bound -51.043661637
Iteration 139 lower bound -45.0005038409
Iteration 140 lower bound -48.9802408835
Iteration 141 lower bound -45.1604183855
Iteration 142 lower bound -52.1197494967
Iteration 143 lower bound -48.308365473
Iteration 144 lower bound -48.4673179593
Iteration 145 lower bound -48.3172215711
Iteration 146 lower bound -54.337440153
Iteration 147 lower bound -55.9806626672
Iteration 148 lower bound -54.8939794023
Iteration 149 lower bound -53.1283437024
Iteration 150 lower bound -36.76552838
Iteration 151 lower bound -62.9640598018
Iteration 152 lower bound -51.2251061412
Iteration 153 lower bound -52.059863633
Iteration 154 lower bound -49.1268118206
Iteration 155 lower bound -57.4516882714
Iteration 156 lower bound -46.5222487028
Iteration 157 lower bound -55.9481095433
Iteration 158 lower bound -61.3444947255
Iteration 159 lower bound -61.3223869839
Iteration 160 lower bound -57.9095354838
Iteration 161 lower bound -60.2864085815
Iteration 162 lower bound -39.3227436103
Iteration 163 lower bound -59.4734762866
Iteration 164 lower bound -53.0859338874
Iteration 165 lower bound -50.2014863814
Iteration 166 lower bound -56.6578528433
Iteration 167 lower bound -63.5970053096
Iteration 168 lower bound -71.8512334993
Iteration 169 lower bound -68.7198581731
Iteration 170 lower bound -55.5408874134
Iteration 171 lower bound -79.1518909295
Iteration 172 lower bound -56.5004199506
Iteration 173 lower bound -59.9126711737
Iteration 174 lower bound -59.3788278352
Iteration 175 lower bound -77.4609636699
Iteration 176 lower bound -71.8347877401
Iteration 177 lower bound -77.4407107135
Iteration 178 lower bound -64.0461134716
Iteration 179 lower bound -83.4196909708
Iteration 180 lower bound -67.536096239
Iteration 181 lower bound -50.0439663497
Iteration 182 lower bound -64.3016457655
Iteration 183 lower bound -80.813427511
Iteration 184 lower bound -78.4690591741
Iteration 185 lower bound -55.9891439606
Iteration 186 lower bound -59.9901406516
Iteration 187 lower bound -68.9996832181
Iteration 188 lower bound -80.1284360547
Iteration 189 lower bound -69.1466862255
Iteration 190 lower bound -80.9897528972
Iteration 191 lower bound -77.8421839123
Iteration 192 lower bound -74.7575908988
Iteration 193 lower bound -85.7167394407
Iteration 194 lower bound -80.3418143298
Iteration 195 lower bound -65.8035067233
Iteration 196 lower bound -84.4786015852
Iteration 197 lower bound -86.1693558801
Iteration 198 lower bound -98.5675332008
Iteration 199 lower bound -76.0340063064
Iteration 200 lower bound -79.4543215307
Iteration 201 lower bound -93.6953055748
Iteration 202 lower bound -83.7406677305
Iteration 203 lower bound -82.5545779319
Iteration 204 lower bound -90.2425619888
Iteration 205 lower bound -90.5118059012
Iteration 206 lower bound -72.4943921128
Iteration 207 lower bound -90.3230140265
Iteration 208 lower bound -86.6867847426
Iteration 209 lower bound -96.5609361041
Iteration 210 lower bound -96.5238007042
Iteration 211 lower bound -82.5926629111
Iteration 212 lower bound -79.4411357734
Iteration 213 lower bound -93.9824893414
Iteration 214 lower bound -78.3944668849
Iteration 215 lower bound -75.6138421679
Iteration 216 lower bound -96.9683940587
Iteration 217 lower bound -72.8694723179
Iteration 218 lower bound -87.7798760487
Iteration 219 lower bound -77.8887362416
Iteration 220 lower bound -82.2181682274
Iteration 221 lower bound -87.6259053317
Iteration 222 lower bound -99.2274183136
Iteration 223 lower bound -67.6542483656
Iteration 224 lower bound -77.2302445889
Iteration 225 lower bound -98.7760960182
Iteration 226 lower bound -83.9661930864
Iteration 227 lower bound -49.8818667418
Iteration 228 lower bound -84.8308085443
Iteration 229 lower bound -95.1757131394
Iteration 230 lower bound -103.437224909
Iteration 231 lower bound -94.9104590374
Iteration 232 lower bound -98.1132221815
Iteration 233 lower bound -97.3101311659
Iteration 234 lower bound -83.0636359915
Iteration 235 lower bound -103.629550217
Iteration 236 lower bound -103.424186338
Iteration 237 lower bound -104.585368949
Iteration 238 lower bound -111.286558277
Iteration 239 lower bound -105.178735578
Iteration 240 lower bound -107.463822435
Iteration 241 lower bound -107.07520884
Iteration 242 lower bound -102.259862843
Iteration 243 lower bound -99.4267986358
Iteration 244 lower bound -87.236788028
Iteration 245 lower bound -84.7583880209
Iteration 246 lower bound -106.411947376
Iteration 247 lower bound -104.739020951
Iteration 248 lower bound -102.16889283
Iteration 249 lower bound -103.713552753
Iteration 250 lower bound -94.8292855691
Iteration 251 lower bound -98.4780865482
Iteration 252 lower bound -103.03074129
Iteration 253 lower bound -107.950192695
Iteration 254 lower bound -105.642329526
Iteration 255 lower bound -112.322704467
Iteration 256 lower bound -109.831778761
Iteration 257 lower bound -110.891252575
Iteration 258 lower bound -117.388890054
Iteration 259 lower bound -116.079228871
Iteration 260 lower bound -111.575955714
Iteration 261 lower bound -108.911533893
Iteration 262 lower bound -105.625350412
Iteration 263 lower bound -113.003808359
Iteration 264 lower bound -97.4653074244
Iteration 265 lower bound -114.254178485
Iteration 266 lower bound -100.49184986
Iteration 267 lower bound -117.388573855
Iteration 268 lower bound -108.508819961
Iteration 269 lower bound -104.655566266
Iteration 270 lower bound -109.358532035
Iteration 271 lower bound -108.125611161
Iteration 272 lower bound -111.978902741
Iteration 273 lower bound -115.293445548
Iteration 274 lower bound -117.0222931
Iteration 275 lower bound -118.567448452
Iteration 276 lower bound -116.00054436
Iteration 277 lower bound -127.971931432
Iteration 278 lower bound -116.538237482
Iteration 279 lower bound -111.410206096
Iteration 280 lower bound -107.080001329
Iteration 281 lower bound -119.471123505
Iteration 282 lower bound -120.85003459
Iteration 283 lower bound -115.528041523
Iteration 284 lower bound -121.79245527
Iteration 285 lower bound -125.372299647
Iteration 286 lower bound -124.231840574
Iteration 287 lower bound -115.569981505
Iteration 288 lower bound -107.269809348
Iteration 289 lower bound -117.261796883
Iteration 290 lower bound -101.923370999
Iteration 291 lower bound -124.331564299
Iteration 292 lower bound -118.983360227
Iteration 293 lower bound -83.9837552393
Iteration 294 lower bound -117.058192984
Iteration 295 lower bound -130.366179463
Iteration 296 lower bound -128.457271972
Iteration 297 lower bound -124.391353196
Iteration 298 lower bound -127.345980341
Iteration 299 lower bound -130.49396151
Iteration 300 lower bound -129.007748675
Iteration 301 lower bound -125.779576165
Iteration 302 lower bound -132.71118735
Iteration 303 lower bound -136.511963333
 bound -90.2425619888
Iteration 205 lower bound -90.5118059012
Iteration 206 lower bound -72.4943921128
Iteration 207 lower bound -90.3230140265
Iteration 208 lower bound -86.6867847426
Iteration 209 lower bound -96.5609361041
Iteration 210 lower bound -96.5238007042
Iteration 211 lower bound -82.5926629111
Iteration 212 lower bound -79.4411357734
Iteration 213 lower bound -93.9824893414
Iteration 214 lower bound -78.3944668849
Iteration 215 lower bound -75.6138421679
Iteration 216 lower bound -96.9683940587
Iteration 217 lower bound -72.8694723179
Iteration 218 lower bound -87.7798760487
Iteration 219 lower bound -77.8887362416
Iteration 220 lower bound -82.2181682274
Iteration 221 lower bound -87.6259053317
Iteration 222 lower bound -99.2274183136
Iteration 223 lower bound -67.6542483656
Iteration 224 lower bound -77.2302445889
Iteration 225 lower bound -98.7760960182
Iteration 226 lower bound -83.9661930864
Iteration 227 lower bound -49.8818667418
Iteration 228 lower bound -84.8308085443
Iteration 229 lower bound -95.1757131394
Iteration 230 lower bound -103.437224909
Iteration 231 lower bound -94.9104590374
Iteration 232 lower bound -98.1132221815
Iteration 233 lower bound -97.3101311659
Iteration 234 lower bound -83.0636359915
Iteration 235 lower bound -103.629550217
Iteration 236 lower bound -103.424186338
Iteration 237 lower bound -104.585368949
Iteration 238 lower bound -111.286558277
Iteration 239 lower bound -105.178735578
Iteration 240 lower bound -107.463822435
Iteration 241 lower bound -107.07520884
Iteration 242 lower bound -102.259862843
Iteration 243 lower bound -99.4267986358
Iteration 244 lower bound -87.236788028
Iteration 245 lower bound -84.7583880209
Iteration 246 lower bound -106.411947376
Iteration 247 lower bound -104.739020951
Iteration 248 lower bound -102.16889283
Iteration 249 lower bound -103.713552753
Iteration 250 lower bound -94.8292855691
Iteration 251 lower bound -98.4780865482
Iteration 252 lower bound -103.03074129
Iteration 253 lower bound -107.950192695
Iteration 254 lower bound -105.642329526
Iteration 255 lower bound -112.322704467
Iteration 256 lower bound -109.831778761
Iteration 257 lower bound -110.891252575
Iteration 258 lower bound -117.388890054
Iteration 259 lower bound -116.079228871
Iteration 260 lower bound -111.575955714
Iteration 261 lower bound -108.911533893
Iteration 262 lower bound -105.625350412
Iteration 263 lower bound -113.003808359
Iteration 264 lower bound -97.4653074244
Iteration 265 lower bound -114.254178485
Iteration 266 lower bound -100.49184986
Iteration 267 lower bound -117.388573855
Iteration 268 lower bound -108.508819961
Iteration 269 lower bound -104.655566266
Iteration 270 lower bound -109.358532035
Iteration 271 lower bound -108.125611161
Iteration 272 lower bound -111.978902741
Iteration 273 lower bound -115.293445548
Iteration 274 lower bound -117.0222931
Iteration 275 lower bound -118.567448452
Iteration 276 lower bound -116.00054436
Iteration 277 lower bound -127.971931432
Iteration 278 lower bound -116.538237482
Iteration 279 lower bound -111.410206096
Iteration 280 lower bound -107.080001329
Iteration 281 lower bound -119.471123505
Iteration 282 lower bound -120.85003459
Iteration 283 lower bound -115.528041523
Iteration 284 lower bound -121.79245527
Iteration 285 lower bound -125.372299647
Iteration 286 lower bound -124.231840574
Iteration 287 lower bound -115.569981505
Iteration 288 lower bound -107.269809348
Iteration 289 lower bound -117.261796883
Iteration 290 lower bound -101.923370999
Iteration 291 lower bound -124.331564299
Iteration 292 lower bound -118.983360227
Iteration 293 lower bound -83.9837552393
Iteration 294 lower bound -117.058192984
Iteration 295 lower bound -130.366179463
Iteration 296 lower bound -128.457271972
Iteration 297 lower bound -124.391353196
Iteration 298 lower bound -127.345980341
Iteration 299 lower bound -130.49396151
Iteration 300 lower bound -129.007748675
Iteration 301 lower bound -125.779576165
Iteration 302 lower bound -132.71118735
Iteration 303 lower bound -136.511963333
loss is
Optimizing variational parameters...
loss is
Optimizing variational parameters...
loss is
Optimizing variational parameters...
Optimizing variational parameters...
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
losOptimizing variational parameters...
loss is
loss is
Iteration 0 lower bound 21491.1685777
loss is
loss is
Iteration 1 lower bound 11160.4690332
loss is
loss is
Iteration 2 lower bound 5228.56721036
loss is
loss is
Iteration 3 lower bound 2459.42543292
loss is
loss is
Iteration 4 lower bound 1405.33151751
loss is
loss is
Iteration 5 lower bound 1097.33700889
loss is
loss is
Iteration 6 lower bound 1094.59487908
loss is
loss is
Iteration 7 lower bound 1174.64658825
loss is
loss is
Iteration 8 lower bound 1233.31140405
loss is
loss is
Iteration 9 lower bound 1219.7609222
loss is
loss is
Iteration 10 lower bound 1151.02826488
loss is
loss is
Iteration 11 lower bound 1049.60509756
loss is
loss is
Iteration 12 lower bound 963.852363511
loss is
loss is
Iteration 13 lower bound 911.775155253
loss is
loss is
Iteration 14 lower bound 887.802944464
loss is
loss is
Iteration 15 lower bound 872.604086113
loss is
loss is
Iteration 16 lower bound 842.320490689
loss is
loss is
Iteration 17 lower bound 805.58686956
loss is
loss is
Iteration 18 lower bound 739.277432412
loss is
loss is
Iteration 19 lower bound 679.126341056
loss is
loss is
Iteration 20 lower bound 623.951352912
loss is
loss is
Iteration 21 lower bound 607.311744917
loss is
loss is
Iteration 22 lower bound 601.710381221
loss is
loss is
Iteration 23 lower bound 597.715355173
loss is
loss is
Iteration 24 lower bound 564.103471667
loss is
loss is
Iteration 25 lower bound 512.165540894
loss is
loss is
Iteration 26 lower bound 486.386700993
loss is
loss is
Iteration 27 lower bound 466.511603283
loss is
loss is
Iteration 28 lower bound 477.875536921
loss is
loss is
Iteration 29 lower bound 447.926984656
loss is
loss is
Iteration 30 lower bound 428.063181237
loss is
loss is
Iteration 31 lower bound 397.881992708
loss is
loss is
Iteration 32 lower bound 376.569689213
loss is
loss is
Iteration 33 lower bound 378.404319272
loss is
loss is
Iteration 34 lower bound 375.391496204
loss is
loss is
Iteration 35 lower bound 372.677028911
loss is
loss is
Iteration 36 lower bound 346.026874188
loss is
loss is
Iteration 37 lower bound 324.589154973
loss is
loss is
Iteration 38 lower bound 295.16196408
loss is
loss is
Iteration 39 lower bound 287.594780304
loss is
loss is
Iteration 40 lower bound 308.354603623
loss is
loss is
Iteration 41 lower bound 275.20005046
loss is
loss is
Iteration 42 lower bound 275.536240803
loss is
loss is
Iteration 43 lower bound 238.324522154
loss is
loss is
Iteration 44 lower bound 241.654171463
loss is
loss is
Iteration 45 lower bound 233.688157446
loss is
loss is
Iteration 46 lower bound 222.572442408
loss is
loss is
Iteration 47 lower bound 219.080344605
loss is
loss is
Iteration 48 lower bound 187.73140392
loss is
loss is
Iteration 49 lower bound 182.670322525
loss is
loss is
Iteration 50 lower bound 176.820553469
loss is
loss is
Iteration 51 lower bound 171.774655478
loss is
loss is
Iteration 52 lower bound 166.344305865
loss is
loss is
Iteration 53 lower bound 132.788347961
loss is
loss is
Iteration 54 lower bound 145.468214806
loss is
loss is
Iteration 55 lower bound 125.953953053
loss is
loss is
Iteration 56 lower bound 105.119366702
loss is
loss is
Iteration 57 lower bound 117.19763984
loss is
loss is
Iteration 58 lower bound 94.5198807
loss is
loss is
Iteration 59 lower bound 106.273843604
loss is
loss is
Iteration 60 lower bound 124.071954061
loss is
loss is
Iteration 61 lower bound 66.2576501806
loss is
loss is
Iteration 62 lower bound 89.5702916553
loss is
loss is
Iteration 63 lower bound 89.8996104033
loss is
loss is
Iteration 64 lower bound 87.59775081
loss is
loss is
Iteration 65 lower bound 70.4539076598
loss is
loss is
Iteration 66 lower bound 65.6706730053
loss is
loss is
Iteration 67 lower bound 66.0970005262
loss is
loss is
Iteration 68 lower bound 70.9024802925
loss is
loss is
Iteration 69 lower bound 76.1534711813
loss is
loss is
Iteration 70 lower bound 66.5984099443
loss is
loss is
Iteration 71 lower bound 59.4855039791
loss is
loss is
Iteration 72 lower bound 43.8252877996
loss is
loss is
Iteration 73 lower bound 42.0351826644
loss is
loss is
Iteration 74 lower bound 42.7960069797
loss is
loss is
Iteration 75 lower bound 41.1207320353
loss is
loss is
Iteration 76 lower bound 33.068637326
loss is
loss is
Iteration 77 lower bound 32.9164503294
loss is
loss is
Iteration 78 lower bound 40.8058819011
loss is
loss is
Iteration 79 lower bound 42.7974325979
loss is
loss is
Iteration 80 lower bound 39.7049173279
loss is
loss is
Iteration 81 lower bound 35.838143782
loss is
loss is
Iteration 82 lower bound 29.9202719453
loss is
loss is
Iteration 83 lower bound 19.184103458
loss is
loss is
Iteration 84 lower bound 11.944031611
loss is
loss is
Iteration 85 lower bound 24.1257039662
loss is
loss is
Iteration 86 lower bound 21.6081801696
loss is
loss is
Iteration 87 lower bound 18.3459631966
loss is
loss is
Iteration 88 lower bound 30.141293524
loss is
loss is
Iteration 89 lower bound 0.236434945181
loss is
loss is
Iteration 90 lower bound 6.53686371384
loss is
loss is
Iteration 91 lower bound -4.13122928508
loss is
loss is
Iteration 92 lower bound 0.637927502159
loss is
loss is
Iteration 93 lower bound 0.670671967961
loss is
loss is
Iteration 94 lower bound 15.0297485336
loss is
loss is
Iteration 95 lower bound 1.94350063568
loss is
loss is
Iteration 96 lower bound 5.57891894105
loss is
loss is
Iteration 97 lower bound 11.1450247362
loss is
loss is
Iteration 98 lower bound -18.9101673353
loss is
loss is
Iteration 99 lower bound 5.80037378661
loss is
loss is
Iteration 100 lower bound -5.15857109527
loss is
loss is
Iteration 101 lower bound 2.52994392187
loss is
loss is
Iteration 102 lower bound -2.21105774916
loss is
loss is
Iteration 103 lower bound -9.17220139714
loss is
loss is
Iteration 104 lower bound -12.0951457957
loss is
loss is
Iteration 105 lower bound 1.46487861127
loss is
loss is
Iteration 106 lower bound 12.1848533908
loss is
loss is
Iteration 107 lower bound 0.672040694807
loss is
loss is
Iteration 108 lower bound -3.27451917875
loss is
loss is
Iteration 109 lower bound 3.32745895361
loss is
loss is
Iteration 110 lower bound 9.18181522616
loss is
loss is
Iteration 111 lower bound -15.7885734048
loss is
loss is
Iteration 112 lower bound -22.5107410093
loss is
loss is
Iteration 113 lower bound -27.9575916986
loss is
loss is
Iteration 114 lower bound -28.0281882646
loss is
loss is
Iteration 115 lower bound -34.7240031542
loss is
loss is
Iteration 116 lower bound -11.5301533797
loss is
loss is
Iteration 117 lower bound -16.057942387
loss is
loss is
Iteration 118 lower bound -22.2779943317
loss is
loss is
Iteration 119 lower bound -33.6908332837
loss is
loss is
Iteration 120 lower bound -33.8340840423
loss is
loss is
Iteration 121 lower bound -32.670476018
loss is
loss is
Iteration 122 lower bound -18.3147926321
loss is
loss is
Iteration 123 lower bound -33.3074774923
loss is
loss is
Iteration 124 lower bound -9.34333763858
loss is
loss is
Iteration 125 lower bound -33.3673949945
loss is
loss is
Iteration 126 lower bound -41.7525292193
loss is
loss is
Iteration 127 lower bound -41.6746193684
loss is
loss is
Iteration 128 lower bound -36.8556837828
loss is
loss is
Iteration 129 lower bound -31.4706993979
loss is
loss is
Iteration 130 lower bound -41.8704349107
loss is
loss is
Iteration 131 lower bound -50.3755950014
loss is
loss is
Iteration 132 lower bound -41.7037056399
loss is
loss is
Iteration 133 lower bound -43.9660192837
loss is
loss is
Iteration 134 lower bound -47.3795353535
loss is
loss is
Iteration 135 lower bound -44.4893709425
loss is
loss is
Iteration 136 lower bound -40.1327001793
loss is
loss is
Iteration 137 lower bound -45.2150375362
loss is
loss is
Iteration 138 lower bound -51.043661637
loss is
loss is
Iteration 139 lower bound -45.0005038409
loss is
loss is
Iteration 140 lower bound -48.9802408835
loss is
loss is
Iteration 141 lower bound -45.1604183855
loss is
loss is
Iteration 142 lower bound -52.1197494967
loss is
loss is
Iteration 143 lower bound -48.308365473
loss is
loss is
Iteration 144 lower bound -48.4673179593
loss is
loss is
Iteration 145 lower bound -48.3172215711
loss is
loss is
Iteration 146 lower bound -54.337440153
s is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
losOptimizing variational parameters...
s is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
losOptimizing variational parameters...
Optimizing variational parameters...
loss is Autograd FloatNode with value -20965.9241238 and 1 tape(s)
loss is -20986.2389109
Iteration 0 lower bound 21491.1685777
loss is Autograd FloatNode with value -10726.6463956 and 1 tape(s)
loss is -10666.8393663
Iteration 1 lower bound 11160.4690332
loss is Autograd FloatNode with value -4752.38335913 and 1 tape(s)
loss is -4745.95788929
Iteration 2 lower bound 5228.56721036
loss is Autograd FloatNode with value -2004.91417467 and 1 tape(s)
loss is -1988.46488593
Iteration 3 lower bound 2459.42543292
loss is Autograd FloatNode with value -944.675595904 and 1 tape(s)
loss is -946.30991732
Iteration 4 lower bound 1405.33151751
loss is Autograd FloatNode with value -652.405459976 and 1 tape(s)
loss is -650.506087284
Iteration 5 lower bound 1097.33700889
loss is Autograd FloatNode with value -659.788730807 and 1 tape(s)
loss is -660.106139772
Iteration 6 lower bound 1094.59487908
loss is Autograd FloatNode with value -757.786619369 and 1 tape(s)
loss is -752.623356164
Iteration 7 lower bound 1174.64658825
loss is Autograd FloatNode with value -817.718918124 and 1 tape(s)
loss is -823.834925055
Iteration 8 lower bound 1233.31140405
loss is Autograd FloatNode with value -823.381251748 and 1 tape(s)
loss is -822.904544784
Iteration 9 lower bound 1219.7609222
loss is Autograd FloatNode with value -765.268638743 and 1 tape(s)
loss is -766.844067199
Iteration 10 lower bound 1151.02826488
loss is Autograd FloatNode with value -678.010473037 and 1 tape(s)
loss is -678.119887919
Iteration 11 lower bound 1049.60509756
loss is Autograd FloatNode with value -608.924195104 and 1 tape(s)
loss is -605.116207282
Iteration 12 lower bound 963.852363511
loss is Autograd FloatNode with value -564.670369511 and 1 tape(s)
loss is -565.801387765
Iteration 13 lower bound 911.775155253
loss is Autograd FloatNode with value -551.438304358 and 1 tape(s)
loss is -554.631501095
Iteration 14 lower bound 887.802944464
loss is Autograd FloatNode with value -546.983246792 and 1 tape(s)
loss is -552.264372464
Iteration 15 lower bound 872.604086113
loss is Autograd FloatNode with value -535.675929047 and 1 tape(s)
loss is -534.830940457
Iteration 16 lower bound 842.320490689
loss is Autograd FloatNode with value -509.544401559 and 1 tape(s)
loss is -510.951712741
Iteration 17 lower bound 805.58686956
loss is Autograd FloatNode with value -458.32017393 and 1 tape(s)
loss is -457.460614317
Iteration 18 lower bound 739.277432412
loss is Autograd FloatNode with value -405.26621221 and 1 tape(s)
loss is -410.094847421
Iteration 19 lower bound 679.126341056
loss is Autograd FloatNode with value -371.80612986 and 1 tape(s)
loss is -367.668826226
Iteration 20 lower bound 623.951352912
loss is Autograd FloatNode with value -360.152731438 and 1 tape(s)
loss is -363.696101096
Iteration 21 lower bound 607.311744917
loss is Autograd FloatNode with value -385.680177429 and 1 tape(s)
loss is -370.700666979
Iteration 22 lower bound 601.710381221
loss is Autograd FloatNode with value -381.183450519 and 1 tape(s)
loss is -379.056620318
Iteration 23 lower bound 597.715355173
loss is Autograd FloatNode with value -350.639445225 and 1 tape(s)
loss is -357.598641133
Iteration 24 lower bound 564.103471667
loss is Autograd FloatNode with value -314.080462737 and 1 tape(s)
loss is -317.64148462
Iteration 25 lower bound 512.165540894
loss is Autograd FloatNode with value -294.787392902 and 1 tape(s)
loss is -303.769570726
Iteration 26 lower bound 486.386700993
loss is Autograd FloatNode with value -294.574142153 and 1 tape(s)
loss is -295.753003542
Iteration 27 lower bound 466.511603283
loss is Autograd FloatNode with value -297.211275739 and 1 tape(s)
loss is -318.846786767
Iteration 28 lower bound 477.875536921
loss is Autograd FloatNode with value -285.993252692 and 1 tape(s)
loss is -300.576095934
Iteration 29 lower bound 447.926984656
loss is Autograd FloatNode with value -296.32070144 and 1 tape(s)
loss is -292.378155127
Iteration 30 lower bound 428.063181237
loss is Autograd FloatNode with value -275.558450239 and 1 tape(s)
loss is -273.442009064
Iteration 31 lower bound 397.881992708
loss is Autograd FloatNode with value -260.128091906 and 1 tape(s)
loss is -263.087272897
Iteration 32 lower bound 376.569689213
loss is Autograd FloatNode with value -274.074282562 and 1 tape(s)
loss is -275.678871615
Iteration 33 lower bound 378.404319272
loss is Autograd FloatNode with value -291.167928408 and 1 tape(s)
loss is -282.877920747
Iteration 34 lower bound 375.391496204
loss is Autograd FloatNode with value -277.095489457 and 1 tape(s)
loss is -289.687573873
Iteration 35 lower bound 372.677028911
loss is Autograd FloatNode with value -275.257591912 and 1 tape(s)
loss is -272.280470695
Iteration 36 lower bound 346.026874188
loss is Autograd FloatNode with value -274.996325339 and 1 tape(s)
loss is -259.792102813
Iteration 37 lower bound 324.589154973
loss is Autograd FloatNode with value -245.722457245 and 1 tape(s)
loss is -238.954727404
Iteration 38 lower bound 295.16196408
loss is Autograd FloatNode with value -268.931429676 and 1 tape(s)
loss is -239.861564442
Iteration 39 lower bound 287.594780304
loss is Autograd FloatNode with value -255.348819386 and 1 tape(s)
loss is -268.682102124
Iteration 40 lower bound 308.354603623
loss is Autograd FloatNode with value -251.982445287 and 1 tape(s)
loss is -243.358212147
Iteration 41 lower bound 275.20005046
loss is Autograd FloatNode with value -257.483224706 and 1 tape(s)
loss is -251.203514266
Iteration 42 lower bound 275.536240803
loss is Autograd FloatNode with value -232.058264552 and 1 tape(s)
loss is -221.08325333
Iteration 43 lower bound 238.324522154
loss is Autograd FloatNode with value -235.712515166 and 1 tape(s)
loss is -231.379675647
Iteration 44 lower bound 241.654171463
loss is Autograd FloatNode with value -235.349717337 and 1 tape(s)
loss is -230.101526769
Iteration 45 lower bound 233.688157446
loss is Autograd FloatNode with value -222.590857648 and 1 tape(s)
loss is -225.528648829
Iteration 46 lower bound 222.572442408
loss is Autograd FloatNode with value -203.621563558 and 1 tape(s)
loss is -228.440148847
Iteration 47 lower bound 219.080344605
loss is Autograd FloatNode with value -211.194311172 and 1 tape(s)
loss is -203.629310078
Iteration 48 lower bound 187.73140392
loss is Autograd FloatNode with value -206.524995453 and 1 tape(s)
loss is -204.922732017
Iteration 49 lower bound 182.670322525
loss is Autograd FloatNode with value -198.84814878 and 1 tape(s)
loss is -205.308986678
Iteration 50 lower bound 176.820553469
loss is Autograd FloatNode with value -195.977848107 and 1 tape(s)
loss is -206.341057825
Iteration 51 lower bound 171.774655478
loss is Autograd FloatNode with value -197.253913189 and 1 tape(s)
loss is -206.679823446
Iteration 52 lower bound 166.344305865
loss is Autograd FloatNode with value -188.630427762 and 1 tape(s)
loss is -178.237774015
Iteration 53 lower bound 132.788347961
loss is Autograd FloatNode with value -194.123547886 and 1 tape(s)
loss is -195.668901114
Iteration 54 lower bound 145.468214806
loss is Autograd FloatNode with value -179.628251336 and 1 tape(s)
loss is -180.169470047
Iteration 55 lower bound 125.953953053
loss is Autograd FloatNode with value -183.775067906 and 1 tape(s)
loss is -163.077252397
Iteration 56 lower bound 105.119366702
loss is Autograd FloatNode with value -191.601400066 and 1 tape(s)
loss is -178.342396453
Iteration 57 lower bound 117.19763984
loss is Autograd FloatNode with value -179.79824688 and 1 tape(s)
loss is -158.135411799
Iteration 58 lower bound 94.5198807
loss is Autograd FloatNode with value -159.615089028 and 1 tape(s)
loss is -171.925551445
Iteration 59 lower bound 106.273843604
loss is Autograd FloatNode with value -161.016620687 and 1 tape(s)
loss is -191.68226752
Iteration 60 lower bound 124.071954061
loss is Autograd FloatNode with value -166.45350808 and 1 tape(s)
loss is -135.638158633
Iteration 61 lower bound 66.2576501806
loss is Autograd FloatNode with value -175.055334764 and 1 tape(s)
loss is -160.05503616
Iteration 62 lower bound 89.5702916553
loss is Autograd FloatNode with value -144.347876294 and 1 tape(s)
loss is -161.518790486
Iteration 63 lower bound 89.8996104033
loss is Autograd FloatNode with value -160.386811074 and 1 tape(s)
loss is -160.827962717
Iteration 64 lower bound 87.59775081
loss is Autograd FloatNode with value -140.629604922 and 1 tape(s)
loss is -145.219217899
Iteration 65 lower bound 70.4539076598
loss is Autograd FloatNode with value -132.773068811 and 1 tape(s)
loss is -142.280935136
Iteration 66 lower bound 65.6706730053
loss is Autograd FloatNode with value -160.862527822 and 1 tape(s)
loss is -144.612027071
Iteration 67 lower bound 66.0970005262
loss is Autograd FloatNode with value -143.396961829 and 1 tape(s)
loss is -151.157451318
Iteration 68 lower bound 70.9024802925
loss is Autograd FloatNode with value -136.672440426 and 1 tape(s)
loss is -158.151917671
Iteration 69 lower bound 76.1534711813
loss is Autograd FloatNode with value -144.272111397 and 1 tape(s)
loss is -150.254416906
Iteration 70 lower bound 66.5984099443
loss is Autograd FloatNode with value -138.422434223 and 1 tape(s)
loss is -144.656819698
Iteration 71 lower bound 59.4855039791
loss is Autograd FloatNode with value -137.20818439 and 1 tape(s)
loss is -130.566996557
Iteration 72 lower bound 43.8252877996
loss is Autograd FloatNode with value -139.482513616 and 1 tape(s)
loss is -130.499785471
Iteration 73 lower bound 42.0351826644
loss is Autograd FloatNode with value -139.286561139 and 1 tape(s)
loss is -132.841392438
Iteration 74 lower bound 42.7960069797
loss is Autograd FloatNode with value -130.061838892 and 1 tape(s)
loss is -132.312862216
Iteration 75 lower bound 41.1207320353
loss is Autograd FloatNode with value -150.163880159 and 1 tape(s)
loss is -125.318653562
Iteration 76 lower bound 33.068637326
loss is Autograd FloatNode with value -122.908913974 and 1 tape(s)
loss is -126.143355653
Iteration 77 lower bound 32.9164503294
loss is Autograd FloatNode with value -141.271318606 and 1 tape(s)
loss is -135.152284684
Iteration 78 lower bound 40.8058819011
loss is Autograd FloatNode with value -136.000288409 and 1 tape(s)
loss is -138.323472699
Iteration 79 lower bound 42.7974325979
loss is Autograd FloatNode with value -136.673870467 and 1 tape(s)
loss is -136.550643822
Iteration 80 lower bound 39.7049173279
loss is Autograd FloatNode with value -117.262638446 and 1 tape(s)
loss is -134.093220433
Iteration 81 lower bound 35.838143782
loss is Autograd FloatNode with value -129.197009591 and 1 tape(s)
loss is -129.786004666
Iteration 82 lower bound 29.9202719453
loss is Autograd FloatNode with value -141.473906008 and 1 tape(s)
loss is -120.694242916
Iteration 83 lower bound 19.184103458
loss is Autograd FloatNode with value -151.820643205 and 1 tape(s)
loss is -115.083190013
Iteration 84 lower bound 11.944031611
loss is Autograd FloatNode with value -115.051802956 and 1 tape(s)
loss is -128.384258349
Iteration 85 lower bound 24.1257039662
loss is Autograd FloatNode with value -128.659904308 and 1 tape(s)
loss is -127.251540622
Iteration 86 lower bound 21.6081801696
loss is Autograd FloatNode with value -113.805704942 and 1 tape(s)
loss is -125.495483894
Iteration 87 lower bound 18.3459631966
loss is Autograd FloatNode with value -118.305278475 and 1 tape(s)
loss is -139.091751371
Iteration 88 lower bound 30.141293524
loss is Autograd FloatNode with value -121.60615479 and 1 tape(s)
loss is -111.181454408
Iteration 89 lower bound 0.236434945181
loss is Autograd FloatNode with value -115.672170779 and 1 tape(s)
loss is -119.476301853
Iteration 90 lower bound 6.53686371384
loss is Autograd FloatNode with value -147.225666624 and 1 tape(s)
loss is -110.799089647
Iteration 91 lower bound -4.13122928508
loss is Autograd FloatNode with value -127.728711219 and 1 tape(s)
loss is -116.980397375
Iteration 92 lower bound 0.637927502159
loss is Autograd FloatNode with value -145.839568096 and 1 tape(s)
loss is -118.181015515
Iteration 93 lower bound 0.670671967961
loss is Autograd FloatNode with value -141.80000348 and 1 tape(s)
loss is -133.109615062
Iteration 94 lower bound 15.0297485336
loss is Autograd FloatNode with vs is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
loss is
alue -148.550950288 and 1 tape(s)
loss is -120.424646373
Iteration 95 lower bound 1.94350063568
loss is Autograd FloatNode with value -119.690865565 and 1 tape(s)
loss is -124.134817383
Iteration 96 lower bound 5.57891894105
loss is Autograd FloatNode with value -109.73715338 and 1 tape(s)
loss is -129.881040831
Iteration 97 lower bound 11.1450247362
loss is Autograd FloatNode with value -109.771556453 and 1 tape(s)
loss is -100.082401637
Iteration 98 lower bound -18.9101673353
loss is Autograd FloatNode with value -119.412657865 and 1 tape(s)
loss is -125.262779684
Iteration 99 lower bound 5.80037378661
loss is Autograd FloatNode with value -153.200890028 and 1 tape(s)
loss is -114.992801488
Iteration 100 lower bound -5.15857109527
loss is Autograd FloatNode with value -107.676896135 and 1 tape(s)
loss is -122.665185238
Iteration 101 lower bound 2.52994392187
loss is Autograd FloatNode with value -136.846904065 and 1 tape(s)
loss is -118.142679804
Iteration 102 lower bound -2.21105774916
loss is Autograd FloatNode with value -114.3675758 and 1 tape(s)
loss is -111.350689343
Iteration 103 lower bound -9.17220139714
loss is Autograd FloatNode with value -122.018042212 and 1 tape(s)
loss is -108.854961738
Iteration 104 lower bound -12.0951457957
loss is Autograd FloatNode with value -105.840777477 and 1 tape(s)
loss is -122.881600593
Iteration 105 lower bound 1.46487861127
loss is Autograd FloatNode with value -116.757086907 and 1 tape(s)
loss is -134.173705485
Iteration 106 lower bound 12.1848533908
loss is Autograd FloatNode with value -110.950865524 and 1 tape(s)
loss is -123.172727772
Iteration 107 lower bound 0.672040694807
loss is Autograd FloatNode with value -113.215747796 and 1 tape(s)
loss is -119.836658399
Iteration 108 lower bound -3.27451917875
loss is Autograd FloatNode with value -106.098449807 and 1 tape(s)
loss is -127.115688565
Iteration 109 lower bound 3.32745895361
loss is Autograd FloatNode with value -96.6682487595 and 1 tape(s)
loss is -133.756098265
Iteration 110 lower bound 9.18181522616
loss is Autograd FloatNode with value -103.623066542 and 1 tape(s)
loss is -109.837874426
Iteration 111 lower bound -15.7885734048
loss is Autograd FloatNode with value -103.682015931 and 1 tape(s)
loss is -104.352994736
Iteration 112 lower bound -22.5107410093
loss is Autograd FloatNode with value -113.271855408 and 1 tape(s)
loss is -100.353330425
Iteration 113 lower bound -27.9575916986
loss is Autograd FloatNode with value -138.781103314 and 1 tape(s)
loss is -101.515202564
Iteration 114 lower bound -28.0281882646
loss is Autograd FloatNode with value -108.188291904 and 1 tape(s)
loss is -96.0956349554
Iteration 115 lower bound -34.7240031542
loss is Autograd FloatNode with value -108.342628694 and 1 tape(s)
loss is -120.520488653
Iteration 116 lower bound -11.5301533797
loss is Autograd FloatNode with value -103.389749577 and 1 tape(s)
loss is -117.231811459
Iteration 117 lower bound -16.057942387
loss is Autograd FloatNode with value -97.098199965 and 1 tape(s)
loss is -112.400615806
Iteration 118 lower bound -22.2779943317
loss is Autograd FloatNode with value -92.9010379646 and 1 tape(s)
loss is -102.557771547
Iteration 119 lower bound -33.6908332837
loss is Autograd FloatNode with value -105.902084866 and 1 tape(s)
loss is -104.089294513
Iteration 120 lower bound -33.8340840423
loss is Autograd FloatNode with value -106.696734998 and 1 tape(s)
loss is -106.772561765
Iteration 121 lower bound -32.670476018
loss is Autograd FloatNode with value -98.3875951886 and 1 tape(s)
loss is -122.616347337
Iteration 122 lower bound -18.3147926321
loss is Autograd FloatNode with value -121.686835537 and 1 tape(s)
loss is -109.196876795
Iteration 123 lower bound -33.3074774923
loss is Autograd FloatNode with value -138.688475024 and 1 tape(s)
loss is -134.323219093
Iteration 124 lower bound -9.34333763858
loss is Autograd FloatNode with value -116.013437412 and 1 tape(s)
loss is -110.712307698
Iteration 125 lower bound -33.3673949945
loss is Autograd FloatNode with value -108.290291061 and 1 tape(s)
loss is -102.888917657
Iteration 126 lower bound -41.7525292193
loss is Autograd FloatNode with value -114.562820898 and 1 tape(s)
loss is -103.764744949
Iteration 127 lower bound -41.6746193684
loss is Autograd FloatNode with value -126.072746679 and 1 tape(s)
loss is -109.23519436
Iteration 128 lower bound -36.8556837828
loss is Autograd FloatNode with value -123.570427451 and 1 tape(s)
loss is -115.075694948
Iteration 129 lower bound -31.4706993979
loss is Autograd FloatNode with value -120.076876085 and 1 tape(s)
loss is -104.848811308
Iteration 130 lower bound -41.8704349107
loss is Autograd FloatNode with value -101.554323219 and 1 tape(s)
loss is -96.3216473923
Iteration 131 lower bound -50.3755950014
loss is Autograd FloatNode with value -91.6683471871 and 1 tape(s)
loss is -105.080511979
Iteration 132 lower bound -41.7037056399
loss is Autograd FloatNode with value -98.1213992198 and 1 tape(s)
loss is -103.276643551
Iteration 133 lower bound -43.9660192837
loss is Autograd FloatNode with value -97.2272000487 and 1 tape(s)
loss is -100.631077745
Iteration 134 lower bound -47.3795353535
loss is Autograd FloatNode with value -96.004614931 and 1 tape(s)
loss is -104.540245819
Iteration 135 lower bound -44.4893709425
loss is Autograd FloatNode with value -99.2851153109 and 1 tape(s)
loss is -110.04984427
Iteration 136 lower bound -40.1327001793
loss is Autograd FloatNode with value -117.18551881 and 1 tape(s)
loss is -106.253651394
Iteration 137 lower bound -45.2150375362
loss is Autograd FloatNode with value -93.434146462 and 1 tape(s)
loss is -101.495962081
Iteration 138 lower bound -51.043661637
loss is Autograd FloatNode with value -112.015206409 and 1 tape(s)
loss is -108.77073389
Iteration 139 lower bound -45.0005038409
loss is Autograd FloatNode with value -114.653410736 and 1 tape(s)
loss is -106.014494177
Iteration 140 lower bound -48.9802408835
loss is Autograd FloatNode with value -131.97339874 and 1 tape(s)
loss is -110.9819169
Iteration 141 lower bound -45.1604183855
loss is Autograd FloatNode with value -105.978077577 and 1 tape(s)
loss is -105.006130106
Iteration 142 lower bound -52.1197494967
loss is Autograd FloatNode with value -107.469995836 and 1 tape(s)
loss is -109.849424529
Iteration 143 lower bound -48.308365473
loss is Autograd FloatNode with value -101.18996316 and 1 tape(s)
loss is -110.706397796
Iteration 144 lower bound -48.4673179593
loss is Autograd FloatNode with value -117.738639759 and 1 tape(s)
loss is -111.966485014
Iteration 145 lower bound -48.3172215711
loss is Autograd FloatNode with value -111.106798189 and 1 tape(s)
loss is -107.005346408
Iteration 146 lower bound -54.337440153
loss is Autograd FloatNode with value -109.924961905 and 1 tape(s)
loss is -106.299789849
Iteration 147 lower bound -55.9806626672
loss is Autograd FloatNode with value -114.10723993 and 1 tape(s)
loss is -108.24762775
Iteration 148 lower bound -54.8939794023
loss is Autograd FloatNode with value -110.180706619 and 1 tape(s)
loss is -110.974830794
Iteration 149 lower bound -53.1283437024
loss is Autograd FloatNode with value -109.486479191 and 1 tape(s)
loss is -128.494263999
Iteration 150 lower bound -36.76552838
loss is Autograd FloatNode with value -100.448560919 and 1 tape(s)
loss is -103.520719109
Iteration 151 lower bound -62.9640598018
loss is Autograd FloatNode with value -108.256710255 and 1 tape(s)
loss is -116.577950129
Iteration 152 lower bound -51.2251061412
loss is Autograd FloatNode with value -106.781704009 and 1 tape(s)
loss is -116.980478691
Iteration 153 lower bound -52.059863633
loss is Autograd FloatNode with value -116.92673876 and 1 tape(s)
loss is -121.20555973
Iteration 154 lower bound -49.1268118206
loss is Autograd FloatNode with value -106.715275368 and 1 tape(s)
loss is -113.954278613
Iteration 155 lower bound -57.4516882714
loss is Autograd FloatNode with value -122.037749772 and 1 tape(s)
loss is -125.830694677
Iteration 156 lower bound -46.5222487028
loss is Autograd FloatNode with value -125.967304324 and 1 tape(s)
loss is -117.23540631
Iteration 157 lower bound -55.9481095433
loss is Autograd FloatNode with value -128.76677836 and 1 tape(s)
loss is -112.270695473
Iteration 158 lower bound -61.3444947255
loss is Autograd FloatNode with value -121.126995702 and 1 tape(s)
loss is -112.778945406
Iteration 159 lower bound -61.3223869839
loss is Autograd FloatNode with value -114.953203124 and 1 tape(s)
loss is -116.709937163
Iteration 160 lower bound -57.9095354838
loss is Autograd FloatNode with value -108.761929622 and 1 tape(s)
loss is -114.689200266
Iteration 161 lower bound -60.2864085815
loss is Autograd FloatNode with value -141.743305583 and 1 tape(s)
loss is -136.045764461
Iteration 162 lower bound -39.3227436103
loss is Autograd FloatNode with value -107.452872659 and 1 tape(s)
loss is -115.893866066
Iteration 163 lower bound -59.4734762866
loss is Autograd FloatNode with value -117.063371251 and 1 tape(s)
loss is -122.407417024
Iteration 164 lower bound -53.0859338874
loss is Autograd FloatNode with value -109.406234254 and 1 tape(s)
loss is -125.324973945
Iteration 165 lower bound -50.2014863814
loss is Autograd FloatNode with value -115.790825152 and 1 tape(s)
loss is -119.179857392
Iteration 166 lower bound -56.6578528433
loss is Autograd FloatNode with value -120.514694117 and 1 tape(s)
loss is -112.699575916
Iteration 167 lower bound -63.5970053096
loss is Autograd FloatNode with value -103.117404349 and 1 tape(s)
loss is -104.722238461
Iteration 168 lower bound -71.8512334993
loss is Autograd FloatNode with value -130.414248974 and 1 tape(s)
loss is -108.282138556
Iteration 169 lower bound -68.7198581731
loss is Autograd FloatNode with value -112.731699916 and 1 tape(s)
loss is -121.43847035
Iteration 170 lower bound -55.5408874134
loss is Autograd FloatNode with value -112.130457965 and 1 tape(s)
loss is -97.8805187372
Iteration 171 lower bound -79.1518909295
loss is Autograd FloatNode with value -120.283958423 and 1 tape(s)
loss is -120.556747849
Iteration 172 lower bound -56.5004199506
loss is Autograd FloatNode with value -125.945589486 and 1 tape(s)
loss is -117.294070862
Iteration 173 lower bound -59.9126711737
loss is Autograd FloatNode with value -105.696876617 and 1 tape(s)
loss is -117.905023383
Iteration 174 lower bound -59.3788278352
loss is Autograd FloatNode with value -97.8247365451 and 1 tape(s)
loss is -100.145515179
Iteration 175 lower bound -77.4609636699
loss is Autograd FloatNode with value -104.272279967 and 1 tape(s)
loss is -106.32501728
Iteration 176 lower bound -71.8347877401
loss is Autograd FloatNode with value -121.385763132 and 1 tape(s)
loss is -101.37353687
Iteration 177 lower bound -77.4407107135
loss is Autograd FloatNode with value -118.531128426 and 1 tape(s)
loss is -115.347144396
Iteration 178 lower bound -64.0461134716
loss is Autograd FloatNode with value -102.143520117 and 1 tape(s)
loss is -96.3683018757
Iteration 179 lower bound -83.4196909708
loss is Autograd FloatNode with value -112.880411917 and 1 tape(s)
loss is -112.749180694
Iteration 180 lower bound -67.536096239
loss is Autograd FloatNode with value -143.96277226 and 1 tape(s)
loss is -130.735598156
Iteration 181 lower bound -50.0439663497
loss is Autograd FloatNode with value -122.125186939 and 1 tape(s)
loss is -116.875451041
Iteration 182 lower bound -64.3016457655
loss is Autograd FloatNode with value -111.533299111 and 1 tape(s)
loss is -100.732059062
Iteration 183 lower bound -80.813427511
loss is Autograd FloatNode with value -105.108735704 and 1 tape(s)
loss is -103.47001318
Iteration 184 lower bound -78.4690591741
loss is Autograd FloatNode with value -104.629230447 and 1 tape(s)
loss is -126.478028889
Iteration 185 lower bound -55.9891439606
loss is Autograd FloatNode with value -111.325187166 and 1 tape(s)
loss is -123.167897139
Iteration 186 lower bound -59.9901406516
loss is Autograd FloatNode with value -107.546317615 and 1 tape(s)
loss is -114.780940004
Iteration 187 lower bound -68.9996832181
loss is Autograd FloatNode with value -103.361089377 and 1 tape(s)
loss is -104.233678735
Iteration 188 lower bound -80.1284360547
loss is Autograd FloatNode with value -116.694046173 and 1 tape(s)
loss is -115.947449165
Iteration 189 lower bound -69.1466862255
loss is Autograd FloatNode with value -125.790367646 and 1 tape(s)
loss is -104.751315792
Iteration 190 lower bound -80.9897528972
loss is Autograd FloatNode with value -95.4277886656 and 1 tape(s)
loss is -108.700372009
Iteration 191 lower bound -77.8421839123
loss is Autograd FloatNode with value -104.795342234 and 1 tape(s)
loss is -112.848232655
Iteration 192 lower bound -74.7575908988
loss is Autograd FloatNode with value -109.864766977 and 1 tape(s)
loss is -103.051604868
Iteration 193 lower bound -85.7167394407
loss is Autograd FloatNode with value -107.301486264 and 1 tape(s)
loss is -109.476412403
Iteration 194 lower bound -80.3418143298
loss is Autograd FloatNode with value -104.167601299 and 1 tape(s)
loss is -125.075589536
Iteration 195 lower bound -65.8035067233
loss is Autograd FloatNode with value -138.22961097 and 1 tape(s)
loss is -107.496064518
Iteration 196 lower bound -84.4786015852
loss is Autograd FloatNode with value -101.16762226 and 1 tape(s)
loss is -106.361022216
Iteration 197 lower bound -86.1693558801
loss is Autograd FloatNode with value -108.553786061 and 1 tape(s)
loss is -94.6284824374
Iteration 198 lower bound -98.5675332008
loss is Autograd FloatNode with value -103.687987606 and 1 tape(s)
loss is -117.74399725
Iteration 199 lower bound -76.0340063064
loss is Autograd FloatNode with value -115.3011618 and 1 tape(s)
loss is -115.150897355
Iteration 200 lower bound -79.4543215307
loss is Autograd FloatNode with value -103.742381164 and 1 tape(s)
loss is -101.723342007
Iteration 201 lower bound -93.6953055748
loss is Autograd FloatNode with value -108.694754305 and 1 tape(s)
loss is -112.599090856
Iteration 202 lower bound -83.7406677305
loss is Autograd FloatNode with value -107.921527142 and 1 tape(s)
loss is -114.772789232
Iteration 203 lower bound -82.5545779319
loss is Autograd FloatNode with value -105.015394227 and 1 tape(s)
loss is -108.101639804
Iteration 204 lower bound -90.2425619888
loss is Autograd FloatNode with value -108.839944534 and 1 tape(s)
loss is -108.967804843
Iteration 205 lower bound -90.5118059012
loss is Autograd FloatNode with value -127.334999002 and 1 tape(s)
loss is -127.983381645
Iteration 206 lower bound -72.4943921128
loss is Autograd FloatNode with value -114.815174525 and 1 tape(s)
loss is -110.726667378
Iteration 207 lower bound -90.3230140265
loss is Autograd FloatNode with value -109.472045627 and 1 tape(s)
loss is -115.063558076
Iteration 208 lower bound -86.6867847426
loss is Autograd FloatNode with value -110.5620701 and 1 tape(s)
loss is -105.97881695
Iteration 209 lower bound -96.5609361041
loss is Autograd FloatNode with value -107.445610588 and 1 tape(s)
loss is -106.713747502
Iteration 210 lower bound -96.5238007042
loss is Autograd FloatNode with value -119.291704777 and 1 tape(s)
loss is -121.332523463
Iteration 211 lower bound -82.5926629111
loss is Autograd FloatNode with value -119.984522295 and 1 tape(s)
loss is -125.075102393
Iteration 212 lower bound -79.4411357734
loss is Autograd FloatNode with value -134.200194149 and 1 tape(s)
loss is -111.14606758
Iteration 213 lower bound -93.9824893414
loss is Autograd FloatNode with value -115.652880869 and 1 tape(s)
loss is -126.493926862
Iteration 214 lower bound -78.3944668849
loss is Autograd FloatNode with value -121.335608529 and 1 tape(s)
loss is -129.123827502
Iteration 215 lower bound -75.6138421679
loss is Autograd FloatNode with value -116.688081563 and 1 tape(s)
loss is -107.86268945
Iteration 216 lower bound -96.9683940587
loss is Autograd FloatNode with value -100.15969461 and 1 tape(s)
loss is -132.222503534
Iteration 217 lower bound -72.8694723179
loss is Autograd FloatNode with value -112.438602366 and 1 tape(s)
loss is -117.775929588
Iteration 218 lower bound -87.7798760487
loss is Autograd FloatNode with value -124.676790633 and 1 tape(s)
loss is -128.093081881
Iteration 219 lower bound -77.8887362416
loss is Autograd FloatNode with value -105.72460304 and 1 tape(s)
loss is -124.061608586
Iteration 220 lower bound -82.2181682274
loss is Autograd FloatNode with value -127.590213458 and 1 tape(s)
loss is -119.176102489
Iteration 221 lower bound -87.6259053317
loss is Autograd FloatNode with value -123.98026657 and 1 tape(s)
loss is -107.869147766
Iteration 222 lower bound -99.2274183136
loss is Autograd FloatNode with value -117.876989357 and 1 tape(s)
loss is -139.670878549
Iteration 223 lower bound -67.6542483656
loss is Autograd FloatNode with value -118.188093679 and 1 tape(s)
loss is -130.353744076
Iteration 224 lower bound -77.2302445889
loss is Autograd FloatNode with value -103.922763242 and 1 tape(s)
loss is -109.280893359
Iteration 225 lower bound -98.7760960182
loss is Autograd FloatNode with value -112.448849181 and 1 tape(s)
loss is -124.763651066
Iteration 226 lower bound -83.9661930864
loss is Autograd FloatNode with value -121.783947495 and 1 tape(s)
loss is -159.490506081
Iteration 227 lower bound -49.8818667418
loss is Autograd FloatNode with value -120.0208831 and 1 tape(s)
loss is -125.176354453
Iteration 228 lower bound -84.8308085443
loss is Autograd FloatNode with value -129.054535716 and 1 tape(s)
loss is -115.295975739
Iteration 229 lower bound -95.1757131394
loss is Autograd FloatNode with value -116.136394132 and 1 tape(s)
loss is -107.419427508
Iteration 230 lower bound -103.437224909
loss is Autograd FloatNode with value -116.618708796 and 1 tape(s)
loss is -116.351141611
Iteration 231 lower bound -94.9104590374
loss is Autograd FloatNode with value -113.313706231 and 1 tape(s)
loss is -113.339688839
Iteration 232 lower bound -98.1132221815
loss is Autograd FloatNode with value -114.977402985 and 1 tape(s)
loss is -114.345475706
Iteration 233 lower bound -97.3101311659
loss is Autograd FloatNode with value -141.119652544 and 1 tape(s)
loss is -128.913181947
Iteration 234 lower bound -83.0636359915
loss is Autograd FloatNode with value -121.555871777 and 1 tape(s)
loss is -108.419867005
Iteration 235 lower bound -103.629550217
loss is Autograd FloatNode with value -114.840550151 and 1 tape(s)
loss is -108.552789292
Iteration 236 lower bound -103.424186338
loss is Autograd FloatNode with value -113.032014677 and 1 tape(s)
loss is -107.338411404
Iteration 237 lower bound -104.585368949
loss is Autograd FloatNode with value -116.018144226 and 1 tape(s)
loss is -100.555467596
Iteration 238 lower bound -111.286558277
loss is Autograd FloatNode with value -105.296461198 and 1 tape(s)
loss is -106.656128099
Iteration 239 lower bound -105.178735578
loss is Autograd FloatNode with value -102.13854303 and 1 tape(s)
loss is -104.578578078
Iteration 240 lower bound -107.463822435
loss is Autograd FloatNode with value -111.258594697 and 1 tape(s)
loss is -105.356542216
Iteration 241 lower bound -107.07520884
loss is Autograd FloatNode with value -109.203039809 and 1 tape(s)
loss is -110.702459926
Iteration 242 lower bound -102.259862843
loss is Autograd FloatNode with value -104.762064094 and 1 tape(s)
loss is -114.052075377
Iteration 243 lower bound -99.4267986358
loss is Autograd FloatNode with value -113.986697702 and 1 tape(s)
loss is -126.770648381
Iteration 244 lower bound -87.236788028
loss is Autograd FloatNode with value -129.47677315 and 1 tape(s)
loss is -129.960539019
Iteration 245 lower bound -84.7583880209
loss is Autograd FloatNode with value -144.281525665 and 1 tape(s)
loss is -108.664986945
Iteration 246 lower bound -106.411947376
loss is Autograd FloatNode with value -105.7062636 and 1 tape(s)
loss is -109.849228417
Iteration 247 lower bound -104.739020951
loss is Autograd FloatNode with value -100.478681048 and 1 tape(s)
loss is -112.131518768
Iteration 248 lower bound -102.16889283
loss is Autograd FloatNode with value -100.181692865 and 1 tape(s)
loss is -110.592134993
Iteration 249 lower bound -103.713552753
loss is Autograd FloatNode with value -112.189550179 and 1 tape(s)
loss is -119.771486155
Iteration 250 lower bound -94.8292855691
loss is Autograd FloatNode with value -103.797114851 and 1 tape(s)
loss is -116.475838799
Iteration 251 lower bound -98.4780865482
loss is Autograd FloatNode with value -106.442628938 and 1 tape(s)
loss is -112.381176679
Iteration 252 lower bound -103.03074129
loss is Autograd FloatNode with value -107.707797037 and 1 tape(s)
loss is -107.989879946
Iteration 253 lower bound -107.950192695
loss is Autograd FloatNode with value -101.89012509 and 1 tape(s)
loss is -110.817065337
Iteration 254 lower bound -105.642329526
loss is Autograd FloatNode with value -115.626760848 and 1 tape(s)
loss is -104.763423143
Iteration 255 lower bound -112.322704467
loss is Autograd FloatNode with value -101.127432467 and 1 tape(s)
loss is -107.826752653
Iteration 256 lower bound -109.831778761
loss is Autograd FloatNode with value -109.075868622 and 1 tape(s)
loss is -107.550201285
Iteration 257 lower bound -110.891252575
loss is Autograd FloatNode with value -119.750402369 and 1 tape(s)
loss is -101.864062483
Iteration 258 lower bound -117.388890054
loss is Autograd FloatNode with value -112.309144943 and 1 tape(s)
loss is -103.774105193
Iteration 259 lower bound -116.079228871
loss is Autograd FloatNode with value -113.732718918 and 1 tape(s)
loss is -108.787223119
Iteration 260 lower bound -111.575955714
loss is Autograd FloatNode with value -127.332431167 and 1 tape(s)
loss is -111.939632952
Iteration 261 lower bound -108.911533893
loss is Autograd FloatNode with value -111.359165924 and 1 tape(s)
loss is -115.323016442
Iteration 262 lower bound -105.625350412
loss is Autograd FloatNode with value -110.700584215 and 1 tape(s)
loss is -108.104032353
Iteration 263 lower bound -113.003808359
loss is Autograd FloatNode with value -112.287078856 and 1 tape(s)
loss is -123.848500146
Iteration 264 lower bound -97.4653074244
loss is Autograd FloatNode with value -114.853528815 and 1 tape(s)
loss is -107.383785959
Iteration 265 lower bound -114.254178485
loss is Autograd FloatNode with value -115.576946466 and 1 tape(s)
loss is -121.4697818
Iteration 266 lower bound -100.49184986
loss is Autograd FloatNode with value -109.68097691 and 1 tape(s)
loss is -104.842955471
Iteration 267 lower bound -117.388573855
loss is Autograd FloatNode with value -122.435806237 and 1 tape(s)
loss is -113.98777022
Iteration 268 lower bound -108.508819961
loss is Autograd FloatNode with value -110.554776525 and 1 tape(s)
loss is -117.971297554
Iteration 269 lower bound -104.655566266
loss is Autograd FloatNode with value -104.45428964 and 1 tape(s)
loss is -113.310468265
Iteration 270 lower bound -109.358532035
loss is Autograd FloatNode with value -104.437513773 and 1 tape(s)
loss is -114.65231306
Iteration 271 lower bound -108.125611161
loss is Autograd FloatNode with value -125.725811249 and 1 tape(s)
loss is -110.963381768
Iteration 272 lower bound -111.978902741
loss is Autograd FloatNode with value -126.963966232 and 1 tape(s)
loss is -107.406114187
Iteration 273 lower bound -115.293445548
loss is Autograd FloatNode with value -109.905948672 and 1 tape(s)
loss is -105.100421475
Iteration 274 lower bound -117.0222931
loss is Autograd FloatNode with value -103.980294031 and 1 tape(s)
loss is -103.171277457
Iteration 275 lower bound -118.567448452
loss is Autograd FloatNode with value -116.202448583 and 1 tape(s)
loss is -105.437863654
Iteration 276 lower bound -116.00054436
loss is Autograd FloatNode with value -102.640753671 and 1 tape(s)
loss is -93.2246003148
Iteration 277 lower bound -127.971931432
loss is Autograd FloatNode with value -98.9953739172 and 1 tape(s)
loss is -104.508699185
Iteration 278 lower bound -116.538237482
loss is Autograd FloatNode with value -109.853193995 and 1 tape(s)
loss is -109.800203656
Iteration 279 lower bound -111.410206096
loss is Autograd FloatNode with value -112.440477497 and 1 tape(s)
loss is -114.359824821
Iteration 280 lower bound -107.080001329
loss is Autograd FloatNode with value -96.264090399 and 1 tape(s)
loss is -102.309382917
Iteration 281 lower bound -119.471123505
loss is Autograd FloatNode with value -110.122251873 and 1 tape(s)
loss is -101.514432422
Iteration 282 lower bound -120.85003459
loss is Autograd FloatNode with value -105.825167906 and 1 tape(s)
loss is -107.419246027
Iteration 283 lower bound -115.528041523
loss is Autograd FloatNode with value -103.677048908 and 1 tape(s)
loss is -101.727335197
Iteration 284 lower bound -121.79245527
loss is Autograd FloatNode with value -101.703771836 and 1 tape(s)
loss is -98.8419909365
Iteration 285 lower bound -125.372299647
loss is Autograd FloatNode with value -109.86374035 and 1 tape(s)
loss is -100.831909154
Iteration 286 lower bound -124.231840574
loss is Autograd FloatNode with value -101.163050162 and 1 tape(s)
loss is -110.409819929
Iteration 287 lower bound -115.569981505
loss is Autograd FloatNode with value -104.875556072 and 1 tape(s)
loss is -119.804399567
Iteration 288 lower bound -107.269809348
loss is Autograd FloatNode with value -100.910698252 and 1 tape(s)
loss is -110.79523694
Iteration 289 lower bound -117.261796883
loss is Autograd FloatNode with value -102.730905968 and 1 tape(s)
loss is -127.273664548
Iteration 290 lower bound -101.923370999
loss is Autograd FloatNode with value -104.455658373 and 1 tape(s)
loss is -106.002885205
Iteration 291 lower bound -124.331564299
loss is Autograd FloatNode with value -117.328338287 and 1 tape(s)
loss is -112.411014671
Iteration 292 lower bound -118.983360227
loss is Autograd FloatNode with value -107.109436314 and 1 tape(s)
loss is -148.104582761
Iteration 293 lower bound -83.9837552393
loss is Autograd FloatNode with value -116.687729588 and 1 tape(s)
loss is -115.550320374
Iteration 294 lower bound -117.058192984
loss is Autograd FloatNode with value -111.528236092 and 1 tape(s)
loss is -102.589506272
Iteration 295 lower bound -130.366179463
loss is Autograd FloatNode with value -105.580181954 and 1 tape(s)
loss is -104.897666506
Iteration 296 lower bound -128.457271972
loss is Autograd FloatNode with value -103.04105336 and 1 tape(s)
loss is -109.527819439
Iteration 297 lower bound -124.391353196
loss is Autograd FloatNode with value -113.795532115 and 1 tape(s)
loss is -107.201919926
Iteration 298 lower bound -127.345980341
loss is Autograd FloatNode with value -109.55513744 and 1 tape(s)
loss is -104.598360182
Iteration 299 lower bound -130.49396151
loss is Autograd FloatNode with value -108.113525452 and 1 tape(s)
loss is -106.60877366
Iteration 300 lower bound -129.007748675
loss is Autograd FloatNode with value -111.104266274 and 1 tape(s)
loss is -110.337546672
Iteration 301 lower bound -125.779576165
loss is Autograd FloatNode with value -118.254776471 and 1 tape(s)
loss is -103.860651493
Iteration 302 lower bound -132.71118735
loss is Autograd FloatNode with value -112.115162811 and 1 tape(s)
loss is -100.305254198
Iteration 303 lower bound -136.511963333
loss is Autograd FloatNode with value -108.475799873 and 1 tape(s)
loss is -131.339105309
Iteration 304 lower bound -105.587405141
loss is Autograd FloatNode with value -103.846617376 and 1 tape(s)
loss is -106.372300525
Iteration 305 lower bound -130.750394287
loss is Autograd FloatNode with value -112.966462421 and 1 tape(s)
loss is -115.969452068
Iteration 306 lower bound -121.463174927
loss is Autograd FloatNode with value -104.8763055 and 1 tape(s)
loss is -112.027316435
Iteration 307 lower bound -125.733437603
loss is Autograd FloatNode with value -109.191731098 and 1 tape(s)
loss is -111.253072876
Iteration 308 lower bound -126.872120572
loss is Autograd FloatNode with value -107.922340024 and 1 tape(s)
loss is -112.627095012
Iteration 309 lower bound -125.910476312
loss is Autograd FloatNode with value -116.195809399 and 1 tape(s)
loss is -108.492780124
Iteration 310 lower bound -130.354309148
loss is Autograd FloatNode with value -112.122793294 and 1 tape(s)
loss is -108.115887218
Iteration 311 lower bound -131.046723603
loss is Autograd FloatNode with value -107.008794584 and 1 tape(s)
loss is -116.700271443
Iteration 312 lower bound -122.581389382
loss is Autograd FloatNode with value -123.886624754 and 1 tape(s)
loss is -121.387794363
Iteration 313 lower bound -118.194128057
loss is Autograd FloatNode with value -131.683572168 and 1 tape(s)
loss is -132.111279911
Iteration 314 lower bound -107.745285406
loss is Autograd FloatNode with value -99.4824967683 and 1 tape(s)
loss is -116.647907616
Iteration 315 lower bound -122.818229067
loss is Autograd FloatNode with value -116.88697363 and 1 tape(s)
loss is -120.197057477
Iteration 316 lower bound -119.091658812
loss is Autograd FloatNode with value -113.934902274 and 1 tape(s)
loss is -121.58040985
Iteration 317 lower bound -117.551997343
loss is Autograd FloatNode with value -110.67787261 and 1 tape(s)
loss is -110.691753662
Iteration 318 lower bound -128.451442098
loss is Autograd FloatNode with value -113.706491295 and 1 tape(s)
loss is -105.144387697
Iteration 319 lower bound -133.995338079
loss is Autograd FloatNode with value -116.865969492 and 1 tape(s)
loss is -120.321001566
Iteration 320 lower bound -118.774904427
loss is Autograd FloatNode with value -117.59921395 and 1 tape(s)
loss is -120.482154102
Iteration 321 lower bound -118.672131473
loss is Autograd FloatNode with value -101.337831365 and 1 tape(s)
loss is -100.647265694
Iteration 322 lower bound -138.681926451
loss is Autograd FloatNode with value -109.078259783 and 1 tape(s)
loss is -110.119294305
Iteration 323 lower bound -129.60002108
loss is Autograd FloatNode with value -106.910882377 and 1 tape(s)
loss is -110.460359348
Iteration 324 lower bound -129.712563439
loss is Autograd FloatNode with value -106.775153959 and 1 tape(s)
loss is -107.431871473
Iteration 325 lower bound -133.365010129
loss is Autograd FloatNode with value -107.861361852 and 1 tape(s)
loss is -113.46874273
Iteration 326 lower bound -128.083233434
loss is Autograd FloatNode with value -107.013859903 and 1 tape(s)
loss is -107.978409005
Iteration 327 lower bound -134.411561788
loss is Autograd FloatNode with value -117.173499338 and 1 tape(s)
loss is -113.850960748
Iteration 328 lower bound -129.510257373
loss is Autograd FloatNode with value -110.95317104 and 1 tape(s)
loss is -116.094554746
Iteration 329 lower bound -128.29284486
loss is Autograd FloatNode with value -123.204436067 and 1 tape(s)
loss is -107.905796794
Iteration 330 lower bound -137.518837671
loss is Autograd FloatNode with value -119.321380367 and 1 tape(s)
loss is -134.128672738
Iteration 331 lower bound -111.93337419
loss is Autograd FloatNode with value -114.139509038 and 1 tape(s)
loss is -113.703862567
Iteration 332 lower bound -133.048414252
loss is Autograd FloatNode with value -120.033478686 and 1 tape(s)
loss is -126.090933736
Iteration 333 lower bound -121.399142706
loss is Autograd FloatNode with value -115.401966156 and 1 tape(s)
loss is -103.530602852
Iteration 334 lower bound -144.759817178
loss is Autograd FloatNode with value -111.388436308 and 1 tape(s)
loss is -113.636800797
Iteration 335 lower bound -135.384862152
loss is Autograd FloatNode with value -116.198661571 and 1 tape(s)
loss is -116.022860014
Iteration 336 lower bound -133.676568301
loss is Autograd FloatNode with value -132.186797956 and 1 tape(s)
loss is -99.8644084114
Iteration 337 lower bound -150.040325958
loss is Autograd FloatNode with value -119.814984749 and 1 tape(s)
loss is -110.030370959
Iteration 338 lower bound -139.517576612
loss is Autograd FloatNode with value -111.819015973 and 1 tape(s)
loss is -104.616921309
Iteration 339 lower bound -144.59695684
loss is Autograd FloatNode with value -115.870647254 and 1 tape(s)
loss is -111.178030392
Iteration 340 lower bound -137.756964207
loss is Autograd FloatNode with value -110.217727873 and 1 tape(s)
loss is -125.398977692
Iteration 341 lower bound -123.187394925
loss is Autograd FloatNode with value -114.099036146 and 1 tape(s)
loss is -113.913041726
Iteration 342 lower bound -134.543661133
loss is Autograd FloatNode with value -105.656718134 and 1 tape(s)
loss is -117.235080582
Iteration 343 lower bound -131.220564403
loss is Autograd FloatNode with value -108.780181481 and 1 tape(s)
loss is -108.12841074
Iteration 344 lower bound -140.416548878
loss is Autograd FloatNode with value -118.041429939 and 1 tape(s)
loss is -117.453859936
Iteration 345 lower bound -131.1838989
loss is Autograd FloatNode with value -114.53620353 and 1 tape(s)
loss is -105.887750745
Iteration 346 lower bound -142.849922284
loss is Autograd FloatNode with value -109.857620979 and 1 tape(s)
loss is -112.970522739
Iteration 347 lower bound -135.853399672
loss is Autograd FloatNode with value -101.829276795 and 1 tape(s)
loss is -111.785917869
Iteration 348 lower bound -137.086488429
loss is Autograd FloatNode with value -112.520082226 and 1 tape(s)
loss is -104.773925474
Iteration 349 lower bound -144.250484357
loss is Autograd FloatNode with value -97.4664460875 and 1 tape(s)
loss is -107.407476956
Iteration 350 lower bound -141.727636329
loss is Autograd FloatNode with value -115.151941446 and 1 tape(s)
loss is -111.440115107
Iteration 351 lower bound -138.011555606
loss is Autograd FloatNode with value -118.463048662 and 1 tape(s)
loss is -108.030253477
Iteration 352 lower bound -141.638749348
loss is Autograd FloatNode with value -113.752581418 and 1 tape(s)
loss is -106.288829673
Iteration 353 lower bound -143.503986061
loss is Autograd FloatNode with value -120.938946921 and 1 tape(s)
loss is -129.810387314
Iteration 354 lower bound -119.819763122
loss is Autograd FloatNode with value -212.575037377 and 1 tape(s)
loss is -106.714683747
Iteration 355 lower bound -142.747889596
loss is Autograd FloatNode with value -112.187256731 and 1 tape(s)
loss is -101.42246218
Iteration 356 lower bound -148.437830338
loss is Autograd FloatNode with value -103.576071416 and 1 tape(s)
loss is -106.360992871
Iteration 357 lower bound -143.806103758
loss is Autograd FloatNode with value -105.574692937 and 1 tape(s)
loss is -109.810021207
Iteration 358 lower bound -140.741411451
loss is Autograd FloatNode with value -140.157464737 and 1 tape(s)
loss is -116.280996153
Iteration 359 lower bound -134.66391013
loss is Autograd FloatNode with value -108.486452621 and 1 tape(s)
loss is -104.884150682
Iteration 360 lower bound -146.852604195
loss is Autograd FloatNode with value -130.675039591 and 1 tape(s)
loss is -243.973000002
Iteration 361 lower bound -8.45371535856
loss is Autograd FloatNode with value -170.042120555 and 1 tape(s)
loss is -139.531464291
Iteration 362 lower bound -113.023870504
loss is Autograd FloatNode with value -147.02000572 and 1 tape(s)
loss is -139.558095416
Iteration 363 lower bound -112.934800024
loss is Autograd FloatNode with value -119.9510469 and 1 tape(s)
loss is -103.486235677
Iteration 364 lower bound -148.955170086
loss is Autograd FloatNode with value -123.112522128 and 1 tape(s)
loss is -173.4705485
Iteration 365 lower bound -78.6416519
loss is Autograd FloatNode with value -111.827011869 and 1 tape(s)
loss is -128.403072352
Iteration 366 lower bound -123.112356096
loss is Autograd FloatNode with value -107.198153472 and 1 tape(s)
loss is -130.572149554
Iteration 367 lower bound -120.470377024
loss is Autograd FloatNode with value -101.556270108 and 1 tape(s)
loss is -105.960613508
Iteration 368 lower bound -144.808594334
loss is Autograd FloatNode with value -106.401179493 and 1 tape(s)
loss is -113.540572382
Iteration 369 lower bound -137.185083942
loss is Autograd FloatNode with value -114.151352881 and 1 tape(s)
loss is -109.110641501
Iteration 370 lower bound -141.610594139
loss is Autograd FloatNode with value -106.887162101 and 1 tape(s)
loss is -112.997319861
Iteration 371 lower bound -137.763786639
loss is Autograd FloatNode with value -131.108258228 and 1 tape(s)
loss is -119.246505089
Iteration 372 lower bound -131.491077518
loss is Autograd FloatNode with value -112.779022478 and 1 tape(s)
loss is -107.202358535
Iteration 373 lower bound -142.808513321
loss is Autograd FloatNode with value -111.416221693 and 1 tape(s)
loss is -103.777515329
Iteration 374 lower bound -145.454504247
loss is Autograd FloatNode with value -98.6588870406 and 1 tape(s)
loss is -96.8364783565
Iteration 375 lower bound -151.664349875
loss is Autograd FloatNode with value -112.573416469 and 1 tape(s)
loss is -110.87086961
Iteration 376 lower bound -137.131995802
loss is Autograd FloatNode with value -113.673529525 and 1 tape(s)
loss is -104.624486902
Iteration 377 lower bound -142.953625264
loss is Autograd FloatNode with value -101.845955361 and 1 tape(s)
loss is -107.182996534
Iteration 378 lower bound -140.079443612
loss is Autograd FloatNode with value -112.621317791 and 1 tape(s)
loss is -112.491567028
Iteration 379 lower bound -134.650651285
loss is Autograd FloatNode with value -127.25415771 and 1 tape(s)
loss is -111.636013161
Iteration 380 lower bound -135.470052256
loss is Autograd FloatNode with value -107.837340382 and 1 tape(s)
loss is -130.523444818
Iteration 381 lower bound -116.665228597
loss is Autograd FloatNode with value -106.559819297 and 1 tape(s)
loss is -113.615676958
Iteration 382 lower bound -133.577908585
loss is Autograd FloatNode with value -119.026114343 and 1 tape(s)
loss is -108.654996386
Iteration 383 lower bound -138.483088975
loss is Autograd FloatNode with value -115.468723288 and 1 tape(s)
loss is -108.878879358
Iteration 384 lower bound -138.066246618
loss is Autograd FloatNode with value -109.270945242 and 1 tape(s)
loss is -106.050142323
Iteration 385 lower bound -140.605923262
loss is Autograd FloatNode with value -118.220114474 and 1 tape(s)
loss is -105.537789125
Iteration 386 lower bound -141.050895119
loss is Autograd FloatNode with value -120.598675416 and 1 tape(s)
loss is -102.983949717
Iteration 387 lower bound -143.613383402
loss is Autograd FloatNode with value -116.095637534 and 1 tape(s)
loss is -110.165608508
Iteration 388 lower bound -136.328934035
loss is Autograd FloatNode with value -100.372453329 and 1 tape(s)
loss is -103.609159749
Iteration 389 lower bound -142.784020726
loss is Autograd FloatNode with value -104.184624256 and 1 tape(s)
loss is -111.088015593
Iteration 390 lower bound -135.408650799
loss is Autograd FloatNode with value -106.063486981 and 1 tape(s)
loss is -114.633426628
Iteration 391 lower bound -132.200137645
loss is Autograd FloatNode with value -104.448868796 and 1 tape(s)
loss is -108.199331084
Iteration 392 lower bound -138.981002926
loss is Autograd FloatNode with value -114.931381897 and 1 tape(s)
loss is -109.543830148
Iteration 393 lower bound -138.062326885
loss is Autograd FloatNode with value -123.035577748 and 1 tape(s)
loss is -105.766648528
Iteration 394 lower bound -142.19819088
loss is Autograd FloatNode with value -109.090883098 and 1 tape(s)
loss is -101.482828708
Iteration 395 lower bound -146.534610327
loss is Autograd FloatNode with value -106.409435232 and 1 tape(s)
loss is -107.887003407
Iteration 396 lower bound -140.092167186
loss is Autograd FloatNode with value -107.996045785 and 1 tape(s)
loss is -120.748985549
Iteration 397 lower bound -127.322195881
loss is Autograd FloatNode with value -94.2557134996 and 1 tape(s)
loss is -108.975452754
Iteration 398 lower bound -139.268635242
loss is Autograd FloatNode with value -119.019387387 and 1 tape(s)
loss is -106.771421637
Iteration 399 lower bound -141.898806884
loss is Autograd FloatNode with value -107.873155468 and 1 tape(s)
loss is -112.08692115
Iteration 400 lower bound -136.799744711
loss is Autograd FloatNode with value -104.890916543 and 1 tape(s)
loss is -105.69280119
Iteration 401 lower bound -143.502291464
loss is Autograd FloatNode with value -109.181734515 and 1 tape(s)
loss is -110.057554894
Iteration 402 lower bound -139.525903363
loss is Autograd FloatNode with value -107.741109946 and 1 tape(s)
loss is -105.123432154
Iteration 403 lower bound -144.862927039
loss is Autograd FloatNode with value -108.187111034 and 1 tape(s)
loss is -106.674715451
Iteration 404 lower bound -143.830306545
loss is Autograd FloatNode with value -101.681279279 and 1 tape(s)
loss is -110.892909849
Iteration 405 lower bound -140.081450626
loss is Autograd FloatNode with value -107.576305844 and 1 tape(s)
loss is -106.409220259
Iteration 406 lower bound -145.108988714
loss is Autograd FloatNode with value -110.330687323 and 1 tape(s)
loss is -114.096182994
Iteration 407 lower bound -138.02124147
loss is Autograd FloatNode with value -117.467362896 and 1 tape(s)
loss is -95.629866287
Iteration 408 lower bound -157.129371896
loss is Autograd FloatNode with value -106.407191772 and 1 tape(s)
loss is -103.394857894
Iteration 409 lower bound -149.655135024
loss is Autograd FloatNode with value -124.015212347 and 1 tape(s)
loss is -111.29933116
Iteration 410 lower bound -142.0802037
loss is Autograd FloatNode with value -99.6798090533 and 1 tape(s)
loss is -101.881150381
Iteration 411 lower bound -151.686464559
loss is Autograd FloatNode with value -119.352732623 and 1 tape(s)
loss is -105.550105698
Iteration 412 lower bound -148.351094918
loss is Autograd FloatNode with value -103.470966491 and 1 tape(s)
loss is -106.488300928
Iteration 413 lower bound -147.631717056
loss is Autograd FloatNode with value -104.903781636 and 1 tape(s)
loss is -103.049683988
Iteration 414 lower bound -151.373102628
loss is Autograd FloatNode with value -104.489336347 and 1 tape(s)
loss is -106.894835161
Iteration 415 lower bound -147.778349097
loss is Autograd FloatNode with value -103.523973716 and 1 tape(s)
loss is -103.55000881
Iteration 416 lower bound -151.519715771
loss is Autograd FloatNode with value -125.256927799 and 1 tape(s)
loss is -116.748447891
Iteration 417 lower bound -138.789587736
loss is Autograd FloatNode with value -117.397655795 and 1 tape(s)
loss is -111.080039464
Iteration 418 lower bound -144.616978511
loss is Autograd FloatNode with value -115.379762324 and 1 tape(s)
loss is -122.900521346
Iteration 419 lower bound -132.857783162
loss is Autograd FloatNode with value -111.638398085 and 1 tape(s)
loss is -112.486709507
Iteration 420 lower bound -143.277196307
loss is Autograd FloatNode with value -104.456521461 and 1 tape(s)
loss is -106.243374774
Iteration 421 lower bound -149.614984931
loss is Autograd FloatNode with value -105.151156752 and 1 tape(s)
loss is -104.91378825
Iteration 422 lower bound -151.128954978
loss is Autograd FloatNode with value -111.083958238 and 1 tape(s)
loss is -113.087417252
Iteration 423 lower bound -143.187168078
loss is Autograd FloatNode with value -112.15516367 and 1 tape(s)
loss is -102.967208018
Iteration 424 lower bound -153.66932155
loss is Autograd FloatNode with value -108.57429395 and 1 tape(s)
loss is -109.315601607
Iteration 425 lower bound -147.70774509
loss is Autograd FloatNode with value -109.267000699 and 1 tape(s)
loss is -110.920061974
Iteration 426 lower bound -146.436082941
loss is Autograd FloatNode with value -113.100963327 and 1 tape(s)
loss is -111.997576699
Iteration 427 lower bound -145.69974729
loss is Autograd FloatNode with value -100.578929649 and 1 tape(s)
loss is -114.326878131
Iteration 428 lower bound -143.619857001
loss is Autograd FloatNode with value -105.557840142 and 1 tape(s)
loss is -105.197981948
Iteration 429 lower bound -153.098176439
loss is Autograd FloatNode with value -110.371976766 and 1 tape(s)
loss is -110.90096015
Iteration 430 lower bound -147.833958727
loss is Autograd FloatNode with value -108.502477098 and 1 tape(s)
loss is -115.618447046
Iteration 431 lower bound -143.626200551
loss is Autograd FloatNode with value -141.767809118 and 1 tape(s)
loss is -105.239555077
Iteration 432 lower bound -154.477869762
loss is Autograd FloatNode with value -105.416784658 and 1 tape(s)
loss is -106.02050954
Iteration 433 lower bound -153.430965794
loss is Autograd FloatNode with value -112.900378401 and 1 tape(s)
loss is -108.299755406
Iteration 434 lower bound -150.957264487
loss is Autograd FloatNode with value -105.643923872 and 1 tape(s)
loss is -111.404559785
Iteration 435 lower bound -147.655000625
loss is Autograd FloatNode with value -112.845693077 and 1 tape(s)
loss is -110.095902141
Iteration 436 lower bound -148.893369905
loss is Autograd FloatNode with value -110.036847629 and 1 tape(s)
loss is -101.9580317
Iteration 437 lower bound -157.08790441
loss is Autograd FloatNode with value -107.14279567 and 1 tape(s)
loss is -110.536528585
Iteration 438 lower bound -148.578369783
loss is Autograd FloatNode with value -106.420023216 and 1 tape(s)
loss is -124.7976351
Iteration 439 lower bound -134.410404487
loss is Autograd FloatNode with value -117.899481307 and 1 tape(s)
loss is -121.384684282
Iteration 440 lower bound -137.932942427
loss is Autograd FloatNode with value -105.81007876 and 1 tape(s)
loss is -115.87776802
Iteration 441 lower bound -143.449541487
loss is Autograd FloatNode with value -103.598024335 and 1 tape(s)
loss is -112.199492247
Iteration 442 lower bound -147.129461662
loss is Autograd FloatNode with value -110.642862628 and 1 tape(s)
loss is -121.8629062
Iteration 443 lower bound -137.670215727
loss is Autograd FloatNode with value -105.118507365 and 1 tape(s)
loss is -104.035220078
Iteration 444 lower bound -155.703426565
loss is Autograd FloatNode with value -111.263376527 and 1 tape(s)
loss is -122.354053328
Iteration 445 lower bound -137.625989518
loss is Autograd FloatNode with value -115.050844658 and 1 tape(s)
loss is -121.408523114
Iteration 446 lower bound -138.809725888
loss is Autograd FloatNode with value -103.327047834 and 1 tape(s)
loss is -99.9410404414
Iteration 447 lower bound -160.445151696
loss is Autograd FloatNode with value -107.858012475 and 1 tape(s)
loss is -106.719510686
Iteration 448 lower bound -153.94669638
loss is Autograd FloatNode with value -124.391414941 and 1 tape(s)
loss is -118.043901625
Iteration 449 lower bound -142.92044693
loss is Autograd FloatNode with value -104.191052928 and 1 tape(s)
loss is -111.285647303
Iteration 450 lower bound -149.792918406
loss is Autograd FloatNode with value -106.594702501 and 1 tape(s)
loss is -106.329972292
Iteration 451 lower bound -154.943206006
loss is Autograd FloatNode with value -103.62429243 and 1 tape(s)
loss is -102.034551842
Iteration 452 lower bound -159.44907865
loss is Autograd FloatNode with value -99.6281200848 and 1 tape(s)
loss is -107.589312022
Iteration 453 lower bound -154.198365532
loss is Autograd FloatNode with value -100.19841517 and 1 tape(s)
loss is -112.988489734
Iteration 454 lower bound -149.219836006
loss is Autograd FloatNode with value -109.156557786 and 1 tape(s)
loss is -99.053982515
Iteration 455 lower bound -163.759884069
loss is Autograd FloatNode with value -115.057356981 and 1 tape(s)
loss is -98.7158893294
Iteration 456 lower bound -164.591174544
loss is Autograd FloatNode with value -117.82782354 and 1 tape(s)
loss is -111.364534419
Iteration 457 lower bound -152.098373502
loss is Autograd FloatNode with value -104.865183133 and 1 tape(s)
loss is -122.542322105
Iteration 458 lower bound -140.79207559
loss is Autograd FloatNode with value -108.249756216 and 1 tape(s)
loss is -115.316915501
Iteration 459 lower bound -147.924465663
loss is Autograd FloatNode with value -107.338237136 and 1 tape(s)
loss is -104.45101336
Iteration 460 lower bound -158.75829011
loss is Autograd FloatNode with value -98.1399965314 and 1 tape(s)
loss is -102.207194696
Iteration 461 lower bound -161.042094224
loss is Autograd FloatNode with value -108.00051126 and 1 tape(s)
loss is -106.666816912
Iteration 462 lower bound -156.753910811
loss is Autograd FloatNode with value -104.674646595 and 1 tape(s)
loss is -135.06711003
Iteration 463 lower bound -128.64023364
loss is Autograd FloatNode with value -111.83710457 and 1 tape(s)
loss is -117.421891244
Iteration 464 lower bound -146.679226986
loss is Autograd FloatNode with value -108.882675653 and 1 tape(s)
loss is -103.260265048
Iteration 465 lower bound -161.065376749
loss is Autograd FloatNode with value -101.716897486 and 1 tape(s)
loss is -112.027955743
Iteration 466 lower bound -152.51499144
loss is Autograd FloatNode with value -96.2948059646 and 1 tape(s)
loss is -113.472186593
Iteration 467 lower bound -151.481195565
loss is Autograd FloatNode with value -103.219828145 and 1 tape(s)
loss is -109.585757518
Iteration 468 lower bound -156.003984053
loss is Autograd FloatNode with value -101.693634599 and 1 tape(s)
loss is -112.78837397
Iteration 469 lower bound -153.53635114
loss is Autograd FloatNode with value -122.605203315 and 1 tape(s)
loss is -107.364743361
Iteration 470 lower bound -159.790238761
loss is Autograd FloatNode with value -116.951429139 and 1 tape(s)
loss is -126.029092364
Iteration 471 lower bound -141.614600023
loss is Autograd FloatNode with value -113.317869158 and 1 tape(s)
loss is -108.916481065
Iteration 472 lower bound -159.127967606
loss is Autograd FloatNode with value -114.097277563 and 1 tape(s)
loss is -104.284955831
Iteration 473 lower bound -163.976204736
loss is Autograd FloatNode with value -109.614735334 and 1 tape(s)
loss is -105.675165824
Iteration 474 lower bound -162.715488898
loss is Autograd FloatNode with value -113.144391307 and 1 tape(s)
loss is -138.807857807
Iteration 475 lower bound -129.709915221
loss is Autograd FloatNode with value -108.903810201 and 1 tape(s)
loss is -104.975860565
Iteration 476 lower bound -163.735718435
loss is Autograd FloatNode with value -105.479081843 and 1 tape(s)
loss is -108.035896865
Iteration 477 lower bound -160.911900177
loss is Autograd FloatNode with value -131.620202852 and 1 tape(s)
loss is -127.613326949
Iteration 478 lower bound -141.563393793
loss is Autograd FloatNode with value -100.083491858 and 1 tape(s)
loss is -110.500726579
Iteration 479 lower bound -158.612014345
loss is Autograd FloatNode with value -110.934928987 and 1 tape(s)
loss is -109.981297543
Iteration 480 lower bound -159.160890083
loss is Autograd FloatNode with value -108.389792293 and 1 tape(s)
loss is -138.40556602
Iteration 481 lower bound -130.750825842
loss is Autograd FloatNode with value -107.679045171 and 1 tape(s)
loss is -117.525075025
Iteration 482 lower bound -151.744123532
loss is Autograd FloatNode with value -107.550721215 and 1 tape(s)
loss is -116.626260337
Iteration 483 lower bound -152.688302893
loss is Autograd FloatNode with value -111.186418875 and 1 tape(s)
loss is -103.523192786
Iteration 484 lower bound -165.838449712
loss is Autograd FloatNode with value -111.606765154 and 1 tape(s)
loss is -110.244863402
Iteration 485 lower bound -159.107242126
loss is Autograd FloatNode with value -113.983633219 and 1 tape(s)
loss is -99.810126867
Iteration 486 lower bound -169.427356003
loss is Autograd FloatNode with value -112.808686833 and 1 tape(s)
loss is -107.262354332
Iteration 487 lower bound -161.739091304
loss is Autograd FloatNode with value -115.322059426 and 1 tape(s)
loss is -108.25243077
Iteration 488 lower bound -160.416298206
loss is Autograd FloatNode with value -110.632028511 and 1 tape(s)
loss is -111.704664639
Iteration 489 lower bound -156.490756341
loss is Autograd FloatNode with value -101.720802633 and 1 tape(s)
loss is -115.681997032
Iteration 490 lower bound -152.099133153
loss is Autograd FloatNode with value -106.502584319 and 1 tape(s)
loss is -113.12783795
Iteration 491 lower bound -154.299884447
loss is Autograd FloatNode with value -105.840025517 and 1 tape(s)
loss is -108.943666102
Iteration 492 lower bound -158.125426001
loss is Autograd FloatNode with value -108.868857113 and 1 tape(s)
loss is -108.03844015
Iteration 493 lower bound -158.716196476
loss is Autograd FloatNode with value -119.681679163 and 1 tape(s)
loss is -111.147910771
Iteration 494 lower bound -155.393012954
loss is Autograd FloatNode with value -107.930148006 and 1 tape(s)
loss is -119.110776603
Iteration 495 lower bound -147.004286299
loss is Autograd FloatNode with value -104.391674835 and 1 tape(s)
loss is -105.094222125
Iteration 496 lower bound -160.815342399
loss is Autograd FloatNode with value -108.534977348 and 1 tape(s)
loss is -107.754447944
Iteration 497 lower bound -158.096267328
loss is Autograd FloatNode with value -107.506584371 and 1 tape(s)
loss is -112.434378367
Iteration 498 lower bound -153.453839553
loss is Autograd FloatNode with value -99.7802944547 and 1 tape(s)
loss is -96.7815707409
Iteration 499 lower bound -169.262115215
loss is Autograd FloatNode with value -115.466716546 and 1 tape(s)
loss is -111.043746859
Iteration 500 lower bound -155.310341852
loss is Autograd FloatNode with value -95.7018934016 and 1 tape(s)
loss is -102.711611569
Iteration 501 lower bound -163.715824795
loss is Autograd FloatNode with value -106.364482979 and 1 tape(s)
loss is -102.308690105
Iteration 502 lower bound -164.432416011
loss is Autograd FloatNode with value -106.370116681 and 1 tape(s)
loss is -108.861050033
Iteration 503 lower bound -158.235752245
loss is Autograd FloatNode with value -102.545161892 and 1 tape(s)
loss is -112.734361566
Iteration 504 lower bound -154.85292085
loss is Autograd FloatNode with value -112.958329093 and 1 tape(s)
loss is -119.87839639
Iteration 505 lower bound -148.304013842
loss is Autograd FloatNode with value -102.68552671 and 1 tape(s)
loss is -109.127765528
Iteration 506 lower bound -159.489756335
loss is Autograd FloatNode with value -110.88137354 and 1 tape(s)
loss is -106.275330283
Iteration 507 lower bound -162.904029117
loss is Autograd FloatNode with value -109.555747311 and 1 tape(s)
loss is -105.023480885
Iteration 508 lower bound -164.593939239
loss is Autograd FloatNode with value -104.176438868 and 1 tape(s)
loss is -105.875570083
Iteration 509 lower bound -164.124641146
loss is Autograd FloatNode with value -106.990018368 and 1 tape(s)
loss is -107.158110739
Iteration 510 lower bound -163.242809612
loss is Autograd FloatNode with value -109.302957854 and 1 tape(s)
loss is -114.137091834
Iteration 511 lower bound -156.694118074
loss is Autograd FloatNode with value -110.223787108 and 1 tape(s)
loss is -111.636637109
Iteration 512 lower bound -159.596172603
loss is Autograd FloatNode with value -121.630649677 and 1 tape(s)
loss is -109.654369349
Iteration 513 lower bound -161.915111972
loss is Autograd FloatNode with value -113.711111578 and 1 tape(s)
loss is -115.569810707
Iteration 514 lower bound -156.135814537
loss is Autograd FloatNode with value -118.136361631 and 1 tape(s)
loss is -115.785855708
Iteration 515 lower bound -156.095968359
loss is Autograd FloatNode with value -117.639395186 and 1 tape(s)
loss is -124.659006178
Iteration 516 lower bound -147.321783359
loss is Autograd FloatNode with value -117.135902407 and 1 tape(s)
loss is -147.853391952
Iteration 517 lower bound -124.207735585
loss is Autograd FloatNode with value -123.237799937 and 1 tape(s)
loss is -112.268406103
Iteration 518 lower bound -159.878411576
loss is Autograd FloatNode with value -112.544146154 and 1 tape(s)
loss is -135.878593245
Iteration 519 lower bound -136.03491111
loss is Autograd FloatNode with value -108.369724826 and 1 tape(s)
loss is -109.39386321
Iteration 520 lower bound -162.372763255
loss is Autograd FloatNode with value -108.727299044 and 1 tape(s)
loss is -110.843167814
Iteration 521 lower bound -160.795633706
loss is Autograd FloatNode with value -134.146546085 and 1 tape(s)
loss is -108.929926149
Iteration 522 lower bound -162.779826976
loss is Autograd FloatNode with value -103.155160062 and 1 tape(s)
loss is -118.450481686
Iteration 523 lower bound -152.723503618
loss is Autograd FloatNode with value -104.911746856 and 1 tape(s)
loss is -104.836137971
Iteration 524 lower bound -165.970244195
loss is Autograd FloatNode with value -118.63041551 and 1 tape(s)
loss is -140.2322081
Iteration 525 lower bound -130.329955008
loss is Autograd FloatNode with value -109.890091745 and 1 tape(s)
loss is -114.241836461
Iteration 526 lower bound -156.067585752
loss is Autograd FloatNode with value -103.568473916 and 1 tape(s)
loss is -108.226692086
Iteration 527 lower bound -161.965930442
loss is Autograd FloatNode with value -102.229238164 and 1 tape(s)
loss is -106.150174323
Iteration 528 lower bound -164.026061335
loss is Autograd FloatNode with value -101.191304361 and 1 tape(s)
loss is -156.40927524
Iteration 529 lower bound -113.846050029
loss is Autograd FloatNode with value -104.606344018 and 1 tape(s)
loss is -96.4896604803
Iteration 530 lower bound -173.974149852
loss is Autograd FloatNode with value -117.248296891 and 1 tape(s)
loss is -112.27738685
Iteration 531 lower bound -158.268155424
loss is Autograd FloatNode with value -106.908439486 and 1 tape(s)
loss is -99.190429572
Iteration 532 lower bound -171.240365047
loss is Autograd FloatNode with value -107.023296929 and 1 tape(s)
loss is -123.814890391
Iteration 533 lower bound -146.44737329
loss is Autograd FloatNode with value -103.216103968 and 1 tape(s)
loss is -104.655227754
Iteration 534 lower bound -165.520463057
loss is Autograd FloatNode with value -103.930245005 and 1 tape(s)
loss is -100.121869176
Iteration 535 lower bound -170.06841819
loss is Autograd FloatNode with value -121.012991052 and 1 tape(s)
loss is -106.53139274
Iteration 536 lower bound -163.751435671
loss is Autograd FloatNode with value -171.534652945 and 1 tape(s)
loss is -99.7640858432
Iteration 537 lower bound -170.378296356
loss is Autograd FloatNode with value -117.150204641 and 1 tape(s)
loss is -108.037632123
Iteration 538 lower bound -160.999094976
loss is Autograd FloatNode with value -107.986215043 and 1 tape(s)
loss is -100.846599492
Iteration 539 lower bound -167.104212358
loss is Autograd FloatNode with value -107.183867037 and 1 tape(s)
loss is -108.970429167
Iteration 540 lower bound -158.046732
loss is Autograd FloatNode with value -108.278817103 and 1 tape(s)
loss is -111.548044141
Iteration 541 lower bound -154.693610859
loss is Autograd FloatNode with value -113.197792127 and 1 tape(s)
loss is -107.259750553
Iteration 542 lower bound -158.404530616
loss is Autograd FloatNode with value -114.923979237 and 1 tape(s)
loss is -116.896279144
Iteration 543 lower bound -148.165174995
loss is Autograd FloatNode with value -109.955879712 and 1 tape(s)
loss is -103.051350745
Iteration 544 lower bound -161.319302635
loss is Autograd FloatNode with value -100.991458115 and 1 tape(s)
loss is -112.80971322
Iteration 545 lower bound -150.76117474
loss is Autograd FloatNode with value -118.086663017 and 1 tape(s)
loss is -111.293224951
Iteration 546 lower bound -151.712191412
loss is Autograd FloatNode with value -105.026778444 and 1 tape(s)
loss is -103.854772398
Iteration 547 lower bound -158.602273107
loss is Autograd FloatNode with value -112.053733197 and 1 tape(s)
loss is -105.351802369
Iteration 548 lower bound -156.648148875
loss is Autograd FloatNode with value -110.233123558 and 1 tape(s)
loss is -105.791912354
Iteration 549 lower bound -155.829274253
loss is Autograd FloatNode with value -118.854927835 and 1 tape(s)
loss is -114.595180368
Iteration 550 lower bound -146.848551122
loss is Autograd FloatNode with value -105.490263589 and 1 tape(s)
loss is -110.561481741
Iteration 551 lower bound -150.673811836
loss is Autograd FloatNode with value -112.084375167 and 1 tape(s)
loss is -114.403110813
Iteration 552 lower bound -146.833099503
loss is Autograd FloatNode with value -106.08287833 and 1 tape(s)
loss is -104.328989349
Iteration 553 lower bound -157.017924676
loss is Autograd FloatNode with value -122.190208239 and 1 tape(s)
loss is -115.967275163
Iteration 554 lower bound -145.67605964
loss is Autograd FloatNode with value -123.595123388 and 1 tape(s)
loss is -109.060531539
Iteration 555 lower bound -152.840711505
loss is Autograd FloatNode with value -112.867684661 and 1 tape(s)
loss is -118.668760101
Iteration 556 lower bound -143.410359232
loss is Autograd FloatNode with value -119.515579171 and 1 tape(s)
loss is -108.819419372
Iteration 557 lower bound -153.546915035
loss is Autograd FloatNode with value -113.858109369 and 1 tape(s)
loss is -106.988775253
Iteration 558 lower bound -155.649499745
loss is Autograd FloatNode with value -120.315928516 and 1 tape(s)
loss is -111.68729432
Iteration 559 lower bound -151.003714686
loss is Autograd FloatNode with value -127.98582735 and 1 tape(s)
loss is -114.29302149
Iteration 560 lower bound -148.340560345
loss is Autograd FloatNode with value -104.894820146 and 1 tape(s)
loss is -109.469327395
Iteration 561 lower bound -153.052554972
loss is Autograd FloatNode with value -104.638421992 and 1 tape(s)
loss is -105.723138273
Iteration 562 lower bound -156.910113041
loss is Autograd FloatNode with value -116.912352373 and 1 tape(s)
loss is -119.163144541
Iteration 563 lower bound -143.775924594
loss is Autograd FloatNode with value -104.658298763 and 1 tape(s)
loss is -101.115940464
Iteration 564 lower bound -162.163168567
loss is Autograd FloatNode with value -105.368909961 and 1 tape(s)
loss is -102.840848557
Iteration 565 lower bound -160.800932699
loss is Autograd FloatNode with value -105.153438265 and 1 tape(s)
loss is -115.673109299
Iteration 566 lower bound -148.476032161
loss is Autograd FloatNode with value -109.622924032 and 1 tape(s)
loss is -107.337870572
Iteration 567 lower bound -157.470234075
loss is Autograd FloatNode with value -106.041305263 and 1 tape(s)
loss is -102.430138952
Iteration 568 lower bound -163.160387043
loss is Autograd FloatNode with value -132.277009719 and 1 tape(s)
loss is -101.597540535
Iteration 569 lower bound -164.822308084
loss is Autograd FloatNode with value -110.825683123 and 1 tape(s)
loss is -116.515810038
Iteration 570 lower bound -150.372962706
loss is Autograd FloatNode with value -103.123167919 and 1 tape(s)
loss is -104.808149806
Iteration 571 lower bound -162.536743382
loss is Autograd FloatNode with value -107.623939408 and 1 tape(s)
loss is -102.387555201
Iteration 572 lower bound -165.596017863
loss is Autograd FloatNode with value -108.378873504 and 1 tape(s)
loss is -113.849797571
Iteration 573 lower bound -154.8448012
loss is Autograd FloatNode with value -114.534029652 and 1 tape(s)
loss is -114.975312638
Iteration 574 lower bound -154.478796211
loss is Autograd FloatNode with value -112.071780966 and 1 tape(s)
loss is -105.037963982
Iteration 575 lower bound -165.062524084
loss is Autograd FloatNode with value -109.381808249 and 1 tape(s)
loss is -143.591787821
Iteration 576 lower bound -126.985203632
loss is Autograd FloatNode with value -105.874664514 and 1 tape(s)
loss is -102.985779626
Iteration 577 lower bound -168.128784745
loss is Autograd FloatNode with value -108.676054675 and 1 tape(s)
loss is -126.258805251
Iteration 578 lower bound -145.35245783
loss is Autograd FloatNode with value -105.287807059 and 1 tape(s)
loss is -101.008096824
Iteration 579 lower bound -171.071659941
loss is Autograd FloatNode with value -113.180364129 and 1 tape(s)
loss is -110.841509239
Iteration 580 lower bound -161.750584974
loss is Autograd FloatNode with value -111.422567658 and 1 tape(s)
loss is -112.074300294
Iteration 581 lower bound -160.834491576
loss is Autograd FloatNode with value -108.945895596 and 1 tape(s)
loss is -116.201387325
Iteration 582 lower bound -156.948145179
loss is Autograd FloatNode with value -101.67373831 and 1 tape(s)
loss is -112.960412702
Iteration 583 lower bound -160.500388792
loss is Autograd FloatNode with value -126.837511554 and 1 tape(s)
loss is -113.111585968
Iteration 584 lower bound -160.745473449
loss is Autograd FloatNode with value -114.401455251 and 1 tape(s)
loss is -102.7976387
Iteration 585 lower bound -170.897244892
loss is Autograd FloatNode with value -103.379939506 and 1 tape(s)
loss is -108.054324672
Iteration 586 lower bound -165.441051216
loss is Autograd FloatNode with value -120.768180789 and 1 tape(s)
loss is -107.692581225
Iteration 587 lower bound -165.745003354
loss is Autograd FloatNode with value -103.072311972 and 1 tape(s)
loss is -112.242613169
Iteration 588 lower bound -161.002062299
loss is Autograd FloatNode with value -118.794137759 and 1 tape(s)
loss is -107.885174545
Iteration 589 lower bound -165.304931886
loss is Autograd FloatNode with value -112.66467544 and 1 tape(s)
loss is -122.70666374
Iteration 590 lower bound -150.182626002
loss is Autograd FloatNode with value -107.021946922 and 1 tape(s)
loss is -107.607497447
Iteration 591 lower bound -164.950264619
loss is Autograd FloatNode with value -117.505790829 and 1 tape(s)
loss is -117.852689699
Iteration 592 lower bound -154.510545019
loss is Autograd FloatNode with value -104.254970295 and 1 tape(s)
loss is -108.191425117
Iteration 593 lower bound -163.999247145
loss is Autograd FloatNode with value -108.78057262 and 1 tape(s)
loss is -132.306953373
Iteration 594 lower bound -139.821290972
loss is Autograd FloatNode with value -103.717524181 and 1 tape(s)
loss is -111.025555599
Iteration 595 lower bound -161.096314232
loss is Autograd FloatNode with value -117.622495066 and 1 tape(s)
loss is -111.394748906
Iteration 596 lower bound -160.778762853
loss is Autograd FloatNode with value -136.372075935 and 1 tape(s)
loss is -105.011216971
Iteration 597 lower bound -167.114441962
loss is Autograd FloatNode with value -108.38810551 and 1 tape(s)
loss is -106.518760145
Iteration 598 lower bound -165.191932944
loss is Autograd FloatNode with value -267.547234368 and 1 tape(s)
loss is -181.728523018
Iteration 599 lower bound -89.7391311505
loss is Autograd FloatNode with value -112.851215393 and 1 tape(s)
loss is -106.397612703
Iteration 600 lower bound -163.55624458
loss is Autograd FloatNode with value -108.046437731 and 1 tape(s)
loss is -107.732368816
Iteration 601 lower bound -160.940512597
loss is Autograd FloatNode with value -137.294741296 and 1 tape(s)
loss is -107.270364456
Iteration 602 lower bound -160.396949653
loss is Autograd FloatNode with value -104.888101907 and 1 tape(s)
loss is -103.901075359
Iteration 603 lower bound -162.249433625
loss is Autograd FloatNode with value -108.729184748 and 1 tape(s)
loss is -103.737639209
Iteration 604 lower bound -161.137927562
loss is Autograd FloatNode with value -106.905647291 and 1 tape(s)
loss is -99.1830427625
Iteration 605 lower bound -164.538812466
loss is Autograd FloatNode with value -111.477630651 and 1 tape(s)
loss is -100.270940906
Iteration 606 lower bound -162.482994777
loss is Autograd FloatNode with value -100.479421275 and 1 tape(s)
loss is -104.056206903
Iteration 607 lower bound -157.866992852
loss is Autograd FloatNode with value -101.468202724 and 1 tape(s)
loss is -106.280267468
Iteration 608 lower bound -155.060812506
loss is Autograd FloatNode with value -97.4719246995 and 1 tape(s)
loss is -100.844587721
Iteration 609 lower bound -160.140299155
loss is Autograd FloatNode with value -102.606272591 and 1 tape(s)
loss is -104.562816122
Iteration 610 lower bound -156.31416818
loss is Autograd FloatNode with value -101.916507552 and 1 tape(s)
loss is -101.87371478
Iteration 611 lower bound -159.055529241
loss is Autograd FloatNode with value -106.653970847 and 1 tape(s)
loss is -112.009515185
Iteration 612 lower bound -149.045023945
loss is Autograd FloatNode with value -101.170179687 and 1 tape(s)
loss is -103.743003019
Iteration 613 lower bound -157.466456549
loss is Autograd FloatNode with value -107.827180986 and 1 tape(s)
loss is -99.1249217967
Iteration 614 lower bound -162.351711078
loss is Autograd FloatNode with value -111.161237051 and 1 tape(s)
loss is -99.2638564262
Iteration 615 lower bound -162.460927716
loss is Autograd FloatNode with value -111.59136105 and 1 tape(s)
loss is -104.687947847
Iteration 616 lower bound -157.256989864
loss is Autograd FloatNode with value -104.180879734 and 1 tape(s)
loss is -122.080144592
Iteration 617 lower bound -140.099175972
loss is Autograd FloatNode with value -108.535558205 and 1 tape(s)
loss is -115.869981125
Iteration 618 lower bound -146.486182232
loss is Autograd FloatNode with value -114.225865263 and 1 tape(s)
loss is -110.383426834
Iteration 619 lower bound -152.162392957
loss is Autograd FloatNode with value -107.150410061 and 1 tape(s)
loss is -116.313471708
Iteration 620 lower bound -146.3214072
loss is Autograd FloatNode with value -106.352716157 and 1 tape(s)
loss is -111.339172037
Iteration 621 lower bound -151.541306186
loss is Autograd FloatNode with value -115.402385193 and 1 tape(s)
loss is -112.366456376
Iteration 622 lower bound -150.782636505
loss is Autograd FloatNode with value -113.299046829 and 1 tape(s)
loss is -109.127686334
Iteration 623 lower bound -154.267704035
loss is Autograd FloatNode with value -104.777347588 and 1 tape(s)
loss is -105.166564736
Iteration 624 lower bound -158.447845249
loss is Autograd FloatNode with value -103.24699282 and 1 tape(s)
loss is -104.747737539
Iteration 625 lower bound -159.189870373
loss is Autograd FloatNode with value -114.095781992 and 1 tape(s)
loss is -116.73389649
Iteration 626 lower bound -147.635384319
loss is Autograd FloatNode with value -104.28411668 and 1 tape(s)
loss is -105.796074639
Iteration 627 lower bound -158.998540184
loss is Autograd FloatNode with value -106.023168975 and 1 tape(s)
loss is -106.290832611
Iteration 628 lower bound -159.006915272
loss is Autograd FloatNode with value -99.9392884505 and 1 tape(s)
loss is -105.279199772
Iteration 629 lower bound -160.513503194
loss is Autograd FloatNode with value -105.353401135 and 1 tape(s)
loss is -99.3252962076
Iteration 630 lower bound -167.080465535
loss is Autograd FloatNode with value -106.23229673 and 1 tape(s)
loss is -101.406960654
Iteration 631 lower bound -165.569450438
loss is Autograd FloatNode with value -105.237361633 and 1 tape(s)
loss is -104.542266066
Iteration 632 lower bound -162.985116987
loss is Autograd FloatNode with value -103.893122011 and 1 tape(s)
loss is -117.787802918
Iteration 633 lower bound -150.324787327
loss is Autograd FloatNode with value -123.420717775 and 1 tape(s)
loss is -108.120266321
Iteration 634 lower bound -160.551694655
loss is Autograd FloatNode with value -115.596440142 and 1 tape(s)
loss is -108.395648244
Iteration 635 lower bound -160.552271361
loss is Autograd FloatNode with value -141.552668073 and 1 tape(s)
loss is -102.064007238
Iteration 636 lower bound -167.037910566
loss is Autograd FloatNode with value -105.998666786 and 1 tape(s)
loss is -113.528226382
Iteration 637 lower bound -155.186044019
loss is Autograd FloatNode with value -106.154223558 and 1 tape(s)
loss is -111.982973986
Iteration 638 lower bound -156.373751881
loss is Autograd FloatNode with value -95.5829703042 and 1 tape(s)
loss is -102.998932163
Iteration 639 lower bound -165.024720246
loss is Autograd FloatNode with value -111.460608874 and 1 tape(s)
loss is -130.136535768
Iteration 640 lower bound -137.760993513
loss is Autograd FloatNode with value -99.1679904899 and 1 tape(s)
loss is -104.161955103
Iteration 641 lower bound -163.652242333
loss is Autograd FloatNode with value -100.146722346 and 1 tape(s)
loss is -110.106002251
Iteration 642 lower bound -157.779900151
loss is Autograd FloatNode with value -110.127783129 and 1 tape(s)
loss is -114.614971348
Iteration 643 lower bound -153.503930075
loss is Autograd FloatNode with value -114.443105088 and 1 tape(s)
loss is -112.093038931
Iteration 644 lower bound -156.239223358
loss is Autograd FloatNode with value -106.624212225 and 1 tape(s)
loss is -102.477081137
Iteration 645 lower bound -165.960939679
loss is Autograd FloatNode with value -104.197778633 and 1 tape(s)
loss is -109.377306058
Iteration 646 lower bound -159.184259325
loss is Autograd FloatNode with value -112.939322814 and 1 tape(s)
loss is -110.525127894
Iteration 647 lower bound -158.199796048
loss is Autograd FloatNode with value -103.841406184 and 1 tape(s)
loss is -114.397332366
Iteration 648 lower bound -154.473892216
loss is Autograd FloatNode with value -100.336347732 and 1 tape(s)
loss is -108.792006358
Iteration 649 lower bound -160.268282042
loss is Autograd FloatNode with value -111.303195454 and 1 tape(s)
loss is -116.423890674
Iteration 650 lower bound -152.912635465
loss is Autograd FloatNode with value -103.706785702 and 1 tape(s)
loss is -113.392354116
Iteration 651 lower bound -156.409938497
loss is Autograd FloatNode with value -104.375837242 and 1 tape(s)
loss is -108.488403479
Iteration 652 lower bound -161.839251265
loss is Autograd FloatNode with value -101.810107937 and 1 tape(s)
loss is -123.69448082
Iteration 653 lower bound -147.153727472
loss is Autograd FloatNode with value -114.580076092 and 1 tape(s)
loss is -102.746170717
Iteration 654 lower bound -168.661878638
loss is Autograd FloatNode with value -100.220086121 and 1 tape(s)
loss is -109.325792553
Iteration 655 lower bound -162.674761478
loss is Autograd FloatNode with value -106.037862321 and 1 tape(s)
loss is -106.201897941
Iteration 656 lower bound -166.404780923
loss is Autograd FloatNode with value -109.546458837 and 1 tape(s)
loss is -105.98502573
Iteration 657 lower bound -167.262620613
loss is Autograd FloatNode with value -111.636189032 and 1 tape(s)
loss is -106.323186084
Iteration 658 lower bound -167.397824113
loss is Autograd FloatNode with value -105.869341077 and 1 tape(s)
loss is -107.040315803
Iteration 659 lower bound -167.100846835
loss is Autograd FloatNode with value -117.40798606 and 1 tape(s)
loss is -109.48154991
Iteration 660 lower bound -165.186600781
loss is Autograd FloatNode with value -104.189822021 and 1 tape(s)
loss is -113.035297159
Iteration 661 lower bound -161.937402828
loss is Autograd FloatNode with value -112.53364758 and 1 tape(s)
loss is -139.529933915
Iteration 662 lower bound -135.750277425
loss is Autograd FloatNode with value -104.202098097 and 1 tape(s)
loss is -114.122752426
Iteration 663 lower bound -161.428903751
loss is Autograd FloatNode with value -102.803181605 and 1 tape(s)
loss is -105.183293784
Iteration 664 lower bound -170.627764172
loss is Autograd FloatNode with value -107.669763394 and 1 tape(s)
loss is -119.101072891
Iteration 665 lower bound -157.043031635
loss is Autograd FloatNode with value -117.36617427 and 1 tape(s)
loss is -115.390332506
Iteration 666 lower bound -161.131483302
loss is Autograd FloatNode with value -113.932511299 and 1 tape(s)
loss is -113.656367134
Iteration 667 lower bound -163.279078664
loss is Autograd FloatNode with value -110.68363331 and 1 tape(s)
loss is -106.461635096
Iteration 668 lower bound -170.746782458
loss is Autograd FloatNode with value -115.895604297 and 1 tape(s)
loss is -117.931508488
Iteration 669 lower bound -159.414853872
loss is Autograd FloatNode with value -115.348477714 and 1 tape(s)
loss is -120.091902106
Iteration 670 lower bound -157.475002634
loss is Autograd FloatNode with value -112.23499711 and 1 tape(s)
loss is -120.610024785
Iteration 671 lower bound -157.084565485
loss is Autograd FloatNode with value -111.824298665 and 1 tape(s)
loss is -120.417948119
Iteration 672 lower bound -157.452112592
loss is Autograd FloatNode with value -104.023385116 and 1 tape(s)
loss is -112.506423183
Iteration 673 lower bound -165.594338074
loss is Autograd FloatNode with value -118.080641984 and 1 tape(s)
loss is -115.857953279
Iteration 674 lower bound -162.63649886
loss is Autograd FloatNode with value -112.443154563 and 1 tape(s)
loss is -111.571860884
Iteration 675 lower bound -166.967484013
loss is Autograd FloatNode with value -114.845410306 and 1 tape(s)
loss is -114.811869411
Iteration 676 lower bound -163.754683561
loss is Autograd FloatNode with value -115.779135618 and 1 tape(s)
loss is -110.356192304
Iteration 677 lower bound -168.259515873
loss is Autograd FloatNode with value -109.301195928 and 1 tape(s)
loss is -118.819100268
Iteration 678 lower bound -159.757597387
loss is Autograd FloatNode with value -117.642926627 and 1 tape(s)
loss is -119.935608294
Iteration 679 lower bound -158.745721728
loss is Autograd FloatNode with value -107.210386847 and 1 tape(s)
loss is -117.780756682
Iteration 680 lower bound -161.119459732
loss is Autograd FloatNode with value -107.265624346 and 1 tape(s)
loss is -104.893597664
Iteration 681 lower bound -174.306154436
loss is Autograd FloatNode with value -130.496773919 and 1 tape(s)
loss is -118.237075751
Iteration 682 lower bound -161.081312254
loss is Autograd FloatNode with value -107.43675968 and 1 tape(s)
loss is -116.872521239
Iteration 683 lower bound -162.366298949
loss is Autograd FloatNode with value -104.751770825 and 1 tape(s)
loss is -111.701364479
Iteration 684 lower bound -167.589826582
loss is Autograd FloatNode with value -104.670041562 and 1 tape(s)
loss is -112.299056439
Iteration 685 lower bound -167.176524159
loss is Autograd FloatNode with value -111.921380426 and 1 tape(s)
loss is -112.823710839
Iteration 686 lower bound -166.949897309
loss is Autograd FloatNode with value -135.370173391 and 1 tape(s)
loss is -112.209656603
Iteration 687 lower bound -167.876141876
loss is Autograd FloatNode with value -118.837496455 and 1 tape(s)
loss is -111.564741167
Iteration 688 lower bound -168.196955259
loss is Autograd FloatNode with value -136.050754551 and 1 tape(s)
loss is -124.886826556
Iteration 689 lower bound -154.464701232
loss is Autograd FloatNode with value -106.887526051 and 1 tape(s)
loss is -110.691251931
Iteration 690 lower bound -167.99190083
loss is Autograd FloatNode with value -117.52874092 and 1 tape(s)
loss is -115.99082873
Iteration 691 lower bound -162.22289435
loss is Autograd FloatNode with value -112.354087258 and 1 tape(s)
loss is -114.831068254
Iteration 692 lower bound -162.951077431
loss is Autograd FloatNode with value -109.264851969 and 1 tape(s)
loss is -111.483093582
Iteration 693 lower bound -166.06756973
loss is Autograd FloatNode with value -110.52579836 and 1 tape(s)
loss is -111.596599424
Iteration 694 lower bound -165.764104703
loss is Autograd FloatNode with value -112.261008104 and 1 tape(s)
loss is -112.727079891
Iteration 695 lower bound -164.481709261
loss is Autograd FloatNode with value -108.731530008 and 1 tape(s)
loss is -100.902549887
Iteration 696 lower bound -176.294241273
loss is Autograd FloatNode with value -107.631377272 and 1 tape(s)
loss is -107.175191618
Iteration 697 lower bound -169.984331391
loss is Autograd FloatNode with value -108.272607306 and 1 tape(s)
loss is -107.782813594
Iteration 698 lower bound -169.401764015
loss is Autograd FloatNode with value -111.926370641 and 1 tape(s)
loss is -122.832321438
Iteration 699 lower bound -154.456511231
loss is Autograd FloatNode with value -107.36874528 and 1 tape(s)
loss is -114.464299309
Iteration 700 lower bound -162.949865609
loss is Autograd FloatNode with value -108.81846465 and 1 tape(s)
loss is -113.528674458
Iteration 701 lower bound -163.981378471
loss is Autograd FloatNode with value -107.888683328 and 1 tape(s)
loss is -112.1216624
Iteration 702 lower bound -165.5673921
loss is Autograd FloatNode with value -115.955382731 and 1 tape(s)
loss is -112.931327346
Iteration 703 lower bound -165.049832009
loss is Autograd FloatNode with value -107.407620172 and 1 tape(s)
loss is -109.581481793
Iteration 704 lower bound -168.662533229
loss is Autograd FloatNode with value -111.168306849 and 1 tape(s)
loss is -101.228388963
Iteration 705 lower bound -177.293984951
loss is Autograd FloatNode with value -107.220809377 and 1 tape(s)
loss is -113.928319308
Iteration 706 lower bound -164.878580037
loss is Autograd FloatNode with value -109.684508322 and 1 tape(s)
loss is -107.524134396
Iteration 707 lower bound -171.615131987
loss is Autograd FloatNode with value -109.051054114 and 1 tape(s)
loss is -102.706272849
Iteration 708 lower bound -176.730527847
loss is Autograd FloatNode with value -101.825401941 and 1 tape(s)
loss is -101.912006605
Iteration 709 lower bound -177.775130253
loss is Autograd FloatNode with value -101.864339503 and 1 tape(s)
loss is -109.485680903
Iteration 710 lower bound -170.515617337
loss is Autograd FloatNode with value -111.118901144 and 1 tape(s)
loss is -105.752140828
Iteration 711 lower bound -174.675854933
loss is Autograd FloatNode with value -134.969916559 and 1 tape(s)
loss is -101.784102461
Iteration 712 lower bound -178.929251195
loss is Autograd FloatNode with value -104.425483447 and 1 tape(s)
loss is -109.975335733
Iteration 713 lower bound -170.743300357
loss is Autograd FloatNode with value -111.881763985 and 1 tape(s)
loss is -105.849344697
Iteration 714 lower bound -174.902378301
loss is Autograd FloatNode with value -109.836828071 and 1 tape(s)
loss is -96.8940617355
Iteration 715 lower bound -183.869113027
loss is Autograd FloatNode with value -105.927133681 and 1 tape(s)
loss is -107.637784515
Iteration 716 lower bound -173.040162731
loss is Autograd FloatNode with value -102.790033862 and 1 tape(s)
loss is -107.366236591
Iteration 717 lower bound -173.39721919
loss is Autograd FloatNode with value -105.74264915 and 1 tape(s)
loss is -105.168864181
Iteration 718 lower bound -175.762188934
loss is Autograd FloatNode with value -103.309854157 and 1 tape(s)
loss is -102.225708516
Iteration 719 lower bound -178.948250066
loss is Autograd FloatNode with value -110.279314824 and 1 tape(s)
loss is -124.409477149
Iteration 720 lower bound -157.121527833
loss is Autograd FloatNode with value -107.27818448 and 1 tape(s)
loss is -116.87994191
Iteration 721 lower bound -165.002372418
loss is Autograd FloatNode with value -104.161636538 and 1 tape(s)
loss is -109.179567717
Iteration 722 lower bound -173.038782922
loss is Autograd FloatNode with value -137.35467233 and 1 tape(s)
loss is -121.436166725
Iteration 723 lower bound -161.109445339
loss is Autograd FloatNode with value -104.259365086 and 1 tape(s)
loss is -119.75040654
Iteration 724 lower bound -163.075257815
loss is Autograd FloatNode with value -108.899020652 and 1 tape(s)
loss is -111.677519394
Iteration 725 lower bound -171.470453739
loss is Autograd FloatNode with value -106.100809295 and 1 tape(s)
loss is -103.934428781
Iteration 726 lower bound -179.551010731
loss is Autograd FloatNode with value -110.576842507 and 1 tape(s)
loss is -118.016333649
Iteration 727 lower bound -165.862488897
loss is Autograd FloatNode with value -124.960578389 and 1 tape(s)
loss is -111.484124711
Iteration 728 lower bound -172.745603196
loss is Autograd FloatNode with value -107.237704815 and 1 tape(s)
loss is -111.493197661
Iteration 729 lower bound -172.605506068
loss is Autograd FloatNode with value -124.187864738 and 1 tape(s)
loss is -108.99972639
Iteration 730 lower bound -175.151929277
loss is Autograd FloatNode with value -110.941445762 and 1 tape(s)
loss is -108.714653682
Iteration 731 lower bound -175.448935529
loss is Autograd FloatNode with value -108.378940989 and 1 tape(s)
loss is -119.66466181
Iteration 732 lower bound -164.530544397
loss is Autograd FloatNode with value -105.960327741 and 1 tape(s)
loss is -131.331437523
Iteration 733 lower bound -152.909461502
loss is Autograd FloatNode with value -109.274428672 and 1 tape(s)
loss is -105.027486647
Iteration 734 lower bound -179.297891518
loss is Autograd FloatNode with value -119.327846622 and 1 tape(s)
loss is -112.97600162
Iteration 735 lower bound -171.400212064
loss is Autograd FloatNode with value -111.705090816 and 1 tape(s)
loss is -110.90216006
Iteration 736 lower bound -173.4323647
loss is Autograd FloatNode with value -113.02367368 and 1 tape(s)
loss is -107.140119362
Iteration 737 lower bound -177.139480568
loss is Autograd FloatNode with value -117.71603106 and 1 tape(s)
loss is -100.951767649
Iteration 738 lower bound -183.241728219
loss is Autograd FloatNode with value -105.148976673 and 1 tape(s)
loss is -108.59941078
Iteration 739 lower bound -175.429686037
loss is Autograd FloatNode with value -115.367700569 and 1 tape(s)
loss is -107.211705431
Iteration 740 lower bound -176.734475977
loss is Autograd FloatNode with value -104.994829519 and 1 tape(s)
loss is -102.95802998
Iteration 741 lower bound -180.781866375
loss is Autograd FloatNode with value -110.147434611 and 1 tape(s)
loss is -105.38613179
Iteration 742 lower bound -178.285237027
loss is Autograd FloatNode with value -104.863010145 and 1 tape(s)
loss is -110.724385507
Iteration 743 lower bound -172.839940376
loss is Autograd FloatNode with value -105.323473832 and 1 tape(s)
loss is -108.876759724
Iteration 744 lower bound -174.625923562
loss is Autograd FloatNode with value -104.763612179 and 1 tape(s)
loss is -103.737312072
Iteration 745 lower bound -179.758775774
loss is Autograd FloatNode with value -103.749117163 and 1 tape(s)
loss is -105.735164396
Iteration 746 lower bound -177.688118764
loss is Autograd FloatNode with value -106.152828337 and 1 tape(s)
loss is -105.563895466
Iteration 747 lower bound -177.910213547
loss is Autograd FloatNode with value -105.558010464 and 1 tape(s)
loss is -103.311288048
Iteration 748 lower bound -180.398984159
loss is Autograd FloatNode with value -105.315121176 and 1 tape(s)
loss is -112.175280067
Iteration 749 lower bound -171.824929596
loss is Autograd FloatNode with value -100.638737578 and 1 tape(s)
loss is -112.787135
Iteration 750 lower bound -171.541969983
loss is Autograd FloatNode with value -121.326349885 and 1 tape(s)
loss is -110.160517539
Iteration 751 lower bound -174.638265481
loss is Autograd FloatNode with value -113.364132838 and 1 tape(s)
loss is -114.854633974
Iteration 752 lower bound -169.97745802
loss is Autograd FloatNode with value -104.882834521 and 1 tape(s)
loss is -104.848863624
Iteration 753 lower bound -180.050573414
loss is Autograd FloatNode with value -111.87163356 and 1 tape(s)
loss is -104.296518569
Iteration 754 lower bound -180.712811529
loss is Autograd FloatNode with value -104.264558777 and 1 tape(s)
loss is -109.357017264
Iteration 755 lower bound -175.78550185
loss is Autograd FloatNode with value -105.916661327 and 1 tape(s)
loss is -111.726554101
Iteration 756 lower bound -173.604843917
loss is Autograd FloatNode with value -110.538259785 and 1 tape(s)
loss is -113.677650716
Iteration 757 lower bound -171.871828846
loss is Autograd FloatNode with value -102.21129409 and 1 tape(s)
loss is -106.920198588
Iteration 758 lower bound -178.932259815
loss is Autograd FloatNode with value -100.765336811 and 1 tape(s)
loss is -104.619445264
Iteration 759 lower bound -181.660871165
loss is Autograd FloatNode with value -102.65392774 and 1 tape(s)
loss is -114.771526141
Iteration 760 lower bound -172.037028228
loss is Autograd FloatNode with value -108.061399064 and 1 tape(s)
loss is -113.528332804
Iteration 761 lower bound -173.83807302
loss is Autograd FloatNode with value -111.533199954 and 1 tape(s)
loss is -113.399407306
Iteration 762 lower bound -174.534687833
loss is Autograd FloatNode with value -108.524704434 and 1 tape(s)
loss is -113.425156669
Iteration 763 lower bound -175.016352252
loss is Autograd FloatNode with value -119.390349253 and 1 tape(s)
loss is -104.328549198
Iteration 764 lower bound -184.625730333
loss is Autograd FloatNode with value -106.953606776 and 1 tape(s)
loss is -108.456960056
Iteration 765 lower bound -180.830961183
loss is Autograd FloatNode with value -111.70685879 and 1 tape(s)
loss is -112.060544083
Iteration 766 lower bound -177.608108598
loss is Autograd FloatNode with value -110.734093755 and 1 tape(s)
loss is -107.923940531
Iteration 767 lower bound -182.065919424
loss is Autograd FloatNode with value -104.910812888 and 1 tape(s)
loss is -114.504310608
Iteration 768 lower bound -175.649427771
loss is Autograd FloatNode with value -117.464721371 and 1 tape(s)
loss is -108.215649979
Iteration 769 lower bound -182.152164338
loss is Autograd FloatNode with value -109.163526695 and 1 tape(s)
loss is -151.939041086
Iteration 770 lower bound -138.568748803
loss is Autograd FloatNode with value -105.172353032 and 1 tape(s)
loss is -112.528389186
Iteration 771 lower bound -178.060160505
loss is Autograd FloatNode with value -120.016069587 and 1 tape(s)
loss is -120.275705213
Iteration 772 lower bound -170.410898411
loss is Autograd FloatNode with value -111.349720353 and 1 tape(s)
loss is -115.000897851
Iteration 773 lower bound -175.559323851
loss is Autograd FloatNode with value -110.846334546 and 1 tape(s)
loss is -108.049802632
Iteration 774 lower bound -182.393244412
loss is Autograd FloatNode with value -109.376471353 and 1 tape(s)
loss is -110.345718986
Iteration 775 lower bound -180.116820183
loss is Autograd FloatNode with value -112.206213462 and 1 tape(s)
loss is -118.426035966
Iteration 776 lower bound -172.12051695
loss is Autograd FloatNode with value -110.825404435 and 1 tape(s)
loss is -109.392332817
Iteration 777 lower bound -181.300053512
loss is Autograd FloatNode with value -114.084052663 and 1 tape(s)
loss is -104.017782614
Iteration 778 lower bound -186.864713762
loss is Autograd FloatNode with value -106.571301375 and 1 tape(s)
loss is -106.722269826
Iteration 779 lower bound -184.339956643
loss is Autograd FloatNode with value -119.681545295 and 1 tape(s)
loss is -125.516640276
Iteration 780 lower bound -165.702741586
loss is Autograd FloatNode with value -113.577511657 and 1 tape(s)
loss is -110.697487923
Iteration 781 lower bound -180.661249965
Optimizing variational parameters...
Optimizing variational parameters...
loss is Autograd FloatNode with value -20965.9241238 and 1 tape(s)
loss is -20986.2389109
Iteration 0 lower bound 21491.1685777
loss is Autograd FloatNode with value -10726.6463956 and 1 tape(s)
loss is -10666.8393663
Iteration 1 lower bound 11160.4690332
loss is Autograd FloatNode with value -4752.38335913 and 1 tape(s)
loss is -4745.95788929
Iteration 2 lower bound 5228.56721036
loss is Autograd FloatNode with value -2004.91417467 and 1 tape(s)
loss is -1988.46488593
Iteration 3 lower bound 2459.42543292
loss is Autograd FloatNode with value -944.675595904 and 1 tape(s)
loss is -946.30991732
Iteration 4 lower bound 1405.33151751
loss is Autograd FloatNode with value -652.405459976 and 1 tape(s)
loss is -650.506087284
Iteration 5 lower bound 1097.33700889
loss is Autograd FloatNode with value -659.788730807 and 1 tape(s)
loss is -660.106139772
Iteration 6 lower bound 1094.59487908
loss is Autograd FloatNode with value -757.786619369 and 1 tape(s)
loss is -752.623356164
Iteration 7 lower bound 1174.64658825
loss is Autograd FloatNode with value -817.718918124 and 1 tape(s)
loss is -823.834925055
Iteration 8 lower bound 1233.31140405
loss is Autograd FloatNode with value -823.381251748 and 1 tape(s)
loss is -822.904544784
Iteration 9 lower bound 1219.7609222
loss is Autograd FloatNode with value -765.268638743 and 1 tape(s)
loss is -766.844067199
Iteration 10 lower bound 1151.02826488
loss is Autograd FloatNode with value -678.010473037 and 1 tape(s)
loss is -678.119887919
Iteration 11 lower bound 1049.60509756
loss is Autograd FloatNode with value -608.924195104 and 1 tape(s)
loss is -605.116207282
Iteration 12 lower bound 963.852363511
loss is Autograd FloatNode with value -564.670369511 and 1 tape(s)
loss is -565.801387765
Iteration 13 lower bound 911.775155253
loss is Autograd FloatNode with value -551.438304358 and 1 tape(s)
loss is -554.631501095
Iteration 14 lower bound 887.802944464
loss is Autograd FloatNode with value -546.983246792 and 1 tape(s)
loss is -552.264372464
Iteration 15 lower bound 872.604086113
loss is Autograd FloatNode with value -535.675929047 and 1 tape(s)
loss is -534.830940457
Iteration 16 lower bound 842.320490689
loss is Autograd FloatNode with value -509.544401559 and 1 tape(s)
loss is -510.951712741
Iteration 17 lower bound 805.58686956
loss is Autograd FloatNode with value -458.32017393 and 1 tape(s)
loss is -457.460614317
Iteration 18 lower bound 739.277432412
loss is Autograd FloatNode with value -405.26621221 and 1 tape(s)
loss is -410.094847421
Iteration 19 lower bound 679.126341056
loss is Autograd FloatNode with value -371.80612986 and 1 tape(s)
loss is -367.668826226
Iteration 20 lower bound 623.951352912
loss is Autograd FloatNode with value -360.152731438 and 1 tape(s)
loss is -363.696101096
Iteration 21 lower bound 607.311744917
loss is Autograd FloatNode with value -385.680177429 and 1 tape(s)
loss is -370.700666979
Iteration 22 lower bound 601.710381221
loss is Autograd FloatNode with value -381.183450519 and 1 tape(s)
loss is -379.056620318
Iteration 23 lower bound 597.715355173
loss is Autograd FloatNode with value -350.639445225 and 1 tape(s)
loss is -357.598641133
Iteration 24 lower bound 564.103471667
loss is Autograd FloatNode with value -314.080462737 and 1 tape(s)
loss is -317.64148462
Iteration 25 lower bound 512.165540894
loss is Autograd FloatNode with value -294.787392902 and 1 tape(s)
loss is -303.769570726
Iteration 26 lower bound 486.386700993
loss is Autograd FloatNode with value -294.574142153 and 1 tape(s)
loss is -295.753003542
Iteration 27 lower bound 466.511603283
loss is Autograd FloatNode with value -297.211275739 and 1 tape(s)
loss is -318.846786767
Iteration 28 lower bound 477.875536921
loss is Autograd FloatNode with value -285.993252692 and 1 tape(s)
loss is -300.576095934
Iteration 29 lower bound 447.926984656
loss is Autograd FloatNode with value -296.32070144 and 1 tape(s)
loss is -292.378155127
Iteration 30 lower bound 428.063181237
loss is Autograd FloatNode with value -275.558450239 and 1 tape(s)
loss is -273.442009064
Iteration 31 lower bound 397.881992708
loss is Autograd FloatNode with value -260.128091906 and 1 tape(s)
loss is -263.087272897
Iteration 32 lower bound 376.569689213
loss is Autograd FloatNode with value -274.074282562 and 1 tape(s)
loss is -275.678871615
Iteration 33 lower bound 378.404319272
loss is Autograd FloatNode with value -291.167928408 and 1 tape(s)
loss is -282.877920747
Iteration 34 lower bound 375.391496204
loss is Autograd FloatNode with value -277.095489457 and 1 tape(s)
loss is -289.687573873
Iteration 35 lower bound 372.677028911
loss is Autograd FloatNode with value -275.257591912 and 1 tape(s)
loss is -272.280470695
Iteration 36 lower bound 346.026874188
loss is Autograd FloatNode with value -274.996325339 and 1 tape(s)
loss is -259.792102813
Iteration 37 lower bound 324.589154973
loss is Autograd FloatNode with value -245.722457245 and 1 tape(s)
loss is -238.954727404
Iteration 38 lower bound 295.16196408
loss is Autograd FloatNode with value -268.931429676 and 1 tape(s)
loss is -239.861564442
Iteration 39 lower bound 287.594780304
loss is Autograd FloatNode with value -255.348819386 and 1 tape(s)
loss is -268.682102124
Iteration 40 lower bound 308.354603623
loss is Autograd FloatNode with value -251.982445287 and 1 tape(s)
loss is -243.358212147
Iteration 41 lower bound 275.20005046
loss is Autograd FloatNode with value -257.483224706 and 1 tape(s)
loss is -251.203514266
Iteration 42 lower bound 275.536240803
loss is Autograd FloatNode with value -232.058264552 and 1 tape(s)
loss is -221.08325333
Iteration 43 lower bound 238.324522154
loss is Autograd FloatNode with value -235.712515166 and 1 tape(s)
loss is -231.379675647
Iteration 44 lower bound 241.654171463
loss is Autograd FloatNode with value -235.349717337 and 1 tape(s)
loss is -230.101526769
Iteration 45 lower bound 233.688157446
loss is Autograd FloatNode with value -222.590857648 and 1 tape(s)
loss is -225.528648829
Iteration 46 lower bound 222.572442408
Optimizing variational parameters...
loss is Autograd FloatNode with value -20965.9241238 and 1 tape(s)
loss is -20986.2389109
Iteration 0 lower bound 21491.1685777
loss is Autograd FloatNode with value -10726.6463956 and 1 tape(s)
loss is -10666.8393663
Iteration 1 lower bound 11160.4690332
loss is Autograd FloatNode with value -4752.38335913 and 1 tape(s)
loss is -4745.95788929
Iteration 2 lower bound 5228.56721036
loss is Autograd FloatNode with value -2004.91417467 and 1 tape(s)
loss is -1988.46488593
Iteration 3 lower bound 2459.42543292
loss is Autograd FloatNode with value -944.675595904 and 1 tape(s)
loss is -946.30991732
Iteration 4 lower bound 1405.33151751
loss is Autograd FloatNode with value -652.405459976 and 1 tape(s)
loss is -650.506087284
Iteration 5 lower bound 1097.33700889
loss is Autograd FloatNode with value -659.788730807 and 1 tape(s)
loss is -660.106139772
Iteration 6 lower bound 1094.59487908
loss is Autograd FloatNode with value -757.786619369 and 1 tape(s)
loss is -752.623356164
Iteration 7 lower bound 1174.64658825
loss is Autograd FloatNode with value -817.718918124 and 1 tape(s)
loss is -823.834925055
Iteration 8 lower bound 1233.31140405
loss is Autograd FloatNode with value -823.381251748 and 1 tape(s)
loss is -822.904544784
Iteration 9 lower bound 1219.7609222
loss is Autograd FloatNode with value -765.268638743 and 1 tape(s)
loss is -766.844067199
Iteration 10 lower bound 1151.02826488
loss is Autograd FloatNode with value -678.010473037 and 1 tape(s)
loss is -678.119887919
Iteration 11 lower bound 1049.60509756
loss is Autograd FloatNode with value -608.924195104 and 1 tape(s)
loss is -605.116207282
Iteration 12 lower bound 963.852363511
loss is Autograd FloatNode with value -564.670369511 and 1 tape(s)
loss is -565.801387765
Iteration 13 lower bound 911.775155253
loss is Autograd FloatNode with value -551.438304358 and 1 tape(s)
loss is -554.631501095
Iteration 14 lower bound 887.802944464
loss is Autograd FloatNode with value -546.983246792 and 1 tape(s)
loss is -552.264372464
Iteration 15 lower bound 872.604086113
loss is Autograd FloatNode with value -535.675929047 and 1 tape(s)
loss is -534.830940457
Iteration 16 lower bound 842.320490689
loss is Autograd FloatNode with value -509.544401559 and 1 tape(s)
loss is -510.951712741
Iteration 17 lower bound 805.58686956
loss is Autograd FloatNode with value -458.32017393 and 1 tape(s)
loss is -457.460614317
Iteration 18 lower bound 739.277432412
loss is Autograd FloatNode with value -405.26621221 and 1 tape(s)
loss is -410.094847421
Iteration 19 lower bound 679.126341056
loss is Autograd FloatNode with value -371.80612986 and 1 tape(s)
loss is -367.668826226
Iteration 20 lower bound 623.951352912
loss is Autograd FloatNode with value -360.152731438 and 1 tape(s)
loss is -363.696101096
Iteration 21 lower bound 607.311744917
loss is Autograd FloatNode with value -385.680177429 and 1 tape(s)
loss is -370.700666979
Iteration 22 lower bound 601.710381221
loss is Autograd FloatNode with value -381.183450519 and 1 tape(s)
loss is -379.056620318
Iteration 23 lower bound 597.715355173
loss is Autograd FloatNode with value -350.639445225 and 1 tape(s)
loss is -357.598641133
Iteration 24 lower bound 564.103471667
loss is Autograd FloatNode with value -314.080462737 and 1 tape(s)
loss is -317.64148462
Iteration 25 lower bound 512.165540894
loss is Autograd FloatNode with value -294.787392902 and 1 tape(s)
loss is -303.769570726
Iteration 26 lower bound 486.386700993
loss is Autograd FloatNode with value -294.574142153 and 1 tape(s)
loss is -295.753003542
Iteration 27 lower bound 466.511603283
loss is Autograd FloatNode with value -297.211275739 and 1 tape(s)
loss is -318.846786767
Iteration 28 lower bound 477.875536921
loss is Autograd FloatNode with value -285.993252692 and 1 tape(s)
loss is -300.576095934
Iteration 29 lower bound 447.926984656
loss is Autograd FloatNode with value -296.32070144 and 1 tape(s)
loss is -292.378155127
Iteration 30 lower bound 428.063181237
loss is Autograd FloatNode with value -275.558450239 and 1 tape(s)
loss is -273.442009064
Iteration 31 lower bound 397.881992708
loss is Autograd FloatNode with value -260.128091906 and 1 tape(s)
loss is -263.087272897
Iteration 32 lower bound 376.569689213
loss is Autograd FloatNode with value -274.074282562 and 1 tape(s)
loss is -275.678871615
Iteration 33 lower bound 378.404319272
loss is Autograd FloatNode with value -291.167928408 and 1 tape(s)
loss is -282.877920747
Iteration 34 lower bound 375.391496204
loss is Autograd FloatNode with value -277.095489457 and 1 tape(s)
loss is -289.687573873
Iteration 35 lower bound 372.677028911
loss is Autograd FloatNode with value -275.257591912 and 1 tape(s)
loss is -272.280470695
Iteration 36 lower bound 346.026874188
loss is Autograd FloatNode with value -274.996325339 and 1 tape(s)
loss is -259.792102813
Iteration 37 lower bound 324.589154973
loss is Autograd FloatNode with value -245.722457245 and 1 tape(s)
loss is -238.954727404
Iteration 38 lower bound 295.16196408
loss is Autograd FloatNode with value -268.931429676 and 1 tape(s)
loss is -239.861564442
Iteration 39 lower bound 287.594780304
loss is Autograd FloatNode with value -255.348819386 and 1 tape(s)
loss is -268.682102124
Iteration 40 lower bound 308.354603623
loss is Autograd FloatNode with value -251.982445287 and 1 tape(s)
loss is -243.358212147
Iteration 41 lower bound 275.20005046
loss is Autograd FloatNode with value -257.483224706 and 1 tape(s)
loss is -251.203514266
Iteration 42 lower bound 275.536240803
loss is Autograd FloatNode with value -232.058264552 and 1 tape(s)
loss is -221.08325333
Iteration 43 lower bound 238.324522154
loss is Autograd FloatNode with value -235.712515166 and 1 tape(s)
loss is -231.379675647
Iteration 44 lower bound 241.654171463
loss is Autograd FloatNode with value -235.349717337 and 1 tape(s)
loss is -230.101526769
Iteration 45 lower bound 233.688157446
loss is Autograd FloatNode with value -222.590857648 and 1 tape(s)
loss is -225.528648829
Iteration 46 lower bound 222.572442408
loss is Autograd FloatNode with value -203.621563558 and 1 tape(s)
loss is -228.440148847
Iteration 47 lower bound 219.080344605
loss is Autograd FloatNode with value -211.194311172 and 1 tape(s)
loss is -203.629310078
Iteration 48 lower bound 187.73140392
loss is Autograd FloatNode with value -206.524995453 and 1 tape(s)
loss is -204.922732017
Iteration 49 lower bound 182.670322525
loss is Autograd FloatNode with value -198.84814878 and 1 tape(s)
loss is -205.308986678
Iteration 50 lower bound 176.820553469
loss is Autograd FloatNode with value -195.977848107 and 1 tape(s)
loss is -206.341057825
Iteration 51 lower bound 171.774655478
loss is Autograd FloatNode with value -197.253913189 and 1 tape(s)
loss is -206.679823446
Iteration 52 lower bound 166.344305865
loss is Autograd FloatNode with value -188.630427762 and 1 tape(s)
loss is -178.237774015
Iteration 53 lower bound 132.788347961
loss is Autograd FloatNode with value -194.123547886 and 1 tape(s)
loss is -195.668901114
Iteration 54 lower bound 145.468214806
loss is Autograd FloatNode with value -179.628251336 and 1 tape(s)
loss is -180.169470047
Iteration 55 lower bound 125.953953053
loss is Autograd FloatNode with value -183.775067906 and 1 tape(s)
loss is -163.077252397
Iteration 56 lower bound 105.119366702
loss is Autograd FloatNode with value -191.601400066 and 1 tape(s)
loss is -178.342396453
Iteration 57 lower bound 117.19763984
loss is Autograd FloatNode with value -179.79824688 and 1 tape(s)
loss is -158.135411799
Iteration 58 lower bound 94.5198807
loss is Autograd FloatNode with value -159.615089028 and 1 tape(s)
loss is -171.925551445
Iteration 59 lower bound 106.273843604
loss is Autograd FloatNode with value -161.016620687 and 1 tape(s)
loss is -191.68226752
Iteration 60 lower bound 124.071954061
loss is Autograd FloatNode with value -166.45350808 and 1 tape(s)
loss is -135.638158633
Iteration 61 lower bound 66.2576501806
loss is Autograd FloatNode with value -175.055334764 and 1 tape(s)
loss is -160.05503616
Iteration 62 lower bound 89.5702916553
loss is Autograd FloatNode with value -144.347876294 and 1 tape(s)
loss is -161.518790486
Iteration 63 lower bound 89.8996104033
loss is Autograd FloatNode with value -160.386811074 and 1 tape(s)
loss is -160.827962717
Iteration 64 lower bound 87.59775081
loss is Autograd FloatNode with value -140.629604922 and 1 tape(s)
loss is -145.219217899
Iteration 65 lower bound 70.4539076598
loss is Autograd FloatNode with value -132.773068811 and 1 tape(s)
loss is -142.280935136
Iteration 66 lower bound 65.6706730053
loss is Autograd FloatNode with value -160.862527822 and 1 tape(s)
loss is -144.612027071
Iteration 67 lower bound 66.0970005262
loss is Autograd FloatNode with value -143.396961829 and 1 tape(s)
loss is -151.157451318
Iteration 68 lower bound 70.9024802925
loss is Autograd FloatNode with value -136.672440426 and 1 tape(s)
loss is -158.151917671
Iteration 69 lower bound 76.1534711813
loss is Autograd FloatNode with value -144.272111397 and 1 tape(s)
loss is -150.254416906
Iteration 70 lower bound 66.5984099443
loss is Autograd FloatNode with value -138.422434223 and 1 tape(s)
loss is -144.656819698
Iteration 71 lower bound 59.4855039791
loss is Autograd FloatNode with value -137.20818439 and 1 tape(s)
loss is -130.566996557
Iteration 72 lower bound 43.8252877996
loss is Autograd FloatNode with value -139.482513616 and 1 tape(s)
loss is -130.499785471
Iteration 73 lower bound 42.0351826644
loss is Autograd FloatNode with value -139.286561139 and 1 tape(s)
loss is -132.841392438
Iteration 74 lower bound 42.7960069797
loss is Autograd FloatNode with value -130.061838892 and 1 tape(s)
loss is -132.312862216
Iteration 75 lower bound 41.1207320353
loss is Autograd FloatNode with value -150.163880159 and 1 tape(s)
loss is -125.318653562
Iteration 76 lower bound 33.068637326
loss is Autograd FloatNode with value -122.908913974 and 1 tape(s)
loss is -126.143355653
Iteration 77 lower bound 32.9164503294
loss is Autograd FloatNode with value -141.271318606 and 1 tape(s)
loss is -135.152284684
Iteration 78 lower bound 40.8058819011
loss is Autograd FloatNode with value -136.000288409 and 1 tape(s)
loss is -138.323472699
Iteration 79 lower bound 42.7974325979
loss is Autograd FloatNode with value -136.673870467 and 1 tape(s)
loss is -136.550643822
Iteration 80 lower bound 39.7049173279
loss is Autograd FloatNode with value -117.262638446 and 1 tape(s)
loss is -134.093220433
Iteration 81 lower bound 35.838143782
loss is Autograd FloatNode with value -129.197009591 and 1 tape(s)
loss is -129.786004666
Iteration 82 lower bound 29.9202719453
loss is Autograd FloatNode with value -141.473906008 and 1 tape(s)
loss is -120.694242916
Iteration 83 lower bound 19.184103458
loss is Autograd FloatNode with value -151.820643205 and 1 tape(s)
loss is -115.083190013
Iteration 84 lower bound 11.944031611
loss is Autograd FloatNode with value -115.051802956 and 1 tape(s)
loss is -128.384258349
Iteration 85 lower bound 24.1257039662
loss is Autograd FloatNode with value -128.659904308 and 1 tape(s)
loss is -127.251540622
Iteration 86 lower bound 21.6081801696
loss is Autograd FloatNode with value -113.805704942 and 1 tape(s)
loss is -125.495483894
Iteration 87 lower bound 18.3459631966
loss is Autograd FloatNode with value -118.305278475 and 1 tape(s)
loss is -139.091751371
Iteration 88 lower bound 30.141293524
loss is Autograd FloatNode with value -121.60615479 and 1 tape(s)
loss is -111.181454408
Iteration 89 lower bound 0.236434945181
loss is Autograd FloatNode with value -115.672170779 and 1 tape(s)
loss is -119.476301853
Iteration 90 lower bound 6.53686371384
loss is Autograd FloatNode with value -147.225666624 and 1 tape(s)
loss is -110.799089647
Iteration 91 lower bound -4.13122928508
loss is Autograd FloatNode with value -127.728711219 and 1 tape(s)
loss is -116.980397375
Iteration 92 lower bound 0.637927502159
loss is Autograd FloatNode with value -145.839568096 and 1 tape(s)
loss is -118.181015515
Iteration 93 lower bound 0.670671967961
loss is Autograd FloatNode with value -141.80000348 and 1 tape(s)
loss is -133.109615062
Iteration 94 lower bound 15.0297485336
loss is Autograd FloatNode with value -148.550950288 and 1 tape(s)
loss is -120.424646373
Iteration 95 lower bound 1.94350063568
loss is Autograd FloatNode with value -119.690865565 and 1 tape(s)
loss is -124.134817383
Iteration 96 lower bound 5.57891894105
loss is Autograd FloatNode with value -109.73715338 and 1 tape(s)
loss is -129.881040831
Iteration 97 lower bound 11.1450247362
loss is Autograd FloatNode with value -109.771556453 and 1 tape(s)
loss is -100.082401637
Iteration 98 lower bound -18.9101673353
loss is Autograd FloatNode with value -119.412657865 and 1 tape(s)
loss is -125.262779684
Iteration 99 lower bound 5.80037378661
loss is Autograd FloatNode with value -153.200890028 and 1 tape(s)
loss is -114.992801488
Iteration 100 lower bound -5.15857109527
loss is Autograd FloatNode with value -107.676896135 and 1 tape(s)
loss is -122.665185238
Iteration 101 lower bound 2.52994392187
loss is Autograd FloatNode with value -136.846904065 and 1 tape(s)
loss is -118.142679804
Iteration 102 lower bound -2.21105774916
loss is Autograd FloatNode with value -114.3675758 and 1 tape(s)
loss is -111.350689343
Iteration 103 lower bound -9.17220139714
loss is Autograd FloatNode with value -122.018042212 and 1 tape(s)
loss is -108.854961738
Iteration 104 lower bound -12.0951457957
loss is Autograd FloatNode with value -105.840777477 and 1 tape(s)
loss is -122.881600593
Iteration 105 lower bound 1.46487861127
loss is Autograd FloatNode with value -116.757086907 and 1 tape(s)
loss is -134.173705485
Iteration 106 lower bound 12.1848533908
loss is Autograd FloatNode with value -110.950865524 and 1 tape(s)
loss is -123.172727772
Iteration 107 lower bound 0.672040694807
loss is Autograd FloatNode with value -113.215747796 and 1 tape(s)
loss is -119.836658399
Iteration 108 lower bound -3.27451917875
loss is Autograd FloatNode with value -106.098449807 and 1 tape(s)
loss is -127.115688565
Iteration 109 lower bound 3.32745895361
loss is Autograd FloatNode with value -96.6682487595 and 1 tape(s)
loss is -133.756098265
Iteration 110 lower bound 9.18181522616
loss is Autograd FloatNode with value -103.623066542 and 1 tape(s)
loss is -109.837874426
Iteration 111 lower bound -15.7885734048
loss is Autograd FloatNode with value -103.682015931 and 1 tape(s)
loss is -104.352994736
Iteration 112 lower bound -22.5107410093
loss is Autograd FloatNode with value -113.271855408 and 1 tape(s)
loss is -100.353330425
Iteration 113 lower bound -27.9575916986
loss is Autograd FloatNode with value -138.781103314 and 1 tape(s)
loss is -101.515202564
Iteration 114 lower bound -28.0281882646
loss is Autograd FloatNode with value -108.188291904 and 1 tape(s)
loss is -96.0956349554
Iteration 115 lower bound -34.7240031542
loss is Autograd FloatNode with value -108.342628694 and 1 tape(s)
loss is -120.520488653
Iteration 116 lower bound -11.5301533797
loss is Autograd FloatNode with value -103.389749577 and 1 tape(s)
loss is -117.231811459
Iteration 117 lower bound -16.057942387
loss is Autograd FloatNode with value -97.098199965 and 1 tape(s)
loss is -112.400615806
Iteration 118 lower bound -22.2779943317
loss is Autograd FloatNode with value -92.9010379646 and 1 tape(s)
loss is -102.557771547
Iteration 119 lower bound -33.6908332837
loss is Autograd FloatNode with value -105.902084866 and 1 tape(s)
loss is -104.089294513
Iteration 120 lower bound -33.8340840423
loss is Autograd FloatNode with value -106.696734998 and 1 tape(s)
loss is -106.772561765
Iteration 121 lower bound -32.670476018
loss is Autograd FloatNode with value -98.3875951886 and 1 tape(s)
loss is -122.616347337
Iteration 122 lower bound -18.3147926321
loss is Autograd FloatNode with value -121.686835537 and 1 tape(s)
loss is -109.196876795
Iteration 123 lower bound -33.3074774923
loss is Autograd FloatNode with value -138.688475024 and 1 tape(s)
loss is -134.323219093
Iteration 124 lower bound -9.34333763858
loss is Autograd FloatNode with value -116.013437412 and 1 tape(s)
loss is -110.712307698
Iteration 125 lower bound -33.3673949945
loss is Autograd FloatNode with value -108.290291061 and 1 tape(s)
loss is -102.888917657
Iteration 126 lower bound -41.7525292193
loss is Autograd FloatNode with value -114.562820898 and 1 tape(s)
loss is -103.764744949
Iteration 127 lower bound -41.6746193684
loss is Autograd FloatNode with value -126.072746679 and 1 tape(s)
loss is -109.23519436
Iteration 128 lower bound -36.8556837828
loss is Autograd FloatNode with value -123.570427451 and 1 tape(s)
loss is -115.075694948
Iteration 129 lower bound -31.4706993979
loss is Autograd FloatNode with value -120.076876085 and 1 tape(s)
loss is -104.848811308
Iteration 130 lower bound -41.8704349107
loss is Autograd FloatNode with value -101.554323219 and 1 tape(s)
loss is -96.3216473923
Iteration 131 lower bound -50.3755950014
loss is Autograd FloatNode with value -91.6683471871 and 1 tape(s)
loss is -105.080511979
Iteration 132 lower bound -41.7037056399
loss is Autograd FloatNode with value -98.1213992198 and 1 tape(s)
loss is -103.276643551
Iteration 133 lower bound -43.9660192837
loss is Autograd FloatNode with value -97.2272000487 and 1 tape(s)
loss is -100.631077745
Iteration 134 lower bound -47.3795353535
loss is Autograd FloatNode with value -96.004614931 and 1 tape(s)
loss is -104.540245819
Iteration 135 lower bound -44.4893709425
loss is Autograd FloatNode with value -99.2851153109 and 1 tape(s)
loss is -110.04984427
Iteration 136 lower bound -40.1327001793
loss is Autograd FloatNode with value -117.18551881 and 1 tape(s)
loss is -106.253651394
Iteration 137 lower bound -45.2150375362
loss is Autograd FloatNode with value -93.434146462 and 1 tape(s)
loss is -101.495962081
Iteration 138 lower bound -51.043661637
loss is Autograd FloatNode with value -112.015206409 and 1 tape(s)
loss is -108.77073389
Iteration 139 lower bound -45.0005038409
loss is Autograd FloatNode with value -114.653410736 and 1 tape(s)
loss is -106.014494177
Iteration 140 lower bound -48.9802408835
loss is Autograd FloatNode with value -131.97339874 and 1 tape(s)
loss is -110.9819169
Iteration 141 lower bound -45.1604183855
loss is Autograd FloatNode with value -105.978077577 and 1 tape(s)
loss is -105.006130106
Iteration 142 lower bound -52.1197494967
loss is Autograd FloatNode with value -107.469995836 and 1 tape(s)
loss is -109.849424529
Iteration 143 lower bound -48.308365473
loss is Autograd FloatNode with value -101.18996316 and 1 tape(s)
loss is -110.706397796
Iteration 144 lower bound -48.4673179593
loss is Autograd FloatNode with value -117.738639759 and 1 tape(s)
loss is -111.966485014
Iteration 145 lower bound -48.3172215711
loss is Autograd FloatNode with value -111.106798189 and 1 tape(s)
loss is -107.005346408
Iteration 146 lower bound -54.337440153
loss is Autograd FloatNode with value -109.924961905 and 1 tape(s)
loss is -106.299789849
Iteration 147 lower bound -55.9806626672
loss is Autograd FloatNode with value -114.10723993 and 1 tape(s)
loss is -108.24762775
Iteration 148 lower bound -54.8939794023
loss is Autograd FloatNode with value -110.180706619 and 1 tape(s)
loss is -110.974830794
Iteration 149 lower bound -53.1283437024
loss is Autograd FloatNode with value -109.486479191 and 1 tape(s)
loss is -128.494263999
Iteration 150 lower bound -36.76552838
loss is Autograd FloatNode with value -100.448560919 and 1 tape(s)
loss is -103.520719109
Iteration 151 lower bound -62.9640598018
loss is Autograd FloatNode with value -108.256710255 and 1 tape(s)
loss is -116.577950129
Iteration 152 lower bound -51.2251061412
loss is Autograd FloatNode with value -106.781704009 and 1 tape(s)
loss is -116.980478691
Iteration 153 lower bound -52.059863633
loss is Autograd FloatNode with value -116.92673876 and 1 tape(s)
loss is -121.20555973
Iteration 154 lower bound -49.1268118206
loss is Autograd FloatNode with value -106.715275368 and 1 tape(s)
loss is -113.954278613
Iteration 155 lower bound -57.4516882714
loss is Autograd FloatNode with value -122.037749772 and 1 tape(s)
loss is -125.830694677
Iteration 156 lower bound -46.5222487028
loss is Autograd FloatNode with value -125.967304324 and 1 tape(s)
loss is -117.23540631
Iteration 157 lower bound -55.9481095433
loss is Autograd FloatNode with value -128.76677836 and 1 tape(s)
loss is -112.270695473
Iteration 158 lower bound -61.3444947255
loss is Autograd FloatNode with value -121.126995702 and 1 tape(s)
loss is -112.778945406
Iteration 159 lower bound -61.3223869839
loss is Autograd FloatNode with value -114.953203124 and 1 tape(s)
loss is -116.709937163
Iteration 160 lower bound -57.9095354838
loss is Autograd FloatNode with value -108.761929622 and 1 tape(s)
loss is -114.689200266
Iteration 161 lower bound -60.2864085815
loss is Autograd FloatNode with value -141.743305583 and 1 tape(s)
loss is -136.045764461
Iteration 162 lower bound -39.3227436103
loss is Autograd FloatNode with value -107.452872659 and 1 tape(s)
loss is -115.893866066
Iteration 163 lower bound -59.4734762866
loss is Autograd FloatNode with value -117.063371251 and 1 tape(s)
loss is -122.407417024
Iteration 164 lower bound -53.0859338874
loss is Autograd FloatNode with value -109.406234254 and 1 tape(s)
loss is -125.324973945
Iteration 165 lower bound -50.2014863814
loss is Autograd FloatNode with value -115.790825152 and 1 tape(s)
loss is -119.179857392
Iteration 166 lower bound -56.6578528433
loss is Autograd FloatNode with value -120.514694117 and 1 tape(s)
loss is -112.699575916
Iteration 167 lower bound -63.5970053096
loss is Autograd FloatNode with value -103.117404349 and 1 tape(s)
loss is -104.722238461
Iteration 168 lower bound -71.8512334993
loss is Autograd FloatNode with value -130.414248974 and 1 tape(s)
loss is -108.282138556
Iteration 169 lower bound -68.7198581731
loss is Autograd FloatNode with value -112.731699916 and 1 tape(s)
loss is -121.43847035
Iteration 170 lower bound -55.5408874134
loss is Autograd FloatNode with value -112.130457965 and 1 tape(s)
loss is -97.8805187372
Iteration 171 lower bound -79.1518909295
loss is Autograd FloatNode with value -120.283958423 and 1 tape(s)
loss is -120.556747849
Iteration 172 lower bound -56.5004199506
loss is Autograd FloatNode with value -125.945589486 and 1 tape(s)
loss is -117.294070862
Iteration 173 lower bound -59.9126711737
loss is Autograd FloatNode with value -105.696876617 and 1 tape(s)
loss is -117.905023383
Iteration 174 lower bound -59.3788278352
loss is Autograd FloatNode with value -97.8247365451 and 1 tape(s)
loss is -100.145515179
Iteration 175 lower bound -77.4609636699
loss is Autograd FloatNode with value -104.272279967 and 1 tape(s)
loss is -106.32501728
Iteration 176 lower bound -71.8347877401
loss is Autograd FloatNode with value -121.385763132 and 1 tape(s)
loss is -101.37353687
Iteration 177 lower bound -77.4407107135
loss is Autograd FloatNode with value -118.531128426 and 1 tape(s)
loss is -115.347144396
Iteration 178 lower bound -64.0461134716
loss is Autograd FloatNode with value -102.143520117 and 1 tape(s)
loss is -96.3683018757
Iteration 179 lower bound -83.4196909708
loss is Autograd FloatNode with value -112.880411917 and 1 tape(s)
loss is -112.749180694
Iteration 180 lower bound -67.536096239
loss is Autograd FloatNode with value -143.96277226 and 1 tape(s)
loss is -130.735598156
Iteration 181 lower bound -50.0439663497
loss is Autograd FloatNode with value -122.125186939 and 1 tape(s)
loss is -116.875451041
Iteration 182 lower bound -64.3016457655
loss is Autograd FloatNode with value -111.533299111 and 1 tape(s)
loss is -100.732059062
Iteration 183 lower bound -80.813427511
loss is Autograd FloatNode with value -105.108735704 and 1 tape(s)
loss is -103.47001318
Iteration 184 lower bound -78.4690591741
loss is Autograd FloatNode with value -104.629230447 and 1 tape(s)
loss is -126.478028889
Iteration 185 lower bound -55.9891439606
loss is Autograd FloatNode with value -111.325187166 and 1 tape(s)
loss is -123.167897139
Iteration 186 lower bound -59.9901406516
loss is Autograd FloatNode with value -107.546317615 and 1 tape(s)
loss is -114.780940004
Iteration 187 lower bound -68.9996832181
loss is Autograd FloatNode with value -103.361089377 and 1 tape(s)
loss is -104.233678735
Iteration 188 lower bound -80.1284360547
loss is Autograd FloatNode with value -116.694046173 and 1 tape(s)
loss is -115.947449165
Iteration 189 lower bound -69.1466862255
loss is Autograd FloatNode with value -125.790367646 and 1 tape(s)
loss is -104.751315792
Iteration 190 lower bound -80.9897528972
loss is Autograd FloatNode with value -95.4277886656 and 1 tape(s)
loss is -108.700372009
Iteration 191 lower bound -77.8421839123
loss is Autograd FloatNode with value -104.795342234 and 1 tape(s)
loss is -112.848232655
Iteration 192 lower bound -74.7575908988
loss is Autograd FloatNode with value -109.864766977 and 1 tape(s)
loss is -103.051604868
Iteration 193 lower bound -85.7167394407
loss is Autograd FloatNode with value -107.301486264 and 1 tape(s)
loss is -109.476412403
Iteration 194 lower bound -80.3418143298
loss is Autograd FloatNode with value -104.167601299 and 1 tape(s)
loss is -125.075589536
Iteration 195 lower bound -65.8035067233
loss is Autograd FloatNode with value -138.22961097 and 1 tape(s)
loss is -107.496064518
Iteration 196 lower bound -84.4786015852
loss is Autograd FloatNode with value -101.16762226 and 1 tape(s)
loss is -106.361022216
Iteration 197 lower bound -86.1693558801
loss is Autograd FloatNode with value -108.553786061 and 1 tape(s)
loss is -94.6284824374
Iteration 198 lower bound -98.5675332008
loss is Autograd FloatNode with value -103.687987606 and 1 tape(s)
loss is -117.74399725
Iteration 199 lower bound -76.0340063064
loss is Autograd FloatNode with value -115.3011618 and 1 tape(s)
loss is -115.150897355
Iteration 200 lower bound -79.4543215307
loss is Autograd FloatNode with value -103.742381164 and 1 tape(s)
loss is -101.723342007
Iteration 201 lower bound -93.6953055748
loss is Autograd FloatNode with value -108.694754305 and 1 tape(s)
loss is -112.599090856
Iteration 202 lower bound -83.7406677305
loss is Autograd FloatNode with value -107.921527142 and 1 tape(s)
loss is -114.772789232
Iteration 203 lower bound -82.5545779319
loss is Autograd FloatNode with value -105.015394227 and 1 tape(s)
loss is -108.101639804
Iteration 204 lower bound -90.2425619888
loss is Autograd FloatNode with value -108.839944534 and 1 tape(s)
loss is -108.967804843
Iteration 205 lower bound -90.5118059012
loss is Autograd FloatNode with value -127.334999002 and 1 tape(s)
loss is -127.983381645
Iteration 206 lower bound -72.4943921128
loss is Autograd FloatNode with value -114.815174525 and 1 tape(s)
loss is -110.726667378
Iteration 207 lower bound -90.3230140265
loss is Autograd FloatNode with value -109.472045627 and 1 tape(s)
loss is -115.063558076
Iteration 208 lower bound -86.6867847426
loss is Autograd FloatNode with value -110.5620701 and 1 tape(s)
loss is -105.97881695
Iteration 209 lower bound -96.5609361041
loss is Autograd FloatNode with value -107.445610588 and 1 tape(s)
loss is -106.713747502
Iteration 210 lower bound -96.5238007042
loss is Autograd FloatNode with value -119.291704777 and 1 tape(s)
loss is -121.332523463
Iteration 211 lower bound -82.5926629111
loss is Autograd FloatNode with value -119.984522295 and 1 tape(s)
loss is -125.075102393
Iteration 212 lower bound -79.4411357734
loss is Autograd FloatNode with value -134.200194149 and 1 tape(s)
loss is -111.14606758
Iteration 213 lower bound -93.9824893414
loss is Autograd FloatNode with value -115.652880869 and 1 tape(s)
loss is -126.493926862
Iteration 214 lower bound -78.3944668849
loss is Autograd FloatNode with value -121.335608529 and 1 tape(s)
loss is -129.123827502
Iteration 215 lower bound -75.6138421679
loss is Autograd FloatNode with value -116.688081563 and 1 tape(s)
loss is -107.86268945
Iteration 216 lower bound -96.9683940587
loss is Autograd FloatNode with value -100.15969461 and 1 tape(s)
loss is -132.222503534
Iteration 217 lower bound -72.8694723179
loss is Autograd FloatNode with value -112.438602366 and 1 tape(s)
loss is -117.775929588
Iteration 218 lower bound -87.7798760487
loss is Autograd FloatNode with value -124.676790633 and 1 tape(s)
loss is -128.093081881
Iteration 219 lower bound -77.8887362416
loss is Autograd FloatNode with value -105.72460304 and 1 tape(s)
loss is -124.061608586
Iteration 220 lower bound -82.2181682274
loss is Autograd FloatNode with value -127.590213458 and 1 tape(s)
loss is -119.176102489
Iteration 221 lower bound -87.6259053317
loss is Autograd FloatNode with value -123.98026657 and 1 tape(s)
loss is -107.869147766
Iteration 222 lower bound -99.2274183136
loss is Autograd FloatNode with value -117.876989357 and 1 tape(s)
loss is -139.670878549
Iteration 223 lower bound -67.6542483656
loss is Autograd FloatNode with value -118.188093679 and 1 tape(s)
loss is -130.353744076
Iteration 224 lower bound -77.2302445889
loss is Autograd FloatNode with value -103.922763242 and 1 tape(s)
loss is -109.280893359
Iteration 225 lower bound -98.7760960182
loss is Autograd FloatNode with value -112.448849181 and 1 tape(s)
loss is -124.763651066
Iteration 226 lower bound -83.9661930864
loss is Autograd FloatNode with value -121.783947495 and 1 tape(s)
loss is -159.490506081
Iteration 227 lower bound -49.8818667418
loss is Autograd FloatNode with value -120.0208831 and 1 tape(s)
loss is -125.176354453
Iteration 228 lower bound -84.8308085443
loss is Autograd FloatNode with value -129.054535716 and 1 tape(s)
loss is -115.295975739
Iteration 229 lower bound -95.1757131394
loss is Autograd FloatNode with value -116.136394132 and 1 tape(s)
loss is -107.419427508
Iteration 230 lower bound -103.437224909
loss is Autograd FloatNode with value -116.618708796 and 1 tape(s)
loss is -116.351141611
Iteration 231 lower bound -94.9104590374
loss is Autograd FloatNode with value -113.313706231 and 1 tape(s)
loss is -113.339688839
Iteration 232 lower bound -98.1132221815
loss is Autograd FloatNode with value -114.977402985 and 1 tape(s)
loss is -114.345475706
Iteration 233 lower bound -97.3101311659
loss is Autograd FloatNode with value -141.119652544 and 1 tape(s)
loss is -128.913181947
Iteration 234 lower bound -83.0636359915
loss is Autograd FloatNode with value -121.555871777 and 1 tape(s)
loss is -108.419867005
Iteration 235 lower bound -103.629550217
loss is Autograd FloatNode with value -114.840550151 and 1 tape(s)
loss is -108.552789292
Iteration 236 lower bound -103.424186338
loss is Autograd FloatNode with value -113.032014677 and 1 tape(s)
loss is -107.338411404
Iteration 237 lower bound -104.585368949
loss is Autograd FloatNode with value -116.018144226 and 1 tape(s)
loss is -100.555467596
Iteration 238 lower bound -111.286558277
loss is Autograd FloatNode with value -105.296461198 and 1 tape(s)
loss is -106.656128099
Iteration 239 lower bound -105.178735578
loss is Autograd FloatNode with value -102.13854303 and 1 tape(s)
loss is -104.578578078
Iteration 240 lower bound -107.463822435
loss is Autograd FloatNode with value -111.258594697 and 1 tape(s)
loss is -105.356542216
Iteration 241 lower bound -107.07520884
loss is Autograd FloatNode with value -109.203039809 and 1 tape(s)
loss is -110.702459926
Iteration 242 lower bound -102.259862843
loss is Autograd FloatNode with value -104.762064094 and 1 tape(s)
loss is -114.052075377
Iteration 243 lower bound -99.4267986358
loss is Autograd FloatNode with value -113.986697702 and 1 tape(s)
loss is -126.770648381
Iteration 244 lower bound -87.236788028
loss is Autograd FloatNode with value -129.47677315 and 1 tape(s)
loss is -129.960539019
Iteration 245 lower bound -84.7583880209
loss is Autograd FloatNode with value -144.281525665 and 1 tape(s)
loss is -108.664986945
Iteration 246 lower bound -106.411947376
loss is Autograd FloatNode with value -105.7062636 and 1 tape(s)
loss is -109.849228417
Iteration 247 lower bound -104.739020951
loss is Autograd FloatNode with value -100.478681048 and 1 tape(s)
loss is -112.131518768
Iteration 248 lower bound -102.16889283
loss is Autograd FloatNode with value -100.181692865 and 1 tape(s)
loss is -110.592134993
Iteration 249 lower bound -103.713552753
loss is Autograd FloatNode with value -112.189550179 and 1 tape(s)
loss is -119.771486155
Iteration 250 lower bound -94.8292855691
loss is Autograd FloatNode with value -103.797114851 and 1 tape(s)
loss is -116.475838799
Iteration 251 lower bound -98.4780865482
loss is Autograd FloatNode with value -106.442628938 and 1 tape(s)
loss is -112.381176679
Iteration 252 lower bound -103.03074129
loss is Autograd FloatNode with value -107.707797037 and 1 tape(s)
loss is -107.989879946
Iteration 253 lower bound -107.950192695
loss is Autograd FloatNode with value -101.89012509 and 1 tape(s)
loss is -110.817065337
Iteration 254 lower bound -105.642329526
loss is Autograd FloatNode with value -115.626760848 and 1 tape(s)
loss is -104.763423143
Iteration 255 lower bound -112.322704467
loss is Autograd FloatNode with value -101.127432467 and 1 tape(s)
loss is -107.826752653
Iteration 256 lower bound -109.831778761
loss is Autograd FloatNode with value -109.075868622 and 1 tape(s)
loss is -107.550201285
Iteration 257 lower bound -110.891252575
loss is Autograd FloatNode with value -119.750402369 and 1 tape(s)
loss is -101.864062483
Iteration 258 lower bound -117.388890054
loss is Autograd FloatNode with value -112.309144943 and 1 tape(s)
loss is -103.774105193
Iteration 259 lower bound -116.079228871
loss is Autograd FloatNode with value -113.732718918 and 1 tape(s)
loss is -108.787223119
Iteration 260 lower bound -111.575955714
loss is Autograd FloatNode with value -127.332431167 and 1 tape(s)
loss is -111.939632952
Iteration 261 lower bound -108.911533893
loss is Autograd FloatNode with value -111.359165924 and 1 tape(s)
loss is -115.323016442
Iteration 262 lower bound -105.625350412
loss is Autograd FloatNode with value -110.700584215 and 1 tape(s)
loss is -108.104032353
Iteration 263 lower bound -113.003808359
loss is Autograd FloatNode with value -112.287078856 and 1 tape(s)
loss is -123.848500146
Iteration 264 lower bound -97.4653074244
loss is Autograd FloatNode with value -114.853528815 and 1 tape(s)
loss is -107.383785959
Iteration 265 lower bound -114.254178485
loss is Autograd FloatNode with value -115.576946466 and 1 tape(s)
loss is -121.4697818
Iteration 266 lower bound -100.49184986
loss is Autograd FloatNode with value -109.68097691 and 1 tape(s)
loss is -104.842955471
Iteration 267 lower bound -117.388573855
loss is Autograd FloatNode with value -122.435806237 and 1 tape(s)
loss is -113.98777022
Iteration 268 lower bound -108.508819961
loss is Autograd FloatNode with value -110.554776525 and 1 tape(s)
loss is -117.971297554
Iteration 269 lower bound -104.655566266
loss is Autograd FloatNode with value -104.45428964 and 1 tape(s)
loss is -113.310468265
Iteration 270 lower bound -109.358532035
loss is Autograd FloatNode with value -104.437513773 and 1 tape(s)
loss is -114.65231306
Iteration 271 lower bound -108.125611161
loss is Autograd FloatNode with value -125.725811249 and 1 tape(s)
loss is -110.963381768
Iteration 272 lower bound -111.978902741
loss is Autograd FloatNode with value -126.963966232 and 1 tape(s)
loss is -107.406114187
Iteration 273 lower bound -115.293445548
loss is Autograd FloatNode with value -109.905948672 and 1 tape(s)
loss is -105.100421475
Iteration 274 lower bound -117.0222931
loss is Autograd FloatNode with value -103.980294031 and 1 tape(s)
loss is -103.171277457
Iteration 275 lower bound -118.567448452
loss is Autograd FloatNode with value -116.202448583 and 1 tape(s)
loss is -105.437863654
Iteration 276 lower bound -116.00054436
loss is Autograd FloatNode with value -102.640753671 and 1 tape(s)
loss is -93.2246003148
Iteration 277 lower bound -127.971931432
loss is Autograd FloatNode with value -98.9953739172 and 1 tape(s)
loss is -104.508699185
Iteration 278 lower bound -116.538237482
loss is Autograd FloatNode with value -109.853193995 and 1 tape(s)
loss is -109.800203656
Iteration 279 lower bound -111.410206096
loss is Autograd FloatNode with value -112.440477497 and 1 tape(s)
loss is -114.359824821
Iteration 280 lower bound -107.080001329
loss is Autograd FloatNode with value -96.264090399 and 1 tape(s)
loss is -102.309382917
Iteration 281 lower bound -119.471123505
loss is Autograd FloatNode with value -110.122251873 and 1 tape(s)
loss is -101.514432422
Iteration 282 lower bound -120.85003459
loss is Autograd FloatNode with value -105.825167906 and 1 tape(s)
loss is -107.419246027
Iteration 283 lower bound -115.528041523
loss is Autograd FloatNode with value -103.677048908 and 1 tape(s)
loss is -101.727335197
Iteration 284 lower bound -121.79245527
loss is Autograd FloatNode with value -101.703771836 and 1 tape(s)
loss is -98.8419909365
Iteration 285 lower bound -125.372299647
loss is Autograd FloatNode with value -109.86374035 and 1 tape(s)
loss is -100.831909154
Iteration 286 lower bound -124.231840574
loss is Autograd FloatNode with value -101.163050162 and 1 tape(s)
loss is -110.409819929
Iteration 287 lower bound -115.569981505
loss is Autograd FloatNode with value -104.875556072 and 1 tape(s)
loss is -119.804399567
Iteration 288 lower bound -107.269809348
loss is Autograd FloatNode with value -100.910698252 and 1 tape(s)
loss is -110.79523694
Iteration 289 lower bound -117.261796883
loss is Autograd FloatNode with value -102.730905968 and 1 tape(s)
loss is -127.273664548
Iteration 290 lower bound -101.923370999
loss is Autograd FloatNode with value -104.455658373 and 1 tape(s)
loss is -106.002885205
Iteration 291 lower bound -124.331564299
loss is Autograd FloatNode with value -117.328338287 and 1 tape(s)
loss is -112.411014671
Iteration 292 lower bound -118.983360227
loss is Autograd FloatNode with value -107.109436314 and 1 tape(s)
loss is -148.104582761
Iteration 293 lower bound -83.9837552393
loss is Autograd FloatNode with value -116.687729588 and 1 tape(s)
loss is -115.550320374
Iteration 294 lower bound -117.058192984
loss is Autograd FloatNode with value -111.528236092 and 1 tape(s)
loss is -102.589506272
Iteration 295 lower bound -130.366179463
loss is Autograd FloatNode with value -105.580181954 and 1 tape(s)
loss is -104.897666506
Iteration 296 lower bound -128.457271972
loss is Autograd FloatNode with value -103.04105336 and 1 tape(s)
loss is -109.527819439
Iteration 297 lower bound -124.391353196
loss is Autograd FloatNode with value -113.795532115 and 1 tape(s)
loss is -107.201919926
Iteration 298 lower bound -127.345980341
loss is Autograd FloatNode with value -109.55513744 and 1 tape(s)
loss is -104.598360182
Iteration 299 lower bound -130.49396151
loss is Autograd FloatNode with value -108.113525452 and 1 tape(s)
loss is -106.60877366
Iteration 300 lower bound -129.007748675
loss is Autograd FloatNode with value -111.104266274 and 1 tape(s)
loss is -110.337546672
Iteration 301 lower bound -125.779576165
loss is Autograd FloatNode with value -118.254776471 and 1 tape(s)
loss is -103.860651493
Iteration 302 lower bound -132.71118735
loss is Autograd FloatNode with value -112.115162811 and 1 tape(s)
loss is -100.305254198
Iteration 303 lower bound -136.511963333
loss is Autograd FloatNode with value -108.475799873 and 1 tape(s)
loss is -131.339105309
Iteration 304 lower bound -105.587405141
loss is Autograd FloatNode with value -103.846617376 and 1 tape(s)
loss is -106.372300525
Iteration 305 lower bound -130.750394287
loss is Autograd FloatNode with value -112.966462421 and 1 tape(s)
loss is -115.969452068
Iteration 306 lower bound -121.463174927
loss is Autograd FloatNode with value -104.8763055 and 1 tape(s)
loss is -112.027316435
Iteration 307 lower bound -125.733437603
loss is Autograd FloatNode with value -109.191731098 and 1 tape(s)
loss is -111.253072876
Iteration 308 lower bound -126.872120572
loss is Autograd FloatNode with value -107.922340024 and 1 tape(s)
loss is -112.627095012
Iteration 309 lower bound -125.910476312
loss is Autograd FloatNode with value -116.195809399 and 1 tape(s)
loss is -108.492780124
Iteration 310 lower bound -130.354309148
loss is Autograd FloatNode with value -112.122793294 and 1 tape(s)
loss is -108.115887218
Iteration 311 lower bound -131.046723603
loss is Autograd FloatNode with value -107.008794584 and 1 tape(s)
loss is -116.700271443
Iteration 312 lower bound -122.581389382
loss is Autograd FloatNode with value -123.886624754 and 1 tape(s)
loss is -121.387794363
Iteration 313 lower bound -118.194128057
loss is Autograd FloatNode with value -131.683572168 and 1 tape(s)
loss is -132.111279911
Iteration 314 lower bound -107.745285406
loss is Autograd FloatNode with value -99.4824967683 and 1 tape(s)
loss is -116.647907616
Iteration 315 lower bound -122.818229067
loss is Autograd FloatNode with value -116.88697363 and 1 tape(s)
loss is -120.197057477
Iteration 316 lower bound -119.091658812
loss is Autograd FloatNode with value -113.934902274 and 1 tape(s)
loss is -121.58040985
Iteration 317 lower bound -117.551997343
loss is Autograd FloatNode with value -110.67787261 and 1 tape(s)
loss is -110.691753662
Iteration 318 lower bound -128.451442098
loss is Autograd FloatNode with value -113.706491295 and 1 tape(s)
loss is -105.144387697
Iteration 319 lower bound -133.995338079
loss is Autograd FloatNode with value -116.865969492 and 1 tape(s)
loss is -120.321001566
Iteration 320 lower bound -118.774904427
loss is Autograd FloatNode with value -117.59921395 and 1 tape(s)
loss is -120.482154102
Iteration 321 lower bound -118.672131473
loss is Autograd FloatNode with value -101.337831365 and 1 tape(s)
loss is -100.647265694
Iteration 322 lower bound -138.681926451
loss is Autograd FloatNode with value -109.078259783 and 1 tape(s)
loss is -110.119294305
Iteration 323 lower bound -129.60002108
loss is Autograd FloatNode with value -106.910882377 and 1 tape(s)
loss is -110.460359348
Iteration 324 lower bound -129.712563439
loss is Autograd FloatNode with value -106.775153959 and 1 tape(s)
loss is -107.431871473
Iteration 325 lower bound -133.365010129
loss is Autograd FloatNode with value -107.861361852 and 1 tape(s)
loss is -113.46874273
Iteration 326 lower bound -128.083233434
loss is Autograd FloatNode with value -107.013859903 and 1 tape(s)
loss is -107.978409005
Iteration 327 lower bound -134.411561788
loss is Autograd FloatNode with value -117.173499338 and 1 tape(s)
loss is -113.850960748
Iteration 328 lower bound -129.510257373
loss is Autograd FloatNode with value -110.95317104 and 1 tape(s)
loss is -116.094554746
Iteration 329 lower bound -128.29284486
loss is Autograd FloatNode with value -123.204436067 and 1 tape(s)
loss is -107.905796794
Iteration 330 lower bound -137.518837671
loss is Autograd FloatNode with value -119.321380367 and 1 tape(s)
loss is -134.128672738
Iteration 331 lower bound -111.93337419
loss is Autograd FloatNode with value -114.139509038 and 1 tape(s)
loss is -113.703862567
Iteration 332 lower bound -133.048414252
loss is Autograd FloatNode with value -120.033478686 and 1 tape(s)
loss is -126.090933736
Iteration 333 lower bound -121.399142706
loss is Autograd FloatNode with value -115.401966156 and 1 tape(s)
loss is -103.530602852
Iteration 334 lower bound -144.759817178
loss is Autograd FloatNode with value -111.388436308 and 1 tape(s)
loss is -113.636800797
Iteration 335 lower bound -135.384862152
loss is Autograd FloatNode with value -116.198661571 and 1 tape(s)
loss is -116.022860014
Iteration 336 lower bound -133.676568301
loss is Autograd FloatNode with value -132.186797956 and 1 tape(s)
loss is -99.8644084114
Iteration 337 lower bound -150.040325958
loss is Autograd FloatNode with value -119.814984749 and 1 tape(s)
loss is -110.030370959
Iteration 338 lower bound -139.517576612
loss is Autograd FloatNode with value -111.819015973 and 1 tape(s)
loss is -104.616921309
Iteration 339 lower bound -144.59695684
loss is Autograd FloatNode with value -115.870647254 and 1 tape(s)
loss is -111.178030392
Iteration 340 lower bound -137.756964207
loss is Autograd FloatNode with value -110.217727873 and 1 tape(s)
loss is -125.398977692
Iteration 341 lower bound -123.187394925
loss is Autograd FloatNode with value -114.099036146 and 1 tape(s)
loss is -113.913041726
Iteration 342 lower bound -134.543661133
loss is Autograd FloatNode with value -105.656718134 and 1 tape(s)
loss is -117.235080582
Iteration 343 lower bound -131.220564403
loss is Autograd FloatNode with value -108.780181481 and 1 tape(s)
loss is -108.12841074
Iteration 344 lower bound -140.416548878
loss is Autograd FloatNode with value -118.041429939 and 1 tape(s)
loss is -117.453859936
Iteration 345 lower bound -131.1838989
loss is Autograd FloatNode with value -114.53620353 and 1 tape(s)
loss is -105.887750745
Iteration 346 lower bound -142.849922284
loss is Autograd FloatNode with value -109.857620979 and 1 tape(s)
loss is -112.970522739
Iteration 347 lower bound -135.853399672
loss is Autograd FloatNode with value -101.829276795 and 1 tape(s)
loss is -111.785917869
Iteration 348 lower bound -137.086488429
loss is Autograd FloatNode with value -112.520082226 and 1 tape(s)
loss is -104.773925474
Iteration 349 lower bound -144.250484357
loss is Autograd FloatNode with value -97.4664460875 and 1 tape(s)
loss is -107.407476956
Iteration 350 lower bound -141.727636329
loss is Autograd FloatNode with value -115.151941446 and 1 tape(s)
loss is -111.440115107
Iteration 351 lower bound -138.011555606
loss is Autograd FloatNode with value -118.463048662 and 1 tape(s)
loss is -108.030253477
Iteration 352 lower bound -141.638749348
loss is Autograd FloatNode with value -113.752581418 and 1 tape(s)
loss is -106.288829673
Iteration 353 lower bound -143.503986061
loss is Autograd FloatNode with value -120.938946921 and 1 tape(s)
loss is -129.810387314
Iteration 354 lower bound -119.819763122
loss is Autograd FloatNode with value -212.575037377 and 1 tape(s)
loss is -106.714683747
Iteration 355 lower bound -142.747889596
loss is Autograd FloatNode with value -112.187256731 and 1 tape(s)
loss is -101.42246218
Iteration 356 lower bound -148.437830338
loss is Autograd FloatNode with value -103.576071416 and 1 tape(s)
loss is -106.360992871
Iteration 357 lower bound -143.806103758
loss is Autograd FloatNode with value -105.574692937 and 1 tape(s)
loss is -109.810021207
Iteration 358 lower bound -140.741411451
loss is Autograd FloatNode with value -140.157464737 and 1 tape(s)
loss is -116.280996153
Iteration 359 lower bound -134.66391013
loss is Autograd FloatNode with value -108.486452621 and 1 tape(s)
loss is -104.884150682
Iteration 360 lower bound -146.852604195
loss is Autograd FloatNode with value -130.675039591 and 1 tape(s)
loss is -243.973000002
Iteration 361 lower bound -8.45371535856
loss is Autograd FloatNode with value -170.042120555 and 1 tape(s)
loss is -139.531464291
Iteration 362 lower bound -113.023870504
loss is Autograd FloatNode with value -147.02000572 and 1 tape(s)
loss is -139.558095416
Iteration 363 lower bound -112.934800024
loss is Autograd FloatNode with value -119.9510469 and 1 tape(s)
loss is -103.486235677
Iteration 364 lower bound -148.955170086
loss is Autograd FloatNode with value -123.112522128 and 1 tape(s)
loss is -173.4705485
Iteration 365 lower bound -78.6416519
loss is Autograd FloatNode with value -111.827011869 and 1 tape(s)
loss is -128.403072352
Iteration 366 lower bound -123.112356096
Optimizing variational parameters...
loss is Autograd FloatNode with value -2422.31797449 and 1 tape(s)
loss is -2436.49788154
Optimizing variational parameters...
loss is Autograd FloatNode with value -2422.31797449 and 1 tape(s)
loss is -2436.49788154
Iteration 0 lower bound 2977.23816303
loss is Autograd FloatNode with value -1114.17239711 and 1 tape(s)
loss is -1124.85416402
Iteration 1 lower bound 1651.49444564
loss is Autograd FloatNode with value -1761.60320917 and 1 tape(s)
loss is -1765.46457084
Iteration 2 lower bound 2277.82238271
loss is Autograd FloatNode with value -1133.52757505 and 1 tape(s)
loss is -1144.06660439
Iteration 3 lower bound 1642.41448941
loss is Autograd FloatNode with value -772.186729058 and 1 tape(s)
loss is -773.138103273
Iteration 4 lower bound 1257.36729407
loss is Autograd FloatNode with value -942.129157165 and 1 tape(s)
loss is -937.792996787
Iteration 5 lower bound 1407.76504395
loss is Autograd FloatNode with value -979.8860096 and 1 tape(s)
loss is -983.54874533
Iteration 6 lower bound 1439.25380529
loss is Autograd FloatNode with value -734.13868038 and 1 tape(s)
loss is -743.705611179
Iteration 7 lower bound 1185.14686671
loss is Autograd FloatNode with value -527.949208998 and 1 tape(s)
loss is -524.725148182
Iteration 8 lower bound 951.882321602
loss is Autograd FloatNode with value -569.654702149 and 1 tape(s)
loss is -567.365562079
Iteration 9 lower bound 980.210736383
loss is Autograd FloatNode with value -700.794588036 and 1 tape(s)
loss is -689.996532238
Iteration 10 lower bound 1088.50163892
loss is Autograd FloatNode with value -630.792672678 and 1 tape(s)
loss is -614.124595091
Iteration 11 lower bound 998.395800144
loss is Autograd FloatNode with value -461.75909127 and 1 tape(s)
loss is -463.891739312
Iteration 12 lower bound 834.025073962
loss is Autograd FloatNode with value -438.381165863 and 1 tape(s)
loss is -433.803981051
Iteration 13 lower bound 789.784353637
loss is Autograd FloatNode with value -491.326700321 and 1 tape(s)
loss is -493.979778006
Iteration 14 lower bound 835.844841858
loss is Autograd FloatNode with value -503.594368455 and 1 tape(s)
loss is -489.570664777
Iteration 15 lower bound 817.33275837
loss is Autograd FloatNode with value -392.920131995 and 1 tape(s)
loss is -399.700951496
Iteration 16 lower bound 713.506471895
loss is Autograd FloatNode with value -340.371637894 and 1 tape(s)
loss is -339.628089309
Iteration 17 lower bound 639.482483648
loss is Autograd FloatNode with value -378.600126816 and 1 tape(s)
loss is -377.712951025
Iteration 18 lower bound 663.594048998
loss is Autograd FloatNode with value -405.330217583 and 1 tape(s)
loss is -414.500494222
Iteration 19 lower bound 686.464204174
loss is Autograd FloatNode with value -345.154633895 and 1 tape(s)
loss is -346.388701601
Iteration 20 lower bound 604.555866286
loss is Autograd FloatNode with value -293.379727737 and 1 tape(s)
loss is -296.438990445
Iteration 21 lower bound 540.819967342
loss is Autograd FloatNode with value -299.949534392 and 1 tape(s)
loss is -301.720277796
Iteration 22 lower bound 532.321950161
loss is Autograd FloatNode with value -337.406419793 and 1 tape(s)
loss is -330.297406392
Iteration 23 lower bound 547.18162702
loss is Autograd FloatNode with value -296.448939175 and 1 tape(s)
loss is -299.425933147
Iteration 24 lower bound 502.802505036
loss is Autograd FloatNode with value -244.510110268 and 1 tape(s)
loss is -248.618629093
Iteration 25 lower bound 438.666389103
loss is Autograd FloatNode with value -249.754948375 and 1 tape(s)
loss is -251.074604205
Iteration 26 lower bound 427.822656597
loss is Autograd FloatNode with value -253.734288013 and 1 tape(s)
loss is -269.475418302
Iteration 27 lower bound 433.090424504
loss is Autograd FloatNode with value -236.895378589 and 1 tape(s)
loss is -251.890413032
Iteration 28 lower bound 402.530966384
loss is Autograd FloatNode with value -207.044079535 and 1 tape(s)
loss is -202.619212762
Iteration 29 lower bound 340.474281625
loss is Autograd FloatNode with value -199.902612265 and 1 tape(s)
loss is -189.000540034
Iteration 30 lower bound 314.214955629
loss is Autograd FloatNode with value -211.253308026 and 1 tape(s)
loss is -190.963305857
Iteration 31 lower bound 303.978696176
loss is Autograd FloatNode with value -191.427389697 and 1 tape(s)
loss is -180.288281666
Iteration 32 lower bound 281.732278329
loss is Autograd FloatNode with value -164.514095444 and 1 tape(s)
loss is -171.057417759
Iteration 33 lower bound 261.415332303
loss is Autograd FloatNode with value -155.48760804 and 1 tape(s)
loss is -179.854899427
Iteration 34 lower bound 259.584637947
loss is Autograd FloatNode with value -193.954043749 and 1 tape(s)
loss is -209.864985303
Iteration 35 lower bound 279.22440244
loss is Autograd FloatNode with value -160.265810355 and 1 tape(s)
loss is -164.864950779
Iteration 36 lower bound 224.635427869
loss is Autograd FloatNode with value -155.729439279 and 1 tape(s)
loss is -150.985202592
Iteration 37 lower bound 201.522580647
loss is Autograd FloatNode with value -150.590807386 and 1 tape(s)
loss is -145.196443426
Iteration 38 lower bound 187.325414926
loss is Autograd FloatNode with value -174.863988854 and 1 tape(s)
loss is -170.479383795
Iteration 39 lower bound 204.789785057
loss is Autograd FloatNode with value -187.016584306 and 1 tape(s)
loss is -172.702833202
Iteration 40 lower bound 199.643780346
loss is Autograd FloatNode with value -168.916451453 and 1 tape(s)
loss is -162.020807558
Iteration 41 lower bound 182.724885139
loss is Autograd FloatNode with value -186.932839954 and 1 tape(s)
loss is -223.557088368
Iteration 42 lower bound 238.831972265
loss is Autograd FloatNode with value -191.491248047 and 1 tape(s)
loss is -168.760873754
Iteration 43 lower bound 179.435449102
loss is Autograd FloatNode with value -155.480543377 and 1 tape(s)
loss is -200.574543124
Iteration 44 lower bound 207.500950104
loss is Autograd FloatNode with value -161.67743378 and 1 tape(s)
loss is -201.038013237
Iteration 45 lower bound 204.240559944
loss is Autograd FloatNode with value -185.795942264 and 1 tape(s)
loss is -154.266918076
Iteration 46 lower bound 153.514126819
loss is Autograd FloatNode with value -138.3559617 and 1 tape(s)
loss is -171.07782571
Iteration 47 lower bound 166.573835858
loss is Autograd FloatNode with value -191.362134288 and 1 tape(s)
loss is -185.356937778
Iteration 48 lower bound 177.553154128
loss is Autograd FloatNode with value -211.902855314 and 1 tape(s)
loss is -174.038119041
Iteration 49 lower bound 163.845217582
loss is Autograd FloatNode with value -157.042909017 and 1 tape(s)
loss is -164.725039114
Iteration 50 lower bound 152.912818076
loss is Autograd FloatNode with value -133.778742105 and 1 tape(s)
loss is -156.719137198
Iteration 51 lower bound 143.230932921
loss is Autograd FloatNode with value -147.824267502 and 1 tape(s)
loss is -171.748394414
Iteration 52 lower bound 156.347505886
loss is Autograd FloatNode with value -160.100574672 and 1 tape(s)
loss is -174.585743055
Iteration 53 lower bound 157.456431619
loss is Autograd FloatNode with value -181.62093019 and 1 tape(s)
loss is -142.768058364
Iteration 54 lower bound 123.810234924
loss is Autograd FloatNode with value -148.364353183 and 1 tape(s)
loss is -167.35784642
Iteration 55 lower bound 146.759219403
loss is Autograd FloatNode with value -116.722863131 and 1 tape(s)
loss is -120.619509734
Iteration 56 lower bound 98.6852860418
loss is Autograd FloatNode with value -168.466829865 and 1 tape(s)
loss is -150.67207666
Iteration 57 lower bound 127.508604472
loss is Autograd FloatNode with value -167.887335325 and 1 tape(s)
loss is -181.473481099
Iteration 58 lower bound 156.868582911
loss is Autograd FloatNode with value -138.244953547 and 1 tape(s)
loss is -128.383051013
Iteration 59 lower bound 101.941217568
loss is Autograd FloatNode with value -178.58282171 and 1 tape(s)
loss is -103.523364099
Iteration 60 lower bound 75.416039458
loss is Autograd FloatNode with value -139.374832755 and 1 tape(s)
loss is -130.25636753
Iteration 61 lower bound 101.197306252
loss is Autograd FloatNode with value -131.532751485 and 1 tape(s)
loss is -141.082544483
Iteration 62 lower bound 111.3549182
loss is Autograd FloatNode with value -127.560422267 and 1 tape(s)
loss is -137.868160109
Iteration 63 lower bound 107.570233003
loss is Autograd FloatNode with value -114.04681844 and 1 tape(s)
loss is -145.24958594
Iteration 64 lower bound 114.110559398
loss is Autograd FloatNode with value -130.290032414 and 1 tape(s)
loss is -124.630310481
Iteration 65 lower bound 92.2810408942
loss is Autograd FloatNode with value -130.757419749 and 1 tape(s)
loss is -113.60737636
Iteration 66 lower bound 79.8128846039
loss is Autograd FloatNode with value -130.541799145 and 1 tape(s)
loss is -134.75602714
Iteration 67 lower bound 99.8200742452
loss is Autograd FloatNode with value -113.723414367 and 1 tape(s)
loss is -103.387929592
Iteration 68 lower bound 67.5630108658
loss is Autograd FloatNode with value -93.4304634665 and 1 tape(s)
loss is -83.3299538148
Iteration 69 lower bound 46.5600176417
loss is Autograd FloatNode with value -110.036355903 and 1 tape(s)
loss is -107.188433032
Iteration 70 lower bound 69.1070508069
loss is Autograd FloatNode with value -104.437788731 and 1 tape(s)
loss is -119.07678814
Iteration 71 lower bound 79.4274328772
loss is Autograd FloatNode with value -108.955698573 and 1 tape(s)
loss is -90.3237878335
Iteration 72 lower bound 48.8034644142
loss is Autograd FloatNode with value -112.303781482 and 1 tape(s)
loss is -103.088064415
Iteration 73 lower bound 59.5812194304
loss is Autograd FloatNode with value -95.1240538681 and 1 tape(s)
loss is -99.5186799067
Iteration 74 lower bound 54.0026554659
loss is Autograd FloatNode with value -89.6892857835 and 1 tape(s)
loss is -102.789072403
Iteration 75 lower bound 55.0602523931
loss is Autograd FloatNode with value -103.296642061 and 1 tape(s)
loss is -96.2797074734
Iteration 76 lower bound 46.0964449456
loss is Autograd FloatNode with value -114.867920403 and 1 tape(s)
loss is -110.209010041
Iteration 77 lower bound 57.4630310447
loss is Autograd FloatNode with value -102.247626884 and 1 tape(s)
loss is -103.352139735
Iteration 78 lower bound 48.1479733302
loss is Autograd FloatNode with value -111.985091934 and 1 tape(s)
loss is -107.097494388
Iteration 79 lower bound 49.3032123776
loss is Autograd FloatNode with value -105.761268657 and 1 tape(s)
loss is -91.8298365184
Iteration 80 lower bound 31.3448861949
loss is Autograd FloatNode with value -114.429791625 and 1 tape(s)
loss is -90.9728594208
Iteration 81 lower bound 27.8817661419
loss is Autograd FloatNode with value -130.483025305 and 1 tape(s)
loss is -113.227257369
Iteration 82 lower bound 47.7321694713
loss is Autograd FloatNode with value -111.330165646 and 1 tape(s)
loss is -116.237844892
Iteration 83 lower bound 48.5001173668
loss is Autograd FloatNode with value -94.5034318622 and 1 tape(s)
loss is -102.796421026
Iteration 84 lower bound 33.079399103
loss is Autograd FloatNode with value -120.807561513 and 1 tape(s)
loss is -102.597456775
Iteration 85 lower bound 30.8103443687
loss is Autograd FloatNode with value -101.974463081 and 1 tape(s)
loss is -105.962833367
Iteration 86 lower bound 32.2467850831
loss is Autograd FloatNode with value -114.967720995 and 1 tape(s)
loss is -111.918085118
Iteration 87 lower bound 36.2895479768
loss is Autograd FloatNode with value -122.006213304 and 1 tape(s)
loss is -101.108422155
Iteration 88 lower bound 23.5034349665
loss is Autograd FloatNode with value -105.496286815 and 1 tape(s)
loss is -109.664299683
Iteration 89 lower bound 30.2798185633
loss is Autograd FloatNode with value -105.260762847 and 1 tape(s)
loss is -104.313570253
Iteration 90 lower bound 23.2154551121
loss is Autograd FloatNode with value -105.030187713 and 1 tape(s)
loss is -100.322436312
Iteration 91 lower bound 17.5184296675
loss is Autograd FloatNode with value -115.846884973 and 1 tape(s)
loss is -105.356601064
Iteration 92 lower bound 20.7994305534
loss is Autograd FloatNode with value -105.975870311 and 1 tape(s)
loss is -94.0953903153
Iteration 93 lower bound 7.98227775632
loss is Autograd FloatNode with value -93.0482984354 and 1 tape(s)
loss is -109.660015471
Iteration 94 lower bound 22.0071206477
loss is Autograd FloatNode with value -129.441410011 and 1 tape(s)
loss is -121.412446972
Iteration 95 lower bound 32.0361893348
loss is Autograd FloatNode with value -102.366729612 and 1 tape(s)
loss is -122.764931784
Iteration 96 lower bound 31.7628104744
loss is Autograd FloatNode with value -100.397304204 and 1 tape(s)
loss is -91.2993221306
Iteration 97 lower bound -1.33992430658
loss is Autograd FloatNode with value -108.072708542 and 1 tape(s)
loss is -101.3712457
Iteration 98 lower bound 7.04735051383
loss is Autograd FloatNode with value -107.315434159 and 1 tape(s)
loss is -98.7387958989
Iteration 99 lower bound 2.78944116264
loss is Autograd FloatNode with value -98.4991669853 and 1 tape(s)
loss is -106.062952415
Iteration 100 lower bound 8.55186439089
loss is Autograd FloatNode with value -105.870930273 and 1 tape(s)
loss is -101.040149434
Iteration 101 lower bound 1.93469902751
loss is Autograd FloatNode with value -88.3291209302 and 1 tape(s)
loss is -116.115958995
Iteration 102 lower bound 15.4144519286
loss is Autograd FloatNode with value -95.0261853058 and 1 tape(s)
loss is -96.8276963969
Iteration 103 lower bound -5.73904085887
loss is Autograd FloatNode with value -109.14894348 and 1 tape(s)
loss is -106.628493589
Iteration 104 lower bound 2.13601205116
loss is Autograd FloatNode with value -94.8050494496 and 1 tape(s)
loss is -114.910746368
Iteration 105 lower bound 8.53492553255
loss is Autograd FloatNode with value -106.418505492 and 1 tape(s)
loss is -107.404709855
Iteration 106 lower bound -0.891029680949
loss is Autograd FloatNode with value -97.1443534853 and 1 tape(s)
loss is -101.006533761
Iteration 107 lower bound -9.10666123265
loss is Autograd FloatNode with value -121.875518999 and 1 tape(s)
loss is -112.688805635
Iteration 108 lower bound 0.741555845256
loss is Autograd FloatNode with value -104.670428574 and 1 tape(s)
loss is -107.493202224
Iteration 109 lower bound -5.94425173981
loss is Autograd FloatNode with value -112.257420728 and 1 tape(s)
loss is -122.535244433
Iteration 110 lower bound 7.61823205647
loss is Autograd FloatNode with value -107.92715326 and 1 tape(s)
loss is -97.5224828501
Iteration 111 lower bound -18.8267279066
loss is Autograd FloatNode with value -117.093039153 and 1 tape(s)
loss is -106.433672807
Iteration 112 lower bound -11.3206842481
loss is Autograd FloatNode with value -112.825562216 and 1 tape(s)
loss is -100.980440827
Iteration 113 lower bound -18.1152082608
loss is Autograd FloatNode with value -108.473621744 and 1 tape(s)
loss is -104.024595073
Iteration 114 lower bound -16.4128076049
loss is Autograd FloatNode with value -119.309474311 and 1 tape(s)
loss is -102.901586608
Iteration 115 lower bound -18.970579631
loss is Autograd FloatNode with value -115.898892209 and 1 tape(s)
loss is -126.691063526
Iteration 116 lower bound 3.37624862411
loss is Autograd FloatNode with value -103.929691673 and 1 tape(s)
loss is -98.6516880435
Iteration 117 lower bound -26.1012024693
loss is Autograd FloatNode with value -105.399186314 and 1 tape(s)
loss is -111.710997442
Iteration 118 lower bound -14.5560360381
loss is Autograd FloatNode with value -119.667187631 and 1 tape(s)
loss is -110.536082664
Iteration 119 lower bound -17.306136147
loss is Autograd FloatNode with value -95.6814654775 and 1 tape(s)
loss is -99.707972504
Iteration 120 lower bound -29.5557503863
loss is Autograd FloatNode with value -102.350628226 and 1 tape(s)
loss is -102.164089363
Iteration 121 lower bound -28.734350369
loss is Autograd FloatNode with value -111.840933959 and 1 tape(s)
loss is -96.2968902092
Iteration 122 lower bound -36.2250988622
loss is Autograd FloatNode with value -103.838532743 and 1 tape(s)
loss is -115.82518479
Iteration 123 lower bound -18.1359434397
loss is Autograd FloatNode with value -106.862340282 and 1 tape(s)
loss is -106.053339134
Iteration 124 lower bound -29.3342313968
loss is Autograd FloatNode with value -99.4692763802 and 1 tape(s)
loss is -96.3336584814
Iteration 125 lower bound -40.422988515
loss is Autograd FloatNode with value -106.749645004 and 1 tape(s)
loss is -100.546261404
Iteration 126 lower bound -37.6897929515
loss is Autograd FloatNode with value -112.689108222 and 1 tape(s)
loss is -103.820844575
Iteration 127 lower bound -35.8580808553
loss is Autograd FloatNode with value -113.479730718 and 1 tape(s)
loss is -117.586321613
Iteration 128 lower bound -23.6369444732
loss is Autograd FloatNode with value -114.624442784 and 1 tape(s)
loss is -137.680384615
Iteration 129 lower bound -5.14510695862
loss is Autograd FloatNode with value -141.218037481 and 1 tape(s)
loss is -113.176129656
Iteration 130 lower bound -31.2290626431
loss is Autograd FloatNode with value -130.514361163 and 1 tape(s)
loss is -112.536868639
Iteration 131 lower bound -33.1219286813
loss is Autograd FloatNode with value -112.900248501 and 1 tape(s)
loss is -101.736343282
Iteration 132 lower bound -45.1332008821
loss is Autograd FloatNode with value -113.032086471 and 1 tape(s)
loss is -138.361079441
Iteration 133 lower bound -9.72053125176
loss is Autograd FloatNode with value -149.790296398 and 1 tape(s)
loss is -162.281680878
Iteration 134 lower bound 12.779629057
loss is Autograd FloatNode with value -167.882659593 and 1 tape(s)
loss is -111.36590914
Iteration 135 lower bound -39.5895701145
loss is Autograd FloatNode with value -121.521554429 and 1 tape(s)
loss is -117.046837335
Iteration 136 lower bound -34.821568997
loss is Autograd FloatNode with value -121.284462473 and 1 tape(s)
loss is -129.262562383
Iteration 137 lower bound -23.4610981764
loss is Autograd FloatNode with value -132.844009069 and 1 tape(s)
loss is -125.297193913
Iteration 138 lower bound -28.3814010341
loss is Autograd FloatNode with value -112.979732136 and 1 tape(s)
loss is -115.15875156
Iteration 139 lower bound -39.529046059
loss is Autograd FloatNode with value -112.046579902 and 1 tape(s)
loss is -100.726707935
Iteration 140 lower bound -55.0276240138
loss is Autograd FloatNode with value -120.304361166 and 1 tape(s)
loss is -121.69201003
Iteration 141 lower bound -35.2384962048
loss is Autograd FloatNode with value -123.873488181 and 1 tape(s)
loss is -119.681689087
Iteration 142 lower bound -38.6102707447
loss is Autograd FloatNode with value -108.899602987 and 1 tape(s)
loss is -124.490833978
Iteration 143 lower bound -35.1791227752
loss is Autograd FloatNode with value -123.731176233 and 1 tape(s)
loss is -110.498494091
Iteration 144 lower bound -50.5851659709
loss is Autograd FloatNode with value -123.764648652 and 1 tape(s)
loss is -130.044357858
Iteration 145 lower bound -32.4249183613
loss is Autograd FloatNode with value -115.001800522 and 1 tape(s)
loss is -110.037734346
Iteration 146 lower bound -53.7806097188
loss is Autograd FloatNode with value -117.84326658 and 1 tape(s)
loss is -116.761716499
Iteration 147 lower bound -48.3393186565
loss is Autograd FloatNode with value -111.647884881 and 1 tape(s)
loss is -121.014517046
Iteration 148 lower bound -45.3698306154
loss is Autograd FloatNode with value -134.249473125 and 1 tape(s)
loss is -125.972558721
Iteration 149 lower bound -41.676136002
loss is Autograd FloatNode with value -121.304109652 and 1 tape(s)
loss is -117.193232315
Iteration 150 lower bound -51.3747770405
loss is Autograd FloatNode with value -110.884685371 and 1 tape(s)
loss is -121.045412324
Iteration 151 lower bound -48.4732972669
loss is Autograd FloatNode with value -109.886632474 and 1 tape(s)
loss is -116.352557397
Iteration 152 lower bound -54.2677481702
loss is Autograd FloatNode with value -113.827539651 and 1 tape(s)
loss is -114.335907974
Iteration 153 lower bound -57.4315475968
loss is Autograd FloatNode with value -120.810366115 and 1 tape(s)
loss is -106.847268044
Iteration 154 lower bound -66.1456716665
loss is Autograd FloatNode with value -117.257699697 and 1 tape(s)
loss is -106.931821772
Iteration 155 lower bound -67.1973711682
loss is Autograd FloatNode with value -111.088531999 and 1 tape(s)
loss is -102.396470275
Iteration 156 lower bound -72.8006488759
loss is Autograd FloatNode with value -112.10120385 and 1 tape(s)
loss is -108.736792212
Iteration 157 lower bound -67.6155856918
loss is Autograd FloatNode with value -97.4472789226 and 1 tape(s)
loss is -111.647103143
Iteration 158 lower bound -65.8965238771
loss is Autograd FloatNode with value -104.99057906 and 1 tape(s)
loss is -110.369755903
Iteration 159 lower bound -68.5256898754
loss is Autograd FloatNode with value -116.030989458 and 1 tape(s)
loss is -110.522567015
Iteration 160 lower bound -69.6892690573
loss is Autograd FloatNode with value -116.308349692 and 1 tape(s)
loss is -102.032775243
Iteration 161 lower bound -79.4760856943
loss is Autograd FloatNode with value -104.728101037 and 1 tape(s)
loss is -110.969169286
Iteration 162 lower bound -71.8484107097
loss is Autograd FloatNode with value -107.152238596 and 1 tape(s)
loss is -110.346814427
Iteration 163 lower bound -73.8482960731
loss is Autograd FloatNode with value -125.228855007 and 1 tape(s)
loss is -120.953038722
Iteration 164 lower bound -64.6050054772
loss is Autograd FloatNode with value -112.279754864 and 1 tape(s)
loss is -119.099703086
Iteration 165 lower bound -67.5844502829
loss is Autograd FloatNode with value -116.180369642 and 1 tape(s)
loss is -105.104460916
Iteration 166 lower bound -82.5985086124
loss is Autograd FloatNode with value -131.112629097 and 1 tape(s)
loss is -127.978258505
Iteration 167 lower bound -60.7721428625
loss is Autograd FloatNode with value -126.937365301 and 1 tape(s)
loss is -105.35850548
Iteration 168 lower bound -84.2873615483
loss is Autograd FloatNode with value -109.081470412 and 1 tape(s)
loss is -119.824085495
Iteration 169 lower bound -70.644313434
loss is Autograd FloatNode with value -127.929115832 and 1 tape(s)
loss is -125.995114409
Iteration 170 lower bound -65.3431561606
loss is Autograd FloatNode with value -126.870598591 and 1 tape(s)
loss is -118.967807734
Iteration 171 lower bound -73.2013772959
loss is Autograd FloatNode with value -113.212537609 and 1 tape(s)
loss is -111.204293605
Iteration 172 lower bound -81.5536282059
loss is Autograd FloatNode with value -144.181541704 and 1 tape(s)
loss is -155.589533502
Iteration 173 lower bound -37.9133707259
loss is Autograd FloatNode with value -139.045901655 and 1 tape(s)
loss is -120.505896712
Iteration 174 lower bound -73.6642381352
loss is Autograd FloatNode with value -101.781827984 and 1 tape(s)
loss is -103.026894553
Iteration 175 lower bound -91.5428958448
loss is Autograd FloatNode with value -129.002884637 and 1 tape(s)
loss is -119.288400258
Iteration 176 lower bound -75.8682571515
loss is Autograd FloatNode with value -116.833093585 and 1 tape(s)
loss is -108.104939621
Iteration 177 lower bound -87.5928669109
loss is Autograd FloatNode with value -104.382060694 and 1 tape(s)
loss is -113.139244315
Iteration 178 lower bound -83.021636187
loss is Autograd FloatNode with value -103.750138928 and 1 tape(s)
loss is -120.824237727
Iteration 179 lower bound -75.9918047082
loss is Autograd FloatNode with value -114.442926523 and 1 tape(s)
loss is -110.067520329
Iteration 180 lower bound -87.6335237055
loss is Autograd FloatNode with value -104.786130835 and 1 tape(s)
loss is -105.628953031
Iteration 181 lower bound -93.0313133645
loss is Autograd FloatNode with value -101.31874924 and 1 tape(s)
loss is -111.501975876
Iteration 182 lower bound -88.280496177
loss is Autograd FloatNode with value -113.120065562 and 1 tape(s)
loss is -109.229373738
Iteration 183 lower bound -91.7775950555
loss is Autograd FloatNode with value -123.013323095 and 1 tape(s)
loss is -108.62574856
Iteration 184 lower bound -93.5134578037
loss is Autograd FloatNode with value -107.30939585 and 1 tape(s)
loss is -118.348706089
Iteration 185 lower bound -84.6302484101
loss is Autograd FloatNode with value -107.234393806 and 1 tape(s)
loss is -110.200800478
Iteration 186 lower bound -93.6510425088
loss is Autograd FloatNode with value -104.937519099 and 1 tape(s)
loss is -124.448127363
Iteration 187 lower bound -80.2888094751
loss is Autograd FloatNode with value -121.605707305 and 1 tape(s)
loss is -119.762150955
Iteration 188 lower bound -85.9598353094
loss is Autograd FloatNode with value -111.996542961 and 1 tape(s)
loss is -106.821045335
Iteration 189 lower bound -99.9434625292
loss is Autograd FloatNode with value -110.406626415 and 1 tape(s)
loss is -107.202989248
Iteration 190 lower bound -100.520407116
loss is Autograd FloatNode with value -123.983270248 and 1 tape(s)
loss is -117.926658029
Iteration 191 lower bound -90.7628800969
loss is Autograd FloatNode with value -105.945963552 and 1 tape(s)
loss is -108.530265277
Iteration 192 lower bound -100.922344918
loss is Autograd FloatNode with value -104.439981021 and 1 tape(s)
loss is -109.509616132
Iteration 193 lower bound -100.756754183
loss is Autograd FloatNode with value -107.50166368 and 1 tape(s)
loss is -105.468445628
Iteration 194 lower bound -105.765538991
loss is Autograd FloatNode with value -106.821395492 and 1 tape(s)
loss is -102.448346435
Iteration 195 lower bound -109.704351795
loss is Autograd FloatNode with value -110.999969259 and 1 tape(s)
loss is -109.832323847
Iteration 196 lower bound -103.281118552
loss is Autograd FloatNode with value -118.644094411 and 1 tape(s)
loss is -119.178470052
Iteration 197 lower bound -95.0233094351
loss is Autograd FloatNode with value -104.074281361 and 1 tape(s)
loss is -109.68020138
Iteration 198 lower bound -105.667388385
loss is Autograd FloatNode with value -132.523658655 and 1 tape(s)
loss is -132.014830614
Iteration 199 lower bound -84.5821258725
loss is Autograd FloatNode with value -115.126017588 and 1 tape(s)
loss is -102.895834373
Iteration 200 lower bound -114.688210397
loss is Autograd FloatNode with value -112.205251458 and 1 tape(s)
loss is -122.509566913
Iteration 201 lower bound -95.943473578
loss is Autograd FloatNode with value -113.507205003 and 1 tape(s)
loss is -120.654620078
Iteration 202 lower bound -98.7279142013
loss is Autograd FloatNode with value -112.887992881 and 1 tape(s)
loss is -122.351467664
Iteration 203 lower bound -98.1528403027
loss is Autograd FloatNode with value -118.599344767 and 1 tape(s)
loss is -117.900519382
Iteration 204 lower bound -103.831259255
loss is Autograd FloatNode with value -107.749658133 and 1 tape(s)
loss is -125.306679635
Iteration 205 lower bound -97.5402807492
loss is Autograd FloatNode with value -113.649741436 and 1 tape(s)
loss is -118.414545901
Iteration 206 lower bound -105.529833787
loss is Autograd FloatNode with value -132.882706038 and 1 tape(s)
loss is -123.723658003
Iteration 207 lower bound -101.285828328
loss is Autograd FloatNode with value -113.293672289 and 1 tape(s)
loss is -128.988461086
Iteration 208 lower bound -96.9198019665
loss is Autograd FloatNode with value -120.905043101 and 1 tape(s)
loss is -131.354959368
Iteration 209 lower bound -95.4448344146
loss is Autograd FloatNode with value -133.02111246 and 1 tape(s)
loss is -124.68156119
Iteration 210 lower bound -103.084309833
loss is Autograd FloatNode with value -120.917485949 and 1 tape(s)
loss is -121.33223381
Iteration 211 lower bound -107.36672701
loss is Autograd FloatNode with value -123.212222271 and 1 tape(s)
loss is -121.943530954
Iteration 212 lower bound -107.565031667
loss is Autograd FloatNode with value -128.205070437 and 1 tape(s)
loss is -108.293488742
Iteration 213 lower bound -121.806367385
loss is Autograd FloatNode with value -122.272375832 and 1 tape(s)
loss is -115.407730877
Iteration 214 lower bound -114.951507488
loss is Autograd FloatNode with value -113.123754 and 1 tape(s)
loss is -123.925874234
Iteration 215 lower bound -106.354578341
loss is Autograd FloatNode with value -138.630805474 and 1 tape(s)
loss is -125.501618908
Iteration 216 lower bound -104.841423217
loss is Autograd FloatNode with value -111.771331659 and 1 tape(s)
loss is -115.347155627
Iteration 217 lower bound -114.912587024
loss is Autograd FloatNode with value -108.870346821 and 1 tape(s)
loss is -117.44359993
Iteration 218 lower bound -112.854667767
loss is Autograd FloatNode with value -123.018670546 and 1 tape(s)
loss is -144.493366605
Iteration 219 lower bound -85.9841490889
loss is Autograd FloatNode with value -120.387583662 and 1 tape(s)
loss is -118.435998806
Iteration 220 lower bound -112.182714439
loss is Autograd FloatNode with value -109.891378755 and 1 tape(s)
loss is -115.563626461
Iteration 221 lower bound -115.246024886
loss is Autograd FloatNode with value -114.141559422 and 1 tape(s)
loss is -111.679726145
Iteration 222 lower bound -119.389969849
loss is Autograd FloatNode with value -115.918356384 and 1 tape(s)
loss is -112.740689221
Iteration 223 lower bound -118.61603012
loss is Autograd FloatNode with value -108.194350542 and 1 tape(s)
loss is -120.655682154
Iteration 224 lower bound -111.113070396
loss is Autograd FloatNode with value -119.795238275 and 1 tape(s)
loss is -126.500517785
Iteration 225 lower bound -105.779251358
loss is Autograd FloatNode with value -112.200909305 and 1 tape(s)
loss is -134.600022352
Iteration 226 lower bound -98.1131034769
loss is Autograd FloatNode with value -117.361809902 and 1 tape(s)
loss is -114.716973013
Iteration 227 lower bound -118.399362151
loss is Autograd FloatNode with value -137.101572682 and 1 tape(s)
loss is -118.05341566
Iteration 228 lower bound -115.452464456
loss is Autograd FloatNode with value -113.353792648 and 1 tape(s)
loss is -110.370484388
Iteration 229 lower bound -123.328438325
loss is Autograd FloatNode with value -119.900920996 and 1 tape(s)
loss is -120.219319291
Iteration 230 lower bound -113.575695631
loss is Autograd FloatNode with value -125.149625758 and 1 tape(s)
loss is -124.901041687
Iteration 231 lower bound -108.943109359
loss is Autograd FloatNode with value -101.033248865 and 1 tape(s)
loss is -107.627513753
Iteration 232 lower bound -126.249674889
loss is Autograd FloatNode with value -107.540548817 and 1 tape(s)
loss is -117.571824519
Iteration 233 lower bound -116.536296597
loss is Autograd FloatNode with value -110.609724566 and 1 tape(s)
loss is -124.475518138
Iteration 234 lower bound -109.978349171
loss is Autograd FloatNode with value -114.874240351 and 1 tape(s)
loss is -123.462933869
Iteration 235 lower bound -111.433749864
loss is Autograd FloatNode with value -119.970849742 and 1 tape(s)
loss is -121.25630756
Iteration 236 lower bound -114.025631498
loss is Autograd FloatNode with value -120.30396835 and 1 tape(s)
loss is -121.688744172
Iteration 237 lower bound -113.831822638
loss is Autograd FloatNode with value -104.941225335 and 1 tape(s)
loss is -115.785399953
Iteration 238 lower bound -119.770495813
loss is Autograd FloatNode with value -104.411358694 and 1 tape(s)
loss is -117.584212533
Iteration 239 lower bound -118.226227889
loss is Autograd FloatNode with value -110.522806527 and 1 tape(s)
loss is -113.71773651
Iteration 240 lower bound -122.550069389
loss is Autograd FloatNode with value -110.138879166 and 1 tape(s)
loss is -121.397155685
Iteration 241 lower bound -115.477054517
loss is Autograd FloatNode with value -119.711262935 and 1 tape(s)
loss is -127.983960136
Iteration 242 lower bound -109.547684583
loss is Autograd FloatNode with value -122.262103746 and 1 tape(s)
loss is -124.971527191
Iteration 243 lower bound -113.256818637
loss is Autograd FloatNode with value -142.216941481 and 1 tape(s)
loss is -112.457281978
Iteration 244 lower bound -126.392040704
loss is Autograd FloatNode with value -116.734439544 and 1 tape(s)
loss is -132.030272689
Iteration 245 lower bound -107.139209054
loss is Autograd FloatNode with value -146.261635858 and 1 tape(s)
loss is -127.218451802
Iteration 246 lower bound -112.468842118
loss is Autograd FloatNode with value -119.315635941 and 1 tape(s)
loss is -130.236617584
Iteration 247 lower bound -109.988990928
loss is Autograd FloatNode with value -132.139208697 and 1 tape(s)
loss is -127.822715626
Iteration 248 lower bound -112.982415476
loss is Autograd FloatNode with value -136.955790981 and 1 tape(s)
loss is -136.959517267
Iteration 249 lower bound -104.424363381
loss is Autograd FloatNode with value -125.042790073 and 1 tape(s)
loss is -127.075576004
Iteration 250 lower bound -114.855559386
loss is Autograd FloatNode with value -121.612025711 and 1 tape(s)
loss is -107.748373382
Iteration 251 lower bound -134.6724859
loss is Autograd FloatNode with value -139.892809799 and 1 tape(s)
loss is -143.719716597
Iteration 252 lower bound -99.0410675852
loss is Autograd FloatNode with value -137.773879044 and 1 tape(s)
loss is -135.824922508
Iteration 253 lower bound -107.176408379
loss is Autograd FloatNode with value -105.451366594 and 1 tape(s)
loss is -121.315618446
Iteration 254 lower bound -122.042258348
loss is Autograd FloatNode with value -128.789671402 and 1 tape(s)
loss is -113.561737161
Iteration 255 lower bound -130.293665095
loss is Autograd FloatNode with value -123.08764998 and 1 tape(s)
loss is -121.830349406
Iteration 256 lower bound -122.344556878
loss is Autograd FloatNode with value -110.841141033 and 1 tape(s)
loss is -112.728126507
Iteration 257 lower bound -131.775068524
loss is Autograd FloatNode with value -108.855971913 and 1 tape(s)
loss is -130.113172021
Iteration 258 lower bound -114.767856791
loss is Autograd FloatNode with value -121.793106526 and 1 tape(s)
loss is -130.123027095
Iteration 259 lower bound -115.22190215
loss is Autograd FloatNode with value -120.755807022 and 1 tape(s)
loss is -122.337560224
Iteration 260 lower bound -123.522316078
loss is Autograd FloatNode with value -158.064004136 and 1 tape(s)
loss is -112.409840373
Iteration 261 lower bound -134.115855766
loss is Autograd FloatNode with value -128.526162719 and 1 tape(s)
loss is -141.469353828
Iteration 262 lower bound -105.554078408
loss is Autograd FloatNode with value -116.29700492 and 1 tape(s)
loss is -128.593206526
Iteration 263 lower bound -118.886611882
loss is Autograd FloatNode with value -110.190447323 and 1 tape(s)
loss is -128.755712226
Iteration 264 lower bound -119.22415254
loss is Autograd FloatNode with value -125.605939237 and 1 tape(s)
loss is -116.110926177
Iteration 265 lower bound -132.398549017
loss is Autograd FloatNode with value -135.919816227 and 1 tape(s)
loss is -129.224855841
Iteration 266 lower bound -119.677903941
loss is Autograd FloatNode with value -126.144703291 and 1 tape(s)
loss is -120.477256575
Iteration 267 lower bound -128.708268904
loss is Autograd FloatNode with value -119.222731615 and 1 tape(s)
loss is -120.406132526
Iteration 268 lower bound -129.021389054
loss is Autograd FloatNode with value -149.20190131 and 1 tape(s)
loss is -119.169423927
Iteration 269 lower bound -130.474950651
loss is Autograd FloatNode with value -121.798011217 and 1 tape(s)
loss is -121.026410289
Iteration 270 lower bound -128.601708082
loss is Autograd FloatNode with value -127.618653115 and 1 tape(s)
loss is -135.650952807
Iteration 271 lower bound -113.966886743
loss is Autograd FloatNode with value -133.625053386 and 1 tape(s)
loss is -131.56184164
Iteration 272 lower bound -118.103942029
loss is Autograd FloatNode with value -113.533570907 and 1 tape(s)
loss is -98.6071865528
Iteration 273 lower bound -151.058067864
loss is Autograd FloatNode with value -113.410990193 and 1 tape(s)
loss is -129.905198652
Iteration 274 lower bound -119.586519984
loss is Autograd FloatNode with value -115.216385886 and 1 tape(s)
loss is -123.012160469
Iteration 275 lower bound -126.34910107
loss is Autograd FloatNode with value -111.860514093 and 1 tape(s)
loss is -118.596318577
Iteration 276 lower bound -130.733863525
loss is Autograd FloatNode with value -112.067396388 and 1 tape(s)
loss is -115.416921154
Iteration 277 lower bound -134.026885602
loss is Autograd FloatNode with value -141.074269601 and 1 tape(s)
loss is -106.350554229
Iteration 278 lower bound -143.25329967
loss is Autograd FloatNode with value -111.902720882 and 1 tape(s)
loss is -129.282080309
Iteration 279 lower bound -119.971151858
loss is Autograd FloatNode with value -112.03976928 and 1 tape(s)
loss is -115.597306026
Iteration 280 lower bound -133.320928084
loss is Autograd FloatNode with value -120.721198277 and 1 tape(s)
loss is -123.952172786
Iteration 281 lower bound -124.865839624
loss is Autograd FloatNode with value -112.047662703 and 1 tape(s)
loss is -110.567120875
Iteration 282 lower bound -138.283484368
loss is Autograd FloatNode with value -110.885626937 and 1 tape(s)
loss is -107.054704817
Iteration 283 lower bound -141.955569328
loss is Autograd FloatNode with value -126.72430781 and 1 tape(s)
loss is -110.010532099
Iteration 284 lower bound -139.19286397
loss is Autograd FloatNode with value -112.887282027 and 1 tape(s)
loss is -113.127429346
Iteration 285 lower bound -136.203151667
loss is Autograd FloatNode with value -119.585507316 and 1 tape(s)
loss is -115.298563532
Iteration 286 lower bound -134.235780958
loss is Autograd FloatNode with value -113.914372333 and 1 tape(s)
loss is -122.027652508
Iteration 287 lower bound -127.603964447
loss is Autograd FloatNode with value -113.059801109 and 1 tape(s)
loss is -126.296596569
Iteration 288 lower bound -123.459337927
loss is Autograd FloatNode with value -124.111310893 and 1 tape(s)
loss is -110.096122633
Iteration 289 lower bound -140.077244254
loss is Autograd FloatNode with value -113.392249355 and 1 tape(s)
loss is -139.696964185
Iteration 290 lower bound -110.854059106
loss is Autograd FloatNode with value -126.312994771 and 1 tape(s)
loss is -129.448447321
Iteration 291 lower bound -121.535884138
loss is Autograd FloatNode with value -134.945276207 and 1 tape(s)
loss is -119.769470557
Iteration 292 lower bound -131.574083256
loss is Autograd FloatNode with value -105.06156915 and 1 tape(s)
loss is -114.770094832
Iteration 293 lower bound -136.806044918
loss is Autograd FloatNode with value -130.090888594 and 1 tape(s)
loss is -127.520383364
Iteration 294 lower bound -124.576568005
loss is Autograd FloatNode with value -114.927455697 and 1 tape(s)
loss is -113.062730227
Iteration 295 lower bound -139.556745181
loss is Autograd FloatNode with value -105.703099394 and 1 tape(s)
loss is -116.420962805
Iteration 296 lower bound -136.896485849
loss is Autograd FloatNode with value -115.095771689 and 1 tape(s)
loss is -124.297073167
Iteration 297 lower bound -129.903519529
loss is Autograd FloatNode with value -123.803123906 and 1 tape(s)
loss is -114.303017636
Iteration 298 lower bound -140.775510851
loss is Autograd FloatNode with value -122.808550393 and 1 tape(s)
loss is -119.068776902
Iteration 299 lower bound -136.844012073
loss is Autograd FloatNode with value -117.148365884 and 1 tape(s)
loss is -112.01899104
Iteration 300 lower bound -144.559326814
loss is Autograd FloatNode with value -113.4932973 and 1 tape(s)
loss is -125.784036743
Iteration 301 lower bound -131.447298135
loss is Autograd FloatNode with value -135.799496872 and 1 tape(s)
loss is -135.194381146
Iteration 302 lower bound -122.800082184
loss is Autograd FloatNode with value -112.199269516 and 1 tape(s)
loss is -117.418278714
Iteration 303 lower bound -141.251727402
loss is Autograd FloatNode with value -115.72725515 and 1 tape(s)
loss is -119.631716671
Iteration 304 lower bound -139.795064221
loss is Autograd FloatNode with value -137.592737972 and 1 tape(s)
loss is -141.574774867
Iteration 305 lower bound -118.53406719
loss is Autograd FloatNode with value -112.764881013 and 1 tape(s)
loss is -120.490661697
Iteration 306 lower bound -140.063525075
loss is Autograd FloatNode with value -122.831797748 and 1 tape(s)
loss is -113.741093366
Iteration 307 lower bound -147.296869135
loss is Autograd FloatNode with value -138.7849909 and 1 tape(s)
loss is -130.856942575
Iteration 308 lower bound -130.415856643
loss is Autograd FloatNode with value -120.141554742 and 1 tape(s)
loss is -118.728825536
Iteration 309 lower bound -142.468081493
loss is Autograd FloatNode with value -114.662940584 and 1 tape(s)
loss is -110.281110993
Iteration 310 lower bound -150.84783548
loss is Autograd FloatNode with value -115.91870202 and 1 tape(s)
loss is -147.583335356
Iteration 311 lower bound -113.58544663
loss is Autograd FloatNode with value -120.990133611 and 1 tape(s)
loss is -122.104963384
Iteration 312 lower bound -139.14454746
loss is Autograd FloatNode with value -114.627004802 and 1 tape(s)
loss is -116.803877874
Iteration 313 lower bound -144.393511394
loss is Autograd FloatNode with value -114.578474084 and 1 tape(s)
loss is -124.270504735
Iteration 314 lower bound -136.956261303
loss is Autograd FloatNode with value -119.392013414 and 1 tape(s)
loss is -121.055081015
Iteration 315 lower bound -140.397517632
loss is Autograd FloatNode with value -125.480170778 and 1 tape(s)
loss is -121.783284495
Iteration 316 lower bound -140.068004719
loss is Autograd FloatNode with value -139.283197851 and 1 tape(s)
loss is -128.255097067
Iteration 317 lower bound -133.953962579
loss is Autograd FloatNode with value -117.585601241 and 1 tape(s)
loss is -141.574331982
Iteration 318 lower bound -120.899071761
loss is Autograd FloatNode with value -116.406793481 and 1 tape(s)
loss is -115.392450856
Iteration 319 lower bound -147.507324161
loss is Autograd FloatNode with value -117.441114724 and 1 tape(s)
loss is -119.851318566
Iteration 320 lower bound -143.544333924
loss is Autograd FloatNode with value -112.700850364 and 1 tape(s)
loss is -114.029385368
Iteration 321 lower bound -149.846951941
loss is Autograd FloatNode with value -126.62634172 and 1 tape(s)
loss is -121.648655092
Iteration 322 lower bound -142.82517758
loss is Autograd FloatNode with value -128.561631976 and 1 tape(s)
loss is -115.282078292
Iteration 323 lower bound -149.756981408
loss is Autograd FloatNode with value -112.965722564 and 1 tape(s)
loss is -120.685150196
Iteration 324 lower bound -144.634628429
loss is Autograd FloatNode with value -116.515317085 and 1 tape(s)
loss is -130.347628537
Iteration 325 lower bound -135.383156619
loss is Autograd FloatNode with value -120.94427417 and 1 tape(s)
loss is -116.819167642
Iteration 326 lower bound -149.445818605
loss is Autograd FloatNode with value -122.405085025 and 1 tape(s)
loss is -116.393117209
Iteration 327 lower bound -150.329767354
loss is Autograd FloatNode with value -136.143801276 and 1 tape(s)
loss is -122.843641851
Iteration 328 lower bound -144.259976796
loss is Autograd FloatNode with value -117.965745127 and 1 tape(s)
loss is -125.258224327
Iteration 329 lower bound -142.209874854
loss is Autograd FloatNode with value -114.249219281 and 1 tape(s)
loss is -117.093741825
Iteration 330 lower bound -150.963755584
loss is Autograd FloatNode with value -116.745782009 and 1 tape(s)
loss is -143.539488634
Iteration 331 lower bound -125.143966212
loss is Autograd FloatNode with value -125.916374752 and 1 tape(s)
loss is -135.235824404
Iteration 332 lower bound -134.18443298
loss is Autograd FloatNode with value -121.474429426 and 1 tape(s)
loss is -117.630213133
Iteration 333 lower bound -152.551790138
loss is Autograd FloatNode with value -121.540846811 and 1 tape(s)
loss is -122.169275916
Iteration 334 lower bound -148.751164145
loss is Autograd FloatNode with value -118.71339974 and 1 tape(s)
loss is -116.004054624
Iteration 335 lower bound -155.753601837
loss is Autograd FloatNode with value -118.386551578 and 1 tape(s)
loss is -113.000274051
Iteration 336 lower bound -159.600061579
loss is Autograd FloatNode with value -116.563220302 and 1 tape(s)
loss is -121.522774464
Iteration 337 lower bound -151.828740247
loss is Autograd FloatNode with value -118.290783104 and 1 tape(s)
loss is -131.762743919
Iteration 338 lower bound -142.304037729
loss is Autograd FloatNode with value -119.283882652 and 1 tape(s)
loss is -127.882252117
Iteration 339 lower bound -146.940239934
loss is Autograd FloatNode with value -123.286677956 and 1 tape(s)
loss is -117.721620128
Iteration 340 lower bound -157.833613078
loss is Autograd FloatNode with value -114.629590281 and 1 tape(s)
loss is -124.485668342
Iteration 341 lower bound -151.746741633
loss is Autograd FloatNode with value -117.333779026 and 1 tape(s)
loss is -124.71275178
Iteration 342 lower bound -152.22714846
loss is Autograd FloatNode with value -117.551717297 and 1 tape(s)
loss is -114.10655808
Iteration 343 lower bound -163.365728356
loss is Autograd FloatNode with value -132.371072542 and 1 tape(s)
loss is -135.160427684
Iteration 344 lower bound -142.863742403
loss is Autograd FloatNode with value -128.940167376 and 1 tape(s)
loss is -121.169300492
Iteration 345 lower bound -156.978425028
loss is Autograd FloatNode with value -115.614135786 and 1 tape(s)
loss is -114.115700559
Iteration 346 lower bound -163.849587869
loss is Autograd FloatNode with value -111.74805239 and 1 tape(s)
loss is -116.886149242
Iteration 347 lower bound -161.048288429
loss is Autograd FloatNode with value -115.713503694 and 1 tape(s)
loss is -109.71703326
Iteration 348 lower bound -168.284127397
loss is Autograd FloatNode with value -114.579916345 and 1 tape(s)
loss is -116.171366935
Iteration 349 lower bound -161.940236198
loss is Autograd FloatNode with value -109.78622122 and 1 tape(s)
loss is -106.151534757
Iteration 350 lower bound -172.127295038
loss is Autograd FloatNode with value -112.735804953 and 1 tape(s)
loss is -103.787385388
Iteration 351 lower bound -174.837187492
loss is Autograd FloatNode with value -131.706042271 and 1 tape(s)
loss is -127.479818173
Iteration 352 lower bound -151.576967171
loss is Autograd FloatNode with value -111.958212979 and 1 tape(s)
loss is -114.815521724
Iteration 353 lower bound -164.379515946
loss is Autograd FloatNode with value -116.816841737 and 1 tape(s)
loss is -117.023010866
Iteration 354 lower bound -162.376732737
loss is Autograd FloatNode with value -112.750989099 and 1 tape(s)
loss is -110.202679237
Iteration 355 lower bound -169.445392317
loss is Autograd FloatNode with value -106.583900428 and 1 tape(s)
loss is -118.446092021
Iteration 356 lower bound -161.570382483
loss is Autograd FloatNode with value -107.698999678 and 1 tape(s)
loss is -111.281594233
Iteration 357 lower bound -169.274911261
loss is Autograd FloatNode with value -109.150288873 and 1 tape(s)
loss is -114.290185382
Iteration 358 lower bound -166.951382083
loss is Autograd FloatNode with value -118.139181038 and 1 tape(s)
loss is -114.335211405
Iteration 359 lower bound -167.721645832
loss is Autograd FloatNode with value -110.586345574 and 1 tape(s)
loss is -122.374231259
Iteration 360 lower bound -160.510193822
loss is Autograd FloatNode with value -120.139806057 and 1 tape(s)
loss is -111.425857332
Iteration 361 lower bound -172.33468556
loss is Autograd FloatNode with value -115.68209933 and 1 tape(s)
loss is -116.821984315
Iteration 362 lower bound -167.745755892
loss is Autograd FloatNode with value -119.791986998 and 1 tape(s)
loss is -128.781107737
Iteration 363 lower bound -156.615329888
loss is Autograd FloatNode with value -124.239265311 and 1 tape(s)
loss is -115.280740492
Iteration 364 lower bound -170.973673278
loss is Autograd FloatNode with value -114.569691628 and 1 tape(s)
loss is -117.490055753
Iteration 365 lower bound -169.52230261
loss is Autograd FloatNode with value -123.319205719 and 1 tape(s)
loss is -123.414746045
Iteration 366 lower bound -164.312362057
loss is Autograd FloatNode with value -135.116222668 and 1 tape(s)
loss is -128.644050756
Iteration 367 lower bound -159.809917714
loss is Autograd FloatNode with value -121.687339538 and 1 tape(s)
loss is -122.54653573
Iteration 368 lower bound -166.658373352
loss is Autograd FloatNode with value -125.857259409 and 1 tape(s)
loss is -118.821940686
Iteration 369 lower bound -171.132835241
loss is Autograd FloatNode with value -131.555633097 and 1 tape(s)
loss is -122.857476184
Iteration 370 lower bound -167.724596354
loss is Autograd FloatNode with value -115.067946432 and 1 tape(s)
loss is -113.041377641
Iteration 371 lower bound -178.055932081
loss is Autograd FloatNode with value -118.202451959 and 1 tape(s)
loss is -120.201353567
Iteration 372 lower bound -171.380293488
loss is Autograd FloatNode with value -119.310737467 and 1 tape(s)
loss is -113.013332744
Iteration 373 lower bound -179.145771496
loss is Autograd FloatNode with value -121.426385764 and 1 tape(s)
loss is -135.64590619
Iteration 374 lower bound -157.019757769
loss is Autograd FloatNode with value -128.487104641 and 1 tape(s)
loss is -119.317050746
Iteration 375 lower bound -173.818540534
loss is Autograd FloatNode with value -117.822910821 and 1 tape(s)
loss is -133.00657574
Iteration 376 lower bound -160.468080742
loss is Autograd FloatNode with value -127.72726791 and 1 tape(s)
loss is -117.761058885
Iteration 377 lower bound -176.071177253
loss is Autograd FloatNode with value -119.812026789 and 1 tape(s)
loss is -120.208677113
Iteration 378 lower bound -173.920746181
loss is Autograd FloatNode with value -121.636707368 and 1 tape(s)
loss is -116.887212964
Iteration 379 lower bound -177.559604713
loss is Autograd FloatNode with value -123.191607907 and 1 tape(s)
loss is -123.897293209
Iteration 380 lower bound -170.716006446
loss is Autograd FloatNode with value -120.139648718 and 1 tape(s)
loss is -122.075676842
Iteration 381 lower bound -172.788081945
loss is Autograd FloatNode with value -122.772759035 and 1 tape(s)
loss is -123.176476182
Iteration 382 lower bound -171.979522664
loss is Autograd FloatNode with value -143.033705839 and 1 tape(s)
loss is -125.666464497
Iteration 383 lower bound -169.802790876
loss is Autograd FloatNode with value -112.914311897 and 1 tape(s)
loss is -116.599442143
Iteration 384 lower bound -178.556692861
loss is Autograd FloatNode with value -122.87554538 and 1 tape(s)
loss is -113.812729339
Iteration 385 lower bound -181.216653207
loss is Autograd FloatNode with value -118.824529331 and 1 tape(s)
loss is -126.938269152
Iteration 386 lower bound -167.866555767
loss is Autograd FloatNode with value -121.678634361 and 1 tape(s)
loss is -115.273458738
Iteration 387 lower bound -179.465395504
loss is Autograd FloatNode with value -120.182682071 and 1 tape(s)
loss is -118.734725704
Iteration 388 lower bound -175.821473597
loss is Autograd FloatNode with value -126.895256 and 1 tape(s)
loss is -120.463505653
Iteration 389 lower bound -173.959836687
loss is Autograd FloatNode with value -116.818557688 and 1 tape(s)
loss is -123.759048192
Iteration 390 lower bound -170.281041059
loss is Autograd FloatNode with value -113.437221329 and 1 tape(s)
loss is -118.597375824
Iteration 391 lower bound -175.172123723
loss is Autograd FloatNode with value -114.125183688 and 1 tape(s)
loss is -114.523255197
Iteration 392 lower bound -179.185537539
loss is Autograd FloatNode with value -116.76000095 and 1 tape(s)
loss is -111.733556616
Iteration 393 lower bound -182.107157902
loss is Autograd FloatNode with value -110.084370769 and 1 tape(s)
loss is -119.828118168
Iteration 394 lower bound -174.230346484
loss is Autograd FloatNode with value -127.519137435 and 1 tape(s)
loss is -123.751375355
Iteration 395 lower bound -170.722657499
loss is Autograd FloatNode with value -132.996456433 and 1 tape(s)
loss is -117.341776929
Iteration 396 lower bound -177.337638561
loss is Autograd FloatNode with value -114.60588119 and 1 tape(s)
loss is -117.356057884
Iteration 397 lower bound -177.401285427
loss is Autograd FloatNode with value -122.260734702 and 1 tape(s)
loss is -119.021931595
Iteration 398 lower bound -175.993921704
loss is Autograd FloatNode with value -128.708815182 and 1 tape(s)
loss is -128.258519245
Iteration 399 lower bound -166.919001555
loss is Autograd FloatNode with value -111.263382669 and 1 tape(s)
loss is -120.484082218
Iteration 400 lower bound -174.791960338
loss is Autograd FloatNode with value -116.10524125 and 1 tape(s)
loss is -112.905344405
Iteration 401 lower bound -182.612139248
loss is Autograd FloatNode with value -114.432418806 and 1 tape(s)
loss is -125.172940711
Iteration 402 lower bound -170.700903904
loss is Autograd FloatNode with value -118.907686849 and 1 tape(s)
loss is -114.642769346
Iteration 403 lower bound -181.755151872
loss is Autograd FloatNode with value -112.413738226 and 1 tape(s)
loss is -120.234390551
Iteration 404 lower bound -176.717819301
loss is Autograd FloatNode with value -125.390648303 and 1 tape(s)
loss is -116.300209942
Iteration 405 lower bound -181.289433485
loss is Autograd FloatNode with value -118.067565295 and 1 tape(s)
loss is -118.393122421
Iteration 406 lower bound -179.695308362
loss is Autograd FloatNode with value -114.416321684 and 1 tape(s)
loss is -113.348196182
Iteration 407 lower bound -185.293081858
loss is Autograd FloatNode with value -117.260922397 and 1 tape(s)
loss is -127.037625125
Iteration 408 lower bound -172.270597532
loss is Autograd FloatNode with value -117.936980059 and 1 tape(s)
loss is -121.960216826
Iteration 409 lower bound -178.034876909
loss is Autograd FloatNode with value -122.808692994 and 1 tape(s)
loss is -124.764777571
Iteration 410 lower bound -175.993918554
loss is Autograd FloatNode with value -125.809568451 and 1 tape(s)
loss is -114.036153536
Iteration 411 lower bound -187.354541826
loss is Autograd FloatNode with value -127.481036202 and 1 tape(s)
loss is -125.866422752
Iteration 412 lower bound -176.115683111
loss is Autograd FloatNode with value -129.562651416 and 1 tape(s)
loss is -127.698794836
Iteration 413 lower bound -174.91921322
loss is Autograd FloatNode with value -125.477089637 and 1 tape(s)
loss is -133.010801272
Iteration 414 lower bound -170.308391603
loss is Autograd FloatNode with value -131.574399354 and 1 tape(s)
loss is -130.104333921
Iteration 415 lower bound -173.905760018
loss is Autograd FloatNode with value -128.395502381 and 1 tape(s)
loss is -123.393560286
Iteration 416 lower bound -181.054169592
loss is Autograd FloatNode with value -126.163964208 and 1 tape(s)
loss is -120.115491705
Iteration 417 lower bound -184.660393555
loss is Autograd FloatNode with value -120.426848297 and 1 tape(s)
loss is -117.11333535
Iteration 418 lower bound -187.942154029
loss is Autograd FloatNode with value -139.614776124 and 1 tape(s)
loss is -116.346122787
Iteration 419 lower bound -188.878223434
loss is Autograd FloatNode with value -129.236474638 and 1 tape(s)
loss is -117.706964633
Iteration 420 lower bound -187.221670758
loss is Autograd FloatNode with value -117.18189597 and 1 tape(s)
loss is -116.571494341
Iteration 421 lower bound -188.009422708
loss is Autograd FloatNode with value -114.80035316 and 1 tape(s)
loss is -126.925595886
Iteration 422 lower bound -177.431835214
loss is Autograd FloatNode with value -114.148716886 and 1 tape(s)
loss is -119.209189163
Iteration 423 lower bound -185.069509922
loss is Autograd FloatNode with value -121.00759839 and 1 tape(s)
loss is -118.917419294
Iteration 424 lower bound -185.417594313
loss is Autograd FloatNode with value -125.811159363 and 1 tape(s)
loss is -118.877982882
Iteration 425 lower bound -185.565227904
loss is Autograd FloatNode with value -123.112469958 and 1 tape(s)
loss is -115.836028706
Iteration 426 lower bound -188.642554821
loss is Autograd FloatNode with value -128.102221123 and 1 tape(s)
loss is -125.371392815
Iteration 427 lower bound -179.236944888
loss is Autograd FloatNode with value -111.355757527 and 1 tape(s)
loss is -113.668439909
Iteration 428 lower bound -191.099328887
loss is Autograd FloatNode with value -129.813549693 and 1 tape(s)
loss is -125.772862521
Iteration 429 lower bound -179.337315835
loss is Autograd FloatNode with value -120.861566153 and 1 tape(s)
loss is -127.533256113
Iteration 430 lower bound -177.769006532
loss is Autograd FloatNode with value -122.622429002 and 1 tape(s)
loss is -115.223274408
Iteration 431 lower bound -190.273310759
loss is Autograd FloatNode with value -123.931992299 and 1 tape(s)
loss is -121.735415569
Iteration 432 lower bound -183.868084602
loss is Autograd FloatNode with value -121.350176029 and 1 tape(s)
loss is -124.761639279
Iteration 433 lower bound -180.995422292
loss is Autograd FloatNode with value -126.68280519 and 1 tape(s)
loss is -118.05624068
Iteration 434 lower bound -187.924324766
loss is Autograd FloatNode with value -117.302413246 and 1 tape(s)
loss is -118.333042395
Iteration 435 lower bound -187.797483768
loss is Autograd FloatNode with value -120.89079315 and 1 tape(s)
loss is -121.519548845
Iteration 436 lower bound -184.820334964
loss is Autograd FloatNode with value -126.97479857 and 1 tape(s)
loss is -116.782138781
Iteration 437 lower bound -189.850134711
loss is Autograd FloatNode with value -119.578312909 and 1 tape(s)
loss is -128.51157674
Iteration 438 lower bound -178.415793704
loss is Autograd FloatNode with value -122.524803185 and 1 tape(s)
loss is -110.998662097
Iteration 439 lower bound -196.222487188
loss is Autograd FloatNode with value -150.742178094 and 1 tape(s)
loss is -124.867027614
Iteration 440 lower bound -182.638261098
loss is Autograd FloatNode with value -129.121335096 and 1 tape(s)
loss is -116.472053912
Iteration 441 lower bound -190.635789091
loss is Autograd FloatNode with value -114.365477115 and 1 tape(s)
loss is -122.523407222
Iteration 442 lower bound -183.883585627
loss is Autograd FloatNode with value -112.789141782 and 1 tape(s)
loss is -119.97973417
Iteration 443 lower bound -185.979465996
loss is Autograd FloatNode with value -116.446932998 and 1 tape(s)
loss is -120.481175495
Iteration 444 lower bound -185.28641505
loss is Autograd FloatNode with value -123.114596663 and 1 tape(s)
loss is -114.450120507
Iteration 445 lower bound -191.211569892
loss is Autograd FloatNode with value -129.610888505 and 1 tape(s)
loss is -154.098037775
Iteration 446 lower bound -151.369366418
loss is Autograd FloatNode with value -116.282634226 and 1 tape(s)
loss is -112.558333598
Iteration 447 lower bound -192.693918359
loss is Autograd FloatNode with value -124.465118779 and 1 tape(s)
loss is -124.071614488
Iteration 448 lower bound -181.062705796
loss is Autograd FloatNode with value -125.100000937 and 1 tape(s)
loss is -126.396374337
Iteration 449 lower bound -178.707587282
loss is Autograd FloatNode with value -129.40168653 and 1 tape(s)
loss is -120.461819365
Iteration 450 lower bound -184.665127724
loss is Autograd FloatNode with value -124.297873573 and 1 tape(s)
loss is -122.516749925
Iteration 451 lower bound -182.571174829
loss is Autograd FloatNode with value -122.809031871 and 1 tape(s)
loss is -118.026462159
Iteration 452 lower bound -187.171184372
loss is Autograd FloatNode with value -120.370768364 and 1 tape(s)
loss is -120.693398489
Iteration 453 lower bound -184.58268907
loss is Autograd FloatNode with value -135.581602149 and 1 tape(s)
loss is -123.045270622
Iteration 454 lower bound -182.363923213
loss is Autograd FloatNode with value -114.415406712 and 1 tape(s)
loss is -117.617391858
Iteration 455 lower bound -187.854548172
loss is Autograd FloatNode with value -111.594918092 and 1 tape(s)
loss is -130.312491793
Iteration 456 lower bound -175.29672478
loss is Autograd FloatNode with value -120.320937713 and 1 tape(s)
loss is -117.28338949
Iteration 457 lower bound -188.651073923
loss is Autograd FloatNode with value -116.389409701 and 1 tape(s)
loss is -122.483970064
Iteration 458 lower bound -183.887669147
loss is Autograd FloatNode with value -120.466550098 and 1 tape(s)
loss is -117.098491912
Iteration 459 lower bound -189.805148672
loss is Autograd FloatNode with value -123.165488744 and 1 tape(s)
loss is -113.915355716
Iteration 460 lower bound -193.385594593
loss is Autograd FloatNode with value -122.452723525 and 1 tape(s)
loss is -126.504237157
Iteration 461 lower bound -181.025413906
loss is Autograd FloatNode with value -124.248617714 and 1 tape(s)
loss is -115.067776556
Iteration 462 lower bound -192.693411433
loss is Autograd FloatNode with value -115.858769977 and 1 tape(s)
loss is -114.615437297
Iteration 463 lower bound -193.409836496
loss is Autograd FloatNode with value -119.744529748 and 1 tape(s)
loss is -120.853306914
Iteration 464 lower bound -187.581671193
loss is Autograd FloatNode with value -125.532476903 and 1 tape(s)
loss is -121.419271789
Iteration 465 lower bound -187.448410013
loss is Autograd FloatNode with value -118.623781037 and 1 tape(s)
loss is -117.269788253
Iteration 466 lower bound -192.058730919
loss is Autograd FloatNode with value -122.1684911 and 1 tape(s)
loss is -123.059312061
Iteration 467 lower bound -186.787708176
loss is Autograd FloatNode with value -121.119674753 and 1 tape(s)
loss is -124.776793067
Iteration 468 lower bound -185.538779139
loss is Autograd FloatNode with value -130.080749256 and 1 tape(s)
loss is -124.909635529
Iteration 469 lower bound -186.037821677
loss is Autograd FloatNode with value -125.979947403 and 1 tape(s)
loss is -127.759400878
Iteration 470 lower bound -183.533470524
loss is Autograd FloatNode with value -128.253533458 and 1 tape(s)
loss is -121.045961401
Iteration 471 lower bound -190.615475749
loss is Autograd FloatNode with value -127.161569726 and 1 tape(s)
loss is -119.83397554
Iteration 472 lower bound -191.74601733
loss is Autograd FloatNode with value -115.14719986 and 1 tape(s)
loss is -118.301402246
Iteration 473 lower bound -193.301115811
loss is Autograd FloatNode with value -117.846959873 and 1 tape(s)
loss is -117.831112169
Iteration 474 lower bound -193.943025027
loss is Autograd FloatNode with value -124.587181238 and 1 tape(s)
loss is -113.508540651
Iteration 475 lower bound -198.523571937
loss is Autograd FloatNode with value -118.080772171 and 1 tape(s)
loss is -123.335733013
Iteration 476 lower bound -189.022444297
loss is Autograd FloatNode with value -120.662939241 and 1 tape(s)
loss is -128.35264564
Iteration 477 lower bound -184.400275954
loss is Autograd FloatNode with value -122.968715636 and 1 tape(s)
loss is -115.535889283
Iteration 478 lower bound -197.676931374
loss is Autograd FloatNode with value -121.353003421 and 1 tape(s)
loss is -121.966147321
Iteration 479 lower bound -191.723045592
loss is Autograd FloatNode with value -119.792013824 and 1 tape(s)
loss is -119.517054953
Iteration 480 lower bound -194.653309653
loss is Autograd FloatNode with value -134.540344506 and 1 tape(s)
loss is -128.192050161
Iteration 481 lower bound -186.513068133
loss is Autograd FloatNode with value -119.021466523 and 1 tape(s)
loss is -112.585215754
Iteration 482 lower bound -202.000950835
loss is Autograd FloatNode with value -120.485571879 and 1 tape(s)
loss is -120.193305124
Iteration 483 lower bound -194.353627452
loss is Autograd FloatNode with value -127.054640506 and 1 tape(s)
loss is -119.374893896
Iteration 484 lower bound -195.233965701
loss is Autograd FloatNode with value -125.764471419 and 1 tape(s)
loss is -118.697930111
Iteration 485 lower bound -195.805372102
loss is Autograd FloatNode with value -115.276694074 and 1 tape(s)
loss is -117.11888435
Iteration 486 lower bound -197.161650064
loss is Autograd FloatNode with value -117.469013238 and 1 tape(s)
loss is -116.450438457
Iteration 487 lower bound -197.751862218
loss is Autograd FloatNode with value -114.2184359 and 1 tape(s)
loss is -120.45602204
Iteration 488 lower bound -193.809563227
loss is Autograd FloatNode with value -120.882653294 and 1 tape(s)
loss is -113.017429266
Iteration 489 lower bound -201.517096827
loss is Autograd FloatNode with value -124.251385472 and 1 tape(s)
loss is -125.244382215
Iteration 490 lower bound -189.656624399
loss is Autograd FloatNode with value -132.609677942 and 1 tape(s)
loss is -121.525241348
Iteration 491 lower bound -193.723362388
loss is Autograd FloatNode with value -118.292556673 and 1 tape(s)
loss is -132.072622721
Iteration 492 lower bound -183.397463575
loss is Autograd FloatNode with value -115.28613818 and 1 tape(s)
loss is -117.259152696
Iteration 493 lower bound -198.59796445
loss is Autograd FloatNode with value -121.599352789 and 1 tape(s)
loss is -126.721442938
Iteration 494 lower bound -189.698661225
loss is Autograd FloatNode with value -121.423558304 and 1 tape(s)
loss is -143.80341041
Iteration 495 lower bound -173.241161193
loss is Autograd FloatNode with value -125.760543413 and 1 tape(s)
loss is -119.780087908
Iteration 496 lower bound -197.945971171
loss is Autograd FloatNode with value -132.22779495 and 1 tape(s)
loss is -131.777008303
Iteration 497 lower bound -186.541703409
loss is Autograd FloatNode with value -118.770654795 and 1 tape(s)
loss is -115.411973683
Iteration 498 lower bound -203.427249485
loss is Autograd FloatNode with value -130.514745813 and 1 tape(s)
loss is -131.568862508
Iteration 499 lower bound -187.88761686
loss is Autograd FloatNode with value -137.692940816 and 1 tape(s)
loss is -147.245399608
Iteration 500 lower bound -172.752825335
loss is Autograd FloatNode with value -120.643066404 and 1 tape(s)
loss is -117.207842575
Iteration 501 lower bound -203.13967686
loss is Autograd FloatNode with value -122.132510068 and 1 tape(s)
loss is -136.112609171
Iteration 502 lower bound -184.623119942
loss is Autograd FloatNode with value -135.731864558 and 1 tape(s)
loss is -140.222224581
Iteration 503 lower bound -180.918776756
loss is Autograd FloatNode with value -117.158597376 and 1 tape(s)
loss is -122.753184177
Iteration 504 lower bound -198.740933423
loss is Autograd FloatNode with value -123.696385034 and 1 tape(s)
loss is -125.382898489
Iteration 505 lower bound -196.548223758
loss is Autograd FloatNode with value -137.245653806 and 1 tape(s)
loss is -121.458520991
Iteration 506 lower bound -200.777340011
loss is Autograd FloatNode with value -124.811945055 and 1 tape(s)
loss is -121.657948994
Iteration 507 lower bound -200.493453353
loss is Autograd FloatNode with value -125.010899394 and 1 tape(s)
loss is -134.941552029
Iteration 508 lower bound -186.949435174
loss is Autograd FloatNode with value -134.156675534 and 1 tape(s)
loss is -129.262909537
Iteration 509 lower bound -192.448528948
loss is Autograd FloatNode with value -124.680302312 and 1 tape(s)
loss is -119.367505104
Iteration 510 lower bound -201.923638092
loss is Autograd FloatNode with value -129.68256812 and 1 tape(s)
loss is -128.434153064
Iteration 511 lower bound -192.506746393
loss is Autograd FloatNode with value -122.183149428 and 1 tape(s)
loss is -124.578288936
Iteration 512 lower bound -195.918563836
loss is Autograd FloatNode with value -121.114651482 and 1 tape(s)
loss is -127.665413528
Iteration 513 lower bound -192.38896194
loss is Autograd FloatNode with value -131.834452932 and 1 tape(s)
loss is -144.917242846
Iteration 514 lower bound -174.792324725
loss is Autograd FloatNode with value -138.966400393 and 1 tape(s)
loss is -127.934378322
Iteration 515 lower bound -191.461504032
loss is Autograd FloatNode with value -117.331058503 and 1 tape(s)
loss is -123.237884116
Iteration 516 lower bound -195.746105992
loss is Autograd FloatNode with value -134.32221909 and 1 tape(s)
loss is -128.762338128
Iteration 517 lower bound -190.051339155
loss is Autograd FloatNode with value -123.319581568 and 1 tape(s)
loss is -124.480063926
Iteration 518 lower bound -194.038785751
loss is Autograd FloatNode with value -127.157070569 and 1 tape(s)
loss is -118.787916374
Iteration 519 lower bound -199.561839004
loss is Autograd FloatNode with value -129.84712773 and 1 tape(s)
loss is -125.263636507
Iteration 520 lower bound -192.866467989
loss is Autograd FloatNode with value -145.086634139 and 1 tape(s)
loss is -128.670302364
Iteration 521 lower bound -189.278259434
loss is Autograd FloatNode with value -119.410065705 and 1 tape(s)
loss is -123.000225034
Iteration 522 lower bound -194.928619695
loss is Autograd FloatNode with value -140.227620591 and 1 tape(s)
loss is -130.267475988
Iteration 523 lower bound -187.770434097
loss is Autograd FloatNode with value -123.139318753 and 1 tape(s)
loss is -123.442607649
Iteration 524 lower bound -194.159318848
loss is Autograd FloatNode with value -119.26106995 and 1 tape(s)
loss is -125.340830906
Iteration 525 lower bound -191.894066805
loss is Autograd FloatNode with value -120.53703398 and 1 tape(s)
loss is -124.359172069
Iteration 526 lower bound -192.683005557
loss is Autograd FloatNode with value -126.336870125 and 1 tape(s)
loss is -124.183403844
Iteration 527 lower bound -192.769647522
loss is Autograd FloatNode with value -119.707420371 and 1 tape(s)
loss is -126.209233484
Iteration 528 lower bound -190.725817864
loss is Autograd FloatNode with value -128.403813159 and 1 tape(s)
loss is -128.662069397
Iteration 529 lower bound -188.400104278
loss is Autograd FloatNode with value -129.977353489 and 1 tape(s)
loss is -122.482265378
Iteration 530 lower bound -194.727917549
loss is Autograd FloatNode with value -128.752620547 and 1 tape(s)
loss is -130.378310325
Iteration 531 lower bound -186.965724605
loss is Autograd FloatNode with value -130.047825989 and 1 tape(s)
loss is -128.217345175
Iteration 532 lower bound -189.328553189
loss is Autograd FloatNode with value -122.697981734 and 1 tape(s)
loss is -123.699665104
Iteration 533 lower bound -194.108609564
loss is Autograd FloatNode with value -124.621377519 and 1 tape(s)
loss is -133.977996278
Iteration 534 lower bound -184.090411739
loss is Autograd FloatNode with value -140.987827132 and 1 tape(s)
loss is -139.000734871
Iteration 535 lower bound -179.47375429
loss is Autograd FloatNode with value -118.004335371 and 1 tape(s)
loss is -121.641620076
Iteration 536 lower bound -197.0503796
loss is Autograd FloatNode with value -137.646036845 and 1 tape(s)
loss is -135.098688139
Iteration 537 lower bound -183.927632475
loss is Autograd FloatNode with value -129.433860666 and 1 tape(s)
loss is -126.909776236
Iteration 538 lower bound -192.419634325
loss is Autograd FloatNode with value -120.233902269 and 1 tape(s)
loss is -125.812643741
Iteration 539 lower bound -193.80750306
loss is Autograd FloatNode with value -125.930525083 and 1 tape(s)
loss is -143.3354715
Iteration 540 lower bound -176.643048096
loss is Autograd FloatNode with value -125.596450838 and 1 tape(s)
loss is -140.439641384
Iteration 541 lower bound -179.898228703
loss is Autograd FloatNode with value -129.250703013 and 1 tape(s)
loss is -125.652359917
Iteration 542 lower bound -195.018317454
loss is Autograd FloatNode with value -128.843509055 and 1 tape(s)
loss is -140.434742839
Iteration 543 lower bound -180.384680423
loss is Autograd FloatNode with value -133.723044985 and 1 tape(s)
loss is -138.966693804
Iteration 544 lower bound -182.168619405
loss is Autograd FloatNode with value -126.181757271 and 1 tape(s)
loss is -124.2194498
Iteration 545 lower bound -197.182099567
loss is Autograd FloatNode with value -129.02871039 and 1 tape(s)
loss is -140.009692548
Iteration 546 lower bound -181.518485957
loss is Autograd FloatNode with value -145.650419793 and 1 tape(s)
loss is -141.421776926
Iteration 547 lower bound -180.328897687
loss is Autograd FloatNode with value -121.051478637 and 1 tape(s)
loss is -125.546793429
Iteration 548 lower bound -196.026191165
loss is Autograd FloatNode with value -123.282310412 and 1 tape(s)
loss is -125.87162824
Iteration 549 lower bound -195.541996472
loss is Autograd FloatNode with value -123.285003354 and 1 tape(s)
loss is -129.308210236
Iteration 550 lower bound -191.899546151
loss is Autograd FloatNode with value -124.282410368 and 1 tape(s)
loss is -126.300844927
Iteration 551 lower bound -194.787753612
loss is Autograd FloatNode with value -125.865477838 and 1 tape(s)
loss is -121.80252547
Iteration 552 lower bound -199.229615897
loss is Autograd FloatNode with value -133.466797684 and 1 tape(s)
loss is -131.162524822
Iteration 553 lower bound -189.729751424
loss is Autograd FloatNode with value -123.268691018 and 1 tape(s)
loss is -122.863831507
Iteration 554 lower bound -197.80270759
loss is Autograd FloatNode with value -124.395108467 and 1 tape(s)
loss is -124.908235843
Iteration 555 lower bound -195.678733275
loss is Autograd FloatNode with value -137.609144969 and 1 tape(s)
loss is -131.174192067
Iteration 556 lower bound -189.429027844
loss is Autograd FloatNode with value -118.762393917 and 1 tape(s)
loss is -117.380772876
Iteration 557 lower bound -203.12232376
loss is Autograd FloatNode with value -119.553278757 and 1 tape(s)
loss is -123.162356993
Iteration 558 lower bound -197.400959987
loss is Autograd FloatNode with value -127.453573584 and 1 tape(s)
loss is -121.074118574
Iteration 559 lower bound -199.626019054
loss is Autograd FloatNode with value -131.248225157 and 1 tape(s)
loss is -116.626332188
Iteration 560 lower bound -204.17594718
loss is Autograd FloatNode with value -121.798861645 and 1 tape(s)
loss is -120.594230833
Iteration 561 lower bound -200.05031767
loss is Autograd FloatNode with value -122.423966624 and 1 tape(s)
loss is -132.450246993
Iteration 562 lower bound -188.122478084
loss is Autograd FloatNode with value -121.886149421 and 1 tape(s)
loss is -122.300100836
Iteration 563 lower bound -198.379265957
loss is Autograd FloatNode with value -123.955210547 and 1 tape(s)
loss is -120.890385559
Iteration 564 lower bound -200.047669482
loss is Autograd FloatNode with value -126.570392244 and 1 tape(s)
loss is -119.815970051
Iteration 565 lower bound -201.45629077
loss is Autograd FloatNode with value -134.439409007 and 1 tape(s)
loss is -124.180970791
Iteration 566 lower bound -197.525257013
loss is Autograd FloatNode with value -119.821095983 and 1 tape(s)
loss is -121.815368456
Iteration 567 lower bound -200.338914684
loss is Autograd FloatNode with value -139.291096892 and 1 tape(s)
loss is -130.693839126
Iteration 568 lower bound -191.964850743
loss is Autograd FloatNode with value -120.585000241 and 1 tape(s)
loss is -127.696731798
Iteration 569 lower bound -195.45764406
loss is Autograd FloatNode with value -121.076488741 and 1 tape(s)
loss is -125.132194929
Iteration 570 lower bound -198.643871431
loss is Autograd FloatNode with value -139.251853298 and 1 tape(s)
loss is -126.403299328
Iteration 571 lower bound -198.074869242
loss is Autograd FloatNode with value -143.957110491 and 1 tape(s)
loss is -129.628095438
Iteration 572 lower bound -195.190920788
loss is Autograd FloatNode with value -120.489563076 and 1 tape(s)
loss is -129.304477521
Iteration 573 lower bound -195.855007664
loss is Autograd FloatNode with value -126.693009447 and 1 tape(s)
loss is -137.090251185
Iteration 574 lower bound -188.499592739
loss is Autograd FloatNode with value -149.384755253 and 1 tape(s)
loss is -132.270805162
Iteration 575 lower bound -193.805874291
loss is Autograd FloatNode with value -117.014765554 and 1 tape(s)
loss is -132.898100621
Iteration 576 lower bound -193.453802334
loss is Autograd FloatNode with value -136.381619727 and 1 tape(s)
loss is -128.21128509
Iteration 577 lower bound -198.505123965
loss is Autograd FloatNode with value -133.570159986 and 1 tape(s)
loss is -133.758275996
Iteration 578 lower bound -193.280300832
loss is Autograd FloatNode with value -129.068154527 and 1 tape(s)
loss is -129.849865784
Iteration 579 lower bound -197.455649986
loss is Autograd FloatNode with value -135.940470995 and 1 tape(s)
loss is -134.598413996
Iteration 580 lower bound -192.805225804
loss is Autograd FloatNode with value -133.511351194 and 1 tape(s)
loss is -130.297275746
Iteration 581 lower bound -197.057017076
loss is Autograd FloatNode with value -126.717361651 and 1 tape(s)
loss is -126.45509606
Iteration 582 lower bound -200.823907473
loss is Autograd FloatNode with value -143.405390796 and 1 tape(s)
loss is -136.652333741
Iteration 583 lower bound -190.603555682
loss is Autograd FloatNode with value -116.275032298 and 1 tape(s)
loss is -122.1660711
Iteration 584 lower bound -205.040146197
loss is Autograd FloatNode with value -136.975710427 and 1 tape(s)
loss is -128.599881106
Iteration 585 lower bound -198.659186756
loss is Autograd FloatNode with value -127.800023026 and 1 tape(s)
loss is -139.913196453
Iteration 586 lower bound -187.237767082
loss is Autograd FloatNode with value -127.956750441 and 1 tape(s)
loss is -126.528273868
Iteration 587 lower bound -200.569820205
loss is Autograd FloatNode with value -129.690831104 and 1 tape(s)
loss is -123.705131161
Iteration 588 lower bound -203.200030807
loss is Autograd FloatNode with value -132.223242717 and 1 tape(s)
loss is -127.491189152
Iteration 589 lower bound -199.220897971
loss is Autograd FloatNode with value -121.389068786 and 1 tape(s)
loss is -125.63363385
Iteration 590 lower bound -200.90864096
loss is Autograd FloatNode with value -120.756492265 and 1 tape(s)
loss is -136.8708164
Iteration 591 lower bound -189.642596711
loss is Autograd FloatNode with value -135.328108398 and 1 tape(s)
loss is -224.353939823
Iteration 592 lower bound -102.29751662
loss is Autograd FloatNode with value -130.054032339 and 1 tape(s)
loss is -120.258914166
Iteration 593 lower bound -206.60100976
loss is Autograd FloatNode with value -122.265423038 and 1 tape(s)
loss is -121.322553398
Iteration 594 lower bound -205.635758369
loss is Autograd FloatNode with value -123.954479902 and 1 tape(s)
loss is -126.425527378
Iteration 595 lower bound -200.630490013
loss is Autograd FloatNode with value -128.467007586 and 1 tape(s)
loss is -133.113021895
Iteration 596 lower bound -193.899650901
loss is Autograd FloatNode with value -126.447805132 and 1 tape(s)
loss is -139.579427145
Iteration 597 lower bound -187.318988091
loss is Autograd FloatNode with value -139.313822438 and 1 tape(s)
loss is -121.090234128
Iteration 598 lower bound -205.711311147
loss is Autograd FloatNode with value -122.095165302 and 1 tape(s)
loss is -122.241156361
Iteration 599 lower bound -203.992432595
loss is Autograd FloatNode with value -121.235049802 and 1 tape(s)
loss is -115.232556499
Iteration 600 lower bound -210.570522066
loss is Autograd FloatNode with value -126.779480687 and 1 tape(s)
loss is -119.644376669
Iteration 601 lower bound -205.813238635
loss is Autograd FloatNode with value -121.326387096 and 1 tape(s)
loss is -128.334998481
Iteration 602 lower bound -196.634377411
loss is Autograd FloatNode with value -118.174387495 and 1 tape(s)
loss is -116.96717426
Iteration 603 lower bound -207.59036546
loss is Autograd FloatNode with value -124.263302149 and 1 tape(s)
loss is -121.728551327
Iteration 604 lower bound -202.58356414
loss is Autograd FloatNode with value -123.722721717 and 1 tape(s)
loss is -119.00153307
Iteration 605 lower bound -205.041326328
loss is Autograd FloatNode with value -119.753231723 and 1 tape(s)
loss is -114.468153121
Iteration 606 lower bound -209.432018979
loss is Autograd FloatNode with value -116.952899635 and 1 tape(s)
loss is -117.645384974
Iteration 607 lower bound -206.183547368
loss is Autograd FloatNode with value -120.439177275 and 1 tape(s)
loss is -115.949347875
Iteration 608 lower bound -207.975280727
loss is Autograd FloatNode with value -119.759693069 and 1 tape(s)
loss is -126.749338458
Iteration 609 lower bound -197.412424635
loss is Autograd FloatNode with value -122.230953404 and 1 tape(s)
loss is -123.729196392
Iteration 610 lower bound -200.755790539
loss is Autograd FloatNode with value -120.633075658 and 1 tape(s)
loss is -116.53590863
Iteration 611 lower bound -208.359074385
loss is Autograd FloatNode with value -117.227235037 and 1 tape(s)
loss is -132.846692982
Iteration 612 lower bound -192.606790542
loss is Autograd FloatNode with value -126.029276462 and 1 tape(s)
loss is -163.021142721
Iteration 613 lower bound -163.050312744
loss is Autograd FloatNode with value -127.479501086 and 1 tape(s)
loss is -124.790114439
Iteration 614 lower bound -201.766407604
loss is Autograd FloatNode with value -130.521062496 and 1 tape(s)
loss is -126.090927599
Iteration 615 lower bound -200.904477979
loss is Autograd FloatNode with value -151.480961559 and 1 tape(s)
loss is -130.654391089
Iteration 616 lower bound -196.876341204
loss is Autograd FloatNode with value -123.398970621 and 1 tape(s)
loss is -129.16031274
Iteration 617 lower bound -198.320356543
loss is Autograd FloatNode with value -124.571795102 and 1 tape(s)
loss is -125.00819642
Iteration 618 lower bound -202.482844297
loss is Autograd FloatNode with value -123.318490288 and 1 tape(s)
loss is -128.826796689
Iteration 619 lower bound -198.795370467
loss is Autograd FloatNode with value -118.682645119 and 1 tape(s)
loss is -122.900446699
Iteration 620 lower bound -204.952936961
loss is Autograd FloatNode with value -128.292553528 and 1 tape(s)
loss is -119.359323405
Iteration 621 lower bound -208.860484114
loss is Autograd FloatNode with value -144.7727013 and 1 tape(s)
loss is -143.751215041
Iteration 622 lower bound -184.740695045
loss is Autograd FloatNode with value -157.136037101 and 1 tape(s)
loss is -174.318012555
Iteration 623 lower bound -154.016591214
loss is Autograd FloatNode with value -136.377672787 and 1 tape(s)
loss is -136.442599793
Iteration 624 lower bound -191.133930347
loss is Autograd FloatNode with value -143.575602318 and 1 tape(s)
loss is -131.972001787
Iteration 625 lower bound -195.006764882
loss is Autograd FloatNode with value -127.835850748 and 1 tape(s)
loss is -118.925143016
Iteration 626 lower bound -207.423091731
loss is Autograd FloatNode with value -116.614673037 and 1 tape(s)
loss is -129.559131961
Iteration 627 lower bound -196.066029476
loss is Autograd FloatNode with value -124.521088623 and 1 tape(s)
loss is -121.869653613
Iteration 628 lower bound -203.214001549
loss is Autograd FloatNode with value -132.621461001 and 1 tape(s)
loss is -125.092326802
Iteration 629 lower bound -199.595209311
loss is Autograd FloatNode with value -121.324872593 and 1 tape(s)
loss is -125.581152049
Iteration 630 lower bound -198.612849272
loss is Autograd FloatNode with value -124.755265699 and 1 tape(s)
loss is -119.286701063
Iteration 631 lower bound -204.476735397
loss is Autograd FloatNode with value -125.10967608 and 1 tape(s)
loss is -124.128583502
Iteration 632 lower bound -199.251330163
loss is Autograd FloatNode with value -121.204830362 and 1 tape(s)
loss is -118.078774564
Iteration 633 lower bound -204.974412336
loss is Autograd FloatNode with value -119.988829198 and 1 tape(s)
loss is -128.069117694
Iteration 634 lower bound -194.775074834
loss is Autograd FloatNode with value -123.518963859 and 1 tape(s)
loss is -121.933095605
Iteration 635 lower bound -200.76899882
loss is Autograd FloatNode with value -122.556833592 and 1 tape(s)
loss is -116.54830933
Iteration 636 lower bound -206.0571869
loss is Autograd FloatNode with value -121.679824996 and 1 tape(s)
loss is -115.980608211
Iteration 637 lower bound -206.636652323
loss is Autograd FloatNode with value -117.379247388 and 1 tape(s)
loss is -122.22118727
Iteration 638 lower bound -200.50721987
loss is Autograd FloatNode with value -122.387921868 and 1 tape(s)
loss is -122.775976118
Iteration 639 lower bound -200.194176482
loss is Autograd FloatNode with value -121.200327691 and 1 tape(s)
loss is -120.508313062
Iteration 640 lower bound -202.785318005
loss is Autograd FloatNode with value -127.692502382 and 1 tape(s)
loss is -118.77343514
Iteration 641 lower bound -204.92173311
loss is Autograd FloatNode with value -123.67556573 and 1 tape(s)
loss is -124.679801292
Iteration 642 lower bound -199.394802014
loss is Autograd FloatNode with value -122.451860119 and 1 tape(s)
loss is -121.769382889
Iteration 643 lower bound -202.636197114
loss is Autograd FloatNode with value -118.631581866 and 1 tape(s)
loss is -152.995020915
Iteration 644 lower bound -171.854852155
loss is Autograd FloatNode with value -126.798230363 and 1 tape(s)
loss is -118.235998443
Iteration 645 lower bound -207.12621736
loss is Autograd FloatNode with value -122.326884575 and 1 tape(s)
loss is -122.860898225
Iteration 646 lower bound -202.950183388
loss is Autograd FloatNode with value -121.370864769 and 1 tape(s)
loss is -120.363059628
Iteration 647 lower bound -205.924905567
loss is Autograd FloatNode with value -120.827413456 and 1 tape(s)
loss is -120.42685719
Iteration 648 lower bound -206.292166313
loss is Autograd FloatNode with value -133.952871634 and 1 tape(s)
loss is -122.216596399
Iteration 649 lower bound -204.903406473
loss is Autograd FloatNode with value -126.541108692 and 1 tape(s)
loss is -128.024700655
Iteration 650 lower bound -199.025797314
loss is Autograd FloatNode with value -121.336420677 and 1 tape(s)
loss is -120.996779668
Iteration 651 lower bound -205.923839258
loss is Autograd FloatNode with value -125.029711285 and 1 tape(s)
loss is -119.643539849
Iteration 652 lower bound -207.264062973
loss is Autograd FloatNode with value -126.978226016 and 1 tape(s)
loss is -120.222589987
Iteration 653 lower bound -206.718862142
loss is Autograd FloatNode with value -118.265896356 and 1 tape(s)
loss is -121.179888576
Iteration 654 lower bound -205.710348308
loss is Autograd FloatNode with value -136.311889213 and 1 tape(s)
loss is -130.104312663
Iteration 655 lower bound -196.891845058
loss is Autograd FloatNode with value -131.402996068 and 1 tape(s)
loss is -118.212806474
Iteration 656 lower bound -208.520224825
loss is Autograd FloatNode with value -124.260886979 and 1 tape(s)
loss is -123.947438243
Iteration 657 lower bound -202.575266027
loss is Autograd FloatNode with value -134.223577298 and 1 tape(s)
loss is -136.911154161
Iteration 658 lower bound -189.430490678
loss is Autograd FloatNode with value -131.110218052 and 1 tape(s)
loss is -124.703992162
Iteration 659 lower bound -201.580691408
loss is Autograd FloatNode with value -129.463442209 and 1 tape(s)
loss is -122.916634014
Iteration 660 lower bound -203.302859065
loss is Autograd FloatNode with value -122.478469694 and 1 tape(s)
loss is -135.161681137
Iteration 661 lower bound -191.025363357
loss is Autograd FloatNode with value -118.83621133 and 1 tape(s)
loss is -120.619582596
Iteration 662 lower bound -205.677211641
loss is Autograd FloatNode with value -117.143402688 and 1 tape(s)
loss is -125.752690936
Iteration 663 lower bound -200.872265935
loss is Autograd FloatNode with value -124.965841797 and 1 tape(s)
loss is -128.10100324
Iteration 664 lower bound -198.976555249
loss is Autograd FloatNode with value -129.876716891 and 1 tape(s)
loss is -122.779513956
Iteration 665 lower bound -204.768983653
loss is Autograd FloatNode with value -118.447612456 and 1 tape(s)
loss is -116.317493499
Iteration 666 lower bound -211.573336736
loss is Autograd FloatNode with value -119.765318078 and 1 tape(s)
loss is -122.086170647
Iteration 667 lower bound -206.27134743
loss is Autograd FloatNode with value -129.320950686 and 1 tape(s)
loss is -126.878720816
Iteration 668 lower bound -201.99639086
loss is Autograd FloatNode with value -119.571096105 and 1 tape(s)
loss is -122.762872396
Iteration 669 lower bound -206.614136126
loss is Autograd FloatNode with value -121.8663384 and 1 tape(s)
loss is -124.330781068
Iteration 670 lower bound -205.641366783
loss is Autograd FloatNode with value -154.536922608 and 1 tape(s)
loss is -142.376339586
Iteration 671 lower bound -188.257124637
loss is Autograd FloatNode with value -129.092210244 and 1 tape(s)
loss is -134.165907054
Iteration 672 lower bound -196.481967004
loss is Autograd FloatNode with value -124.320943411 and 1 tape(s)
loss is -120.558518058
Iteration 673 lower bound -210.111775085
loss is Autograd FloatNode with value -135.721146502 and 1 tape(s)
loss is -122.836094294
Iteration 674 lower bound -207.907099976
loss is Autograd FloatNode with value -115.414236148 and 1 tape(s)
loss is -119.214294551
Iteration 675 lower bound -211.284860677
loss is Autograd FloatNode with value -120.995297532 and 1 tape(s)
loss is -118.407546104
Iteration 676 lower bound -212.064835901
loss is Autograd FloatNode with value -119.827689784 and 1 tape(s)
loss is -127.110869294
Iteration 677 lower bound -203.442915373
loss is Autograd FloatNode with value -133.470954958 and 1 tape(s)
loss is -130.632248711
Iteration 678 lower bound -200.171563895
loss is Autograd FloatNode with value -126.467958668 and 1 tape(s)
loss is -142.130381499
Iteration 679 lower bound -188.743267509
loss is Autograd FloatNode with value -122.220029492 and 1 tape(s)
loss is -119.597830122
Iteration 680 lower bound -211.267189698
loss is Autograd FloatNode with value -122.528124647 and 1 tape(s)
loss is -121.112267954
Iteration 681 lower bound -209.825476516
loss is Autograd FloatNode with value -115.416317491 and 1 tape(s)
loss is -123.50846008
Iteration 682 lower bound -207.607947165
loss is Autograd FloatNode with value -129.987438643 and 1 tape(s)
loss is -119.781270995
Iteration 683 lower bound -211.705190869
loss is Autograd FloatNode with value -120.305480397 and 1 tape(s)
loss is -118.999793499
Iteration 684 lower bound -212.668262961
loss is Autograd FloatNode with value -129.878344129 and 1 tape(s)
loss is -120.885681755
Iteration 685 lower bound -210.978095547
loss is Autograd FloatNode with value -127.363835691 and 1 tape(s)
loss is -126.920821457
Iteration 686 lower bound -204.980277584
loss is Autograd FloatNode with value -125.327617589 and 1 tape(s)
loss is -125.053021727
Iteration 687 lower bound -206.811662648
loss is Autograd FloatNode with value -126.923530192 and 1 tape(s)
loss is -128.835115576
Iteration 688 lower bound -203.055898531
loss is Autograd FloatNode with value -126.888388638 and 1 tape(s)
loss is -122.11421734
Iteration 689 lower bound -209.822859712
loss is Autograd FloatNode with value -122.416416357 and 1 tape(s)
loss is -125.640509992
Iteration 690 lower bound -206.369423153
loss is Autograd FloatNode with value -129.779372955 and 1 tape(s)
loss is -126.559377075
Iteration 691 lower bound -205.6546436
loss is Autograd FloatNode with value -125.606091027 and 1 tape(s)
loss is -126.06969645
Iteration 692 lower bound -206.367235756
loss is Autograd FloatNode with value -125.295164933 and 1 tape(s)
loss is -129.440194381
Iteration 693 lower bound -203.297837479
loss is Autograd FloatNode with value -134.345157291 and 1 tape(s)
loss is -130.747617817
Iteration 694 lower bound -202.383203414
loss is Autograd FloatNode with value -133.571997714 and 1 tape(s)
loss is -127.868986874
Iteration 695 lower bound -205.664438541
loss is Autograd FloatNode with value -122.746434022 and 1 tape(s)
loss is -134.67441455
Iteration 696 lower bound -199.212907474
loss is Autograd FloatNode with value -134.917537901 and 1 tape(s)
loss is -146.718793495
Iteration 697 lower bound -187.620174557
loss is Autograd FloatNode with value -126.257328845 and 1 tape(s)
loss is -125.005279549
Iteration 698 lower bound -209.913538788
loss is Autograd FloatNode with value -129.96932958 and 1 tape(s)
loss is -129.796281596
Iteration 699 lower bound -205.71509514
loss is Autograd FloatNode with value -129.58444458 and 1 tape(s)
loss is -127.717365832
Iteration 700 lower bound -208.214464451
loss is Autograd FloatNode with value -128.160532661 and 1 tape(s)
loss is -131.915504459
Iteration 701 lower bound -204.504143183
loss is Autograd FloatNode with value -121.717867648 and 1 tape(s)
loss is -127.321920873
Iteration 702 lower bound -209.72850187
loss is Autograd FloatNode with value -127.739849163 and 1 tape(s)
loss is -143.927684932
Iteration 703 lower bound -193.795113872
loss is Autograd FloatNode with value -133.294797941 and 1 tape(s)
loss is -135.032467609
Iteration 704 lower bound -203.425978768
loss is Autograd FloatNode with value -133.320301801 and 1 tape(s)
loss is -134.440646192
Iteration 705 lower bound -204.692167875
loss is Autograd FloatNode with value -145.290609279 and 1 tape(s)
loss is -127.556476534
Iteration 706 lower bound -212.061653368
loss is Autograd FloatNode with value -132.011262358 and 1 tape(s)
loss is -138.620047399
Iteration 707 lower bound -201.825965285
loss is Autograd FloatNode with value -129.861474282 and 1 tape(s)
loss is -144.694423661
Iteration 708 lower bound -196.29714946
loss is Autograd FloatNode with value -136.814727372 and 1 tape(s)
loss is -128.424620065
Iteration 709 lower bound -213.121446531
loss is Autograd FloatNode with value -140.649666189 and 1 tape(s)
loss is -157.295651241
Iteration 710 lower bound -184.373177296
loss is Autograd FloatNode with value -138.759592921 and 1 tape(s)
loss is -175.507128439
Iteration 711 lower bound -166.01940315
loss is Autograd FloatNode with value -133.980142352 and 1 tape(s)
loss is -130.028265037
Iteration 712 lower bound -211.128604439
loss is Autograd FloatNode with value -162.211198848 and 1 tape(s)
loss is -186.066197493
Iteration 713 lower bound -154.773201424
loss is Autograd FloatNode with value -128.495739872 and 1 tape(s)
loss is -130.310317567
Iteration 714 lower bound -210.110537335
loss is Autograd FloatNode with value -128.43874914 and 1 tape(s)
loss is -126.827098535
Iteration 715 lower bound -213.122551377
loss is Autograd FloatNode with value -127.906590864 and 1 tape(s)
loss is -141.2666392
Iteration 716 lower bound -198.328199238
loss is Autograd FloatNode with value -131.424723841 and 1 tape(s)
loss is -123.20101833
Iteration 717 lower bound -216.130306736
loss is Autograd FloatNode with value -124.15794959 and 1 tape(s)
loss is -123.295224791
Iteration 718 lower bound -215.793745853
loss is Autograd FloatNode with value -128.868030436 and 1 tape(s)
loss is -131.464723843
Iteration 719 lower bound -207.449661105
loss is Autograd FloatNode with value -129.854136276 and 1 tape(s)
loss is -129.939996331
Iteration 720 lower bound -208.82463628
loss is Autograd FloatNode with value -121.595393122 and 1 tape(s)
loss is -121.757884847
Iteration 721 lower bound -216.792076071
loss is Autograd FloatNode with value -131.472347544 and 1 tape(s)
loss is -124.936790402
Iteration 722 lower bound -213.552971334
loss is Autograd FloatNode with value -129.165908596 and 1 tape(s)
loss is -122.578028397
Iteration 723 lower bound -215.773268563
loss is Autograd FloatNode with value -119.998256196 and 1 tape(s)
loss is -123.211329948
Iteration 724 lower bound -215.024376383
loss is Autograd FloatNode with value -128.996065264 and 1 tape(s)
loss is -132.793959492
Iteration 725 lower bound -205.474721018
loss is Autograd FloatNode with value -130.152218303 and 1 tape(s)
loss is -135.412782924
Iteration 726 lower bound -202.914914392
loss is Autograd FloatNode with value -130.746652476 and 1 tape(s)
loss is -124.576136335
Iteration 727 lower bound -213.783498896
loss is Autograd FloatNode with value -123.967869538 and 1 tape(s)
loss is -124.835624736
Iteration 728 lower bound -213.512947008
loss is Autograd FloatNode with value -125.731510822 and 1 tape(s)
loss is -128.562716382
Iteration 729 lower bound -209.948439381
loss is Autograd FloatNode with value -120.630729359 and 1 tape(s)
loss is -126.986711363
Iteration 730 lower bound -211.669002104
loss is Autograd FloatNode with value -125.146846893 and 1 tape(s)
loss is -126.530040785
Iteration 731 lower bound -212.382978204
loss is Autograd FloatNode with value -118.136863528 and 1 tape(s)
loss is -123.36280913
Iteration 732 lower bound -215.759646259
loss is Autograd FloatNode with value -125.989801515 and 1 tape(s)
loss is -128.405540575
Iteration 733 lower bound -211.058971504
loss is Autograd FloatNode with value -147.624310117 and 1 tape(s)
loss is -129.669659492
Iteration 734 lower bound -210.154559869
loss is Autograd FloatNode with value -123.819453503 and 1 tape(s)
loss is -120.045414009
Iteration 735 lower bound -219.529444914
loss is Autograd FloatNode with value -125.596440761 and 1 tape(s)
loss is -127.568902833
Iteration 736 lower bound -211.865002503
loss is Autograd FloatNode with value -126.628805334 and 1 tape(s)
loss is -127.557697884
Iteration 737 lower bound -211.817415699
loss is Autograd FloatNode with value -121.004201976 and 1 tape(s)
loss is -124.178990323
Iteration 738 lower bound -215.166392721
loss is Autograd FloatNode with value -114.918121287 and 1 tape(s)
loss is -121.735960803
Iteration 739 lower bound -217.698775837
loss is Autograd FloatNode with value -125.311699074 and 1 tape(s)
loss is -124.330566951
Iteration 740 lower bound -215.446585859
loss is Autograd FloatNode with value -126.283291657 and 1 tape(s)
loss is -126.005727588
Iteration 741 lower bound -214.170485218
loss is Autograd FloatNode with value -122.724473716 and 1 tape(s)
loss is -122.803337985
Iteration 742 lower bound -217.740869467
loss is Autograd FloatNode with value -130.406744379 and 1 tape(s)
loss is -131.474478734
Iteration 743 lower bound -209.411099176
loss is Autograd FloatNode with value -130.273734597 and 1 tape(s)
loss is -124.963285712
Iteration 744 lower bound -216.252974631
loss is Autograd FloatNode with value -140.766472241 and 1 tape(s)
loss is -123.123233359
Iteration 745 lower bound -218.312472381
loss is Autograd FloatNode with value -137.090299818 and 1 tape(s)
loss is -127.492431935
Iteration 746 lower bound -213.52907248
loss is Autograd FloatNode with value -135.284604013 and 1 tape(s)
loss is -138.966099715
Iteration 747 lower bound -201.497596725
loss is Autograd FloatNode with value -123.661137082 and 1 tape(s)
loss is -133.358554285
Iteration 748 lower bound -206.596324926
loss is Autograd FloatNode with value -136.080704711 and 1 tape(s)
loss is -136.114860072
Iteration 749 lower bound -203.448322891
loss is Autograd FloatNode with value -155.02704481 and 1 tape(s)
loss is -133.112249473
Iteration 750 lower bound -206.159038895
loss is Autograd FloatNode with value -118.818584149 and 1 tape(s)
loss is -118.599636742
Iteration 751 lower bound -219.944178844
loss is Autograd FloatNode with value -124.575709786 and 1 tape(s)
loss is -133.316547551
Iteration 752 lower bound -204.675628995
loss is Autograd FloatNode with value -129.471139144 and 1 tape(s)
loss is -138.758266854
Iteration 753 lower bound -198.786229813
loss is Autograd FloatNode with value -130.291552379 and 1 tape(s)
loss is -120.328956275
Iteration 754 lower bound -216.819836143
loss is Autograd FloatNode with value -132.183031736 and 1 tape(s)
loss is -121.257766494
Iteration 755 lower bound -215.546026036
loss is Autograd FloatNode with value -131.251118321 and 1 tape(s)
loss is -133.975897145
Iteration 756 lower bound -202.530872408
loss is Autograd FloatNode with value -126.867116232 and 1 tape(s)
loss is -126.505929221
Iteration 757 lower bound -209.873124943
loss is Autograd FloatNode with value -121.641313614 and 1 tape(s)
loss is -125.407839273
Iteration 758 lower bound -210.87910481
loss is Autograd FloatNode with value -134.830204922 and 1 tape(s)
loss is -132.408900639
Iteration 759 lower bound -203.839437355
loss is Autograd FloatNode with value -128.722766256 and 1 tape(s)
loss is -121.040144584
Iteration 760 lower bound -215.27679339
loss is Autograd FloatNode with value -131.162900717 and 1 tape(s)
loss is -129.5097672
Iteration 761 lower bound -206.85800807
loss is Autograd FloatNode with value -129.95836768 and 1 tape(s)
loss is -130.944552745
Iteration 762 lower bound -205.525790059
loss is Autograd FloatNode with value -133.505844049 and 1 tape(s)
loss is -131.076583061
Iteration 763 lower bound -205.52715787
loss is Autograd FloatNode with value -132.150639116 and 1 tape(s)
loss is -135.262960445
Iteration 764 lower bound -201.418214812
loss is Autograd FloatNode with value -121.836316777 and 1 tape(s)
loss is -131.858881485
Iteration 765 lower bound -204.911148681
loss is Autograd FloatNode with value -121.04165628 and 1 tape(s)
loss is -125.926589213
Iteration 766 lower bound -211.092642051
loss is Autograd FloatNode with value -141.497767809 and 1 tape(s)
loss is -182.487144595
Iteration 767 lower bound -154.838904117
loss is Autograd FloatNode with value -134.567881058 and 1 tape(s)
loss is -133.824965849
Iteration 768 lower bound -203.797174453
loss is Autograd FloatNode with value -153.441952573 and 1 tape(s)
loss is -145.96211613
Iteration 769 lower bound -191.704942679
loss is Autograd FloatNode with value -129.367761256 and 1 tape(s)
loss is -123.443236748
Iteration 770 lower bound -213.520699291
loss is Autograd FloatNode with value -132.634329272 and 1 tape(s)
loss is -135.324265123
Iteration 771 lower bound -200.993196377
loss is Autograd FloatNode with value -123.661014914 and 1 tape(s)
loss is -116.979510629
Iteration 772 lower bound -218.769759408
loss is Autograd FloatNode with value -131.800704951 and 1 tape(s)
loss is -131.079744608
Iteration 773 lower bound -204.152583529
loss is Autograd FloatNode with value -138.16447876 and 1 tape(s)
loss is -135.868995826
Iteration 774 lower bound -199.026450555
loss is Autograd FloatNode with value -125.513362487 and 1 tape(s)
loss is -130.543261632
Iteration 775 lower bound -203.908578555
loss is Autograd FloatNode with value -145.962969979 and 1 tape(s)
loss is -141.503861454
Iteration 776 lower bound -192.62692801
loss is Autograd FloatNode with value -123.841805331 and 1 tape(s)
loss is -125.197374455
Iteration 777 lower bound -208.605145691
loss is Autograd FloatNode with value -138.194069413 and 1 tape(s)
loss is -140.249514
Iteration 778 lower bound -193.341913117
loss is Autograd FloatNode with value -140.961183863 and 1 tape(s)
loss is -132.856207091
Iteration 779 lower bound -200.580121611
loss is Autograd FloatNode with value -122.226095836 and 1 tape(s)
loss is -148.460020497
Iteration 780 lower bound -184.855933022
loss is Autograd FloatNode with value -140.17204369 and 1 tape(s)
loss is -129.752510962
Iteration 781 lower bound -203.535759275
loss is Autograd FloatNode with value -123.415400257 and 1 tape(s)
loss is -127.105735694
Iteration 782 lower bound -205.957213192
loss is Autograd FloatNode with value -122.493678652 and 1 tape(s)
loss is -126.45603684
Iteration 783 lower bound -206.569535149
loss is Autograd FloatNode with value -127.577862763 and 1 tape(s)
loss is -120.559143705
Iteration 784 lower bound -212.39476919
loss is Autograd FloatNode with value -122.197253745 and 1 tape(s)
loss is -124.980513183
Iteration 785 lower bound -208.065975379
loss is Autograd FloatNode with value -121.223824469 and 1 tape(s)
loss is -123.87551718
Iteration 786 lower bound -209.353244822
loss is Autograd FloatNode with value -118.638144513 and 1 tape(s)
loss is -123.268253063
Iteration 787 lower bound -210.27865401
loss is Autograd FloatNode with value -124.075423806 and 1 tape(s)
loss is -119.753636081
Iteration 788 lower bound -214.222547955
loss is Autograd FloatNode with value -124.313373488 and 1 tape(s)
loss is -120.546742474
Iteration 789 lower bound -213.95630852
loss is Autograd FloatNode with value -121.950895296 and 1 tape(s)
loss is -118.952879668
Iteration 790 lower bound -216.074761157
loss is Autograd FloatNode with value -125.99183596 and 1 tape(s)
loss is -121.866482035
Iteration 791 lower bound -213.812009828
loss is Autograd FloatNode with value -141.453333453 and 1 tape(s)
loss is -124.642744086
Iteration 792 lower bound -211.640568441
loss is Autograd FloatNode with value -127.017337094 and 1 tape(s)
loss is -120.549143117
Iteration 793 lower bound -215.959758299
loss is Autograd FloatNode with value -130.535534673 and 1 tape(s)
loss is -124.556092989
Iteration 794 lower bound -212.06493699
loss is Autograd FloatNode with value -117.203934575 and 1 tape(s)
loss is -127.90233287
Iteration 795 lower bound -208.738317196
loss is Autograd FloatNode with value -128.034511443 and 1 tape(s)
loss is -123.321725986
Iteration 796 lower bound -213.49077402
loss is Autograd FloatNode with value -129.199855249 and 1 tape(s)
loss is -128.865251695
Iteration 797 lower bound -208.097051629
loss is Autograd FloatNode with value -121.409476488 and 1 tape(s)
loss is -130.884120062
Iteration 798 lower bound -206.046519977
loss is Autograd FloatNode with value -124.177846787 and 1 tape(s)
loss is -124.486929381
Iteration 799 lower bound -212.466703505
loss is Autograd FloatNode with value -131.673124125 and 1 tape(s)
loss is -124.584235968
Iteration 800 lower bound -212.380262775
loss is Autograd FloatNode with value -120.293948657 and 1 tape(s)
loss is -123.210607229
Iteration 801 lower bound -213.664974361
loss is Autograd FloatNode with value -125.511422616 and 1 tape(s)
loss is -122.866158647
Iteration 802 lower bound -214.035380016
loss is Autograd FloatNode with value -125.912049669 and 1 tape(s)
loss is -126.708477829
Iteration 803 lower bound -210.22603888
loss is Autograd FloatNode with value -129.66925855 and 1 tape(s)
loss is -126.87285017
Iteration 804 lower bound -210.043659667
loss is Autograd FloatNode with value -128.851510009 and 1 tape(s)
loss is -125.918936964
Iteration 805 lower bound -210.979743746
loss is Autograd FloatNode with value -125.970285428 and 1 tape(s)
loss is -120.451149704
Iteration 806 lower bound -216.430465675
loss is Autograd FloatNode with value -121.791241059 and 1 tape(s)
loss is -119.16471614
Iteration 807 lower bound -217.66034105
loss is Autograd FloatNode with value -124.90603919 and 1 tape(s)
loss is -122.600051453
Iteration 808 lower bound -214.241531675
loss is Autograd FloatNode with value -124.838087535 and 1 tape(s)
loss is -129.030743796
Iteration 809 lower bound -207.860152917
loss is Autograd FloatNode with value -121.873044471 and 1 tape(s)
loss is -124.060853934
Iteration 810 lower bound -212.969355914
loss is Autograd FloatNode with value -121.319766384 and 1 tape(s)
loss is -121.525201535
Iteration 811 lower bound -215.735358057
loss is Autograd FloatNode with value -129.577281845 and 1 tape(s)
loss is -119.368419585
Iteration 812 lower bound -218.179762427
loss is Autograd FloatNode with value -120.007307639 and 1 tape(s)
loss is -125.460476475
Iteration 813 lower bound -212.183459865
loss is Autograd FloatNode with value -137.891470002 and 1 tape(s)
loss is -122.68885481
Iteration 814 lower bound -215.106747354
loss is Autograd FloatNode with value -126.083807485 and 1 tape(s)
loss is -128.019444351
Iteration 815 lower bound -209.507520409
loss is Autograd FloatNode with value -133.673658634 and 1 tape(s)
loss is -139.094922694
Iteration 816 lower bound -198.129629474
loss is Autograd FloatNode with value -132.255349197 and 1 tape(s)
loss is -124.758508447
Iteration 817 lower bound -212.066757845
loss is Autograd FloatNode with value -218.978616331 and 1 tape(s)
loss is -124.727210809
Iteration 818 lower bound -211.737349715
loss is Autograd FloatNode with value -129.976434088 and 1 tape(s)
loss is -117.630940251
Iteration 819 lower bound -218.185078923
loss is Autograd FloatNode with value -124.231609847 and 1 tape(s)
loss is -119.320076437
Iteration 820 lower bound -215.910271677
loss is Autograd FloatNode with value -126.690943816 and 1 tape(s)
loss is -131.944409089
Iteration 821 lower bound -202.904409377
loss is Autograd FloatNode with value -124.975621096 and 1 tape(s)
loss is -122.052297317
Iteration 822 lower bound -212.56626753
loss is Autograd FloatNode with value -116.217543459 and 1 tape(s)
loss is -120.295589437
Iteration 823 lower bound -214.194066212
loss is Autograd FloatNode with value -129.602021264 and 1 tape(s)
loss is -126.569151981
Iteration 824 lower bound -208.021140352
loss is Autograd FloatNode with value -119.530330719 and 1 tape(s)
loss is -121.50500747
Iteration 825 lower bound -213.24116691
loss is Autograd FloatNode with value -123.020757647 and 1 tape(s)
loss is -124.708908847
Iteration 826 lower bound -210.32733667
loss is Autograd FloatNode with value -125.714270085 and 1 tape(s)
loss is -130.593601359
Iteration 827 lower bound -204.7800131
loss is Autograd FloatNode with value -133.076190077 and 1 tape(s)
loss is -124.318085132
Iteration 828 lower bound -211.483784051
loss is Autograd FloatNode with value -123.233678624 and 1 tape(s)
loss is -132.654471242
Iteration 829 lower bound -203.489536032
loss is Autograd FloatNode with value -123.512961767 and 1 tape(s)
loss is -124.568843593
Iteration 830 lower bound -212.049033822
loss is Autograd FloatNode with value -128.200524342 and 1 tape(s)
loss is -121.349667545
Iteration 831 lower bound -215.779101985
loss is Autograd FloatNode with value -133.04878382 and 1 tape(s)
loss is -129.435120643
Iteration 832 lower bound -208.173200489
loss is Autograd FloatNode with value -122.925300423 and 1 tape(s)
loss is -121.160036346
Iteration 833 lower bound -216.825851346
loss is Autograd FloatNode with value -123.299353996 and 1 tape(s)
loss is -125.659136486
Iteration 834 lower bound -212.787853753
loss is Autograd FloatNode with value -121.836602503 and 1 tape(s)
loss is -126.643031031
Iteration 835 lower bound -212.279297477
loss is Autograd FloatNode with value -129.034687626 and 1 tape(s)
loss is -132.536106345
Iteration 836 lower bound -206.912515362
loss is Autograd FloatNode with value -127.390667907 and 1 tape(s)
loss is -125.32388227
Iteration 837 lower bound -214.543552231
loss is Autograd FloatNode with value -127.698072042 and 1 tape(s)
loss is -125.936936776
Iteration 838 lower bound -214.315477434
loss is Autograd FloatNode with value -127.296566924 and 1 tape(s)
loss is -122.549263052
Iteration 839 lower bound -218.075005635
loss is Autograd FloatNode with value -129.774683862 and 1 tape(s)
loss is -128.400752275
Iteration 840 lower bound -212.596042111
loss is Autograd FloatNode with value -121.713866619 and 1 tape(s)
loss is -124.610361136
Iteration 841 lower bound -216.721466144
loss is Autograd FloatNode with value -136.879540504 and 1 tape(s)
loss is -131.790641403
Iteration 842 lower bound -209.904945258
loss is Autograd FloatNode with value -126.776598674 and 1 tape(s)
loss is -130.857459218
Iteration 843 lower bound -211.119927717
loss is Autograd FloatNode with value -130.707973064 and 1 tape(s)
loss is -124.009593918
Iteration 844 lower bound -218.262188821
loss is Autograd FloatNode with value -130.199609518 and 1 tape(s)
loss is -128.288635441
Iteration 845 lower bound -214.18200852
loss is Autograd FloatNode with value -122.426923436 and 1 tape(s)
loss is -131.345646567
Iteration 846 lower bound -211.159675979
loss is Autograd FloatNode with value -134.895453961 and 1 tape(s)
loss is -133.462142463
Iteration 847 lower bound -209.178750222
loss is Autograd FloatNode with value -129.053796836 and 1 tape(s)
loss is -123.350641674
Iteration 848 lower bound -219.398495457
loss is Autograd FloatNode with value -132.420631998 and 1 tape(s)
loss is -126.916875419
Iteration 849 lower bound -215.856673723
loss is Autograd FloatNode with value -128.877297324 and 1 tape(s)
loss is -129.547720374
Iteration 850 lower bound -213.155866561
loss is Autograd FloatNode with value -126.028758694 and 1 tape(s)
loss is -122.362377155
Iteration 851 lower bound -220.271789437
loss is Autograd FloatNode with value -121.97454329 and 1 tape(s)
loss is -121.115352012
Iteration 852 lower bound -221.38655368
loss is Autograd FloatNode with value -120.546161091 and 1 tape(s)
loss is -127.188869303
Iteration 853 lower bound -215.247580041
loss is Autograd FloatNode with value -125.247736754 and 1 tape(s)
loss is -129.175448067
Iteration 854 lower bound -213.261222724
loss is Autograd FloatNode with value -131.746570561 and 1 tape(s)
loss is -120.991981341
Iteration 855 lower bound -221.541392982
loss is Autograd FloatNode with value -117.867990577 and 1 tape(s)
loss is -125.54559468
Iteration 856 lower bound -216.978077562
loss is Autograd FloatNode with value -131.820099166 and 1 tape(s)
loss is -123.669462151
Iteration 857 lower bound -218.991183391
loss is Autograd FloatNode with value -126.291794431 and 1 tape(s)
loss is -133.910368701
Iteration 858 lower bound -208.891979401
loss is Autograd FloatNode with value -136.682646567 and 1 tape(s)
loss is -125.015322394
Iteration 859 lower bound -217.953820602
loss is Autograd FloatNode with value -122.025798343 and 1 tape(s)
loss is -155.582240295
Iteration 860 lower bound -187.374475298
loss is Autograd FloatNode with value -121.280474693 and 1 tape(s)
loss is -132.593290492
Iteration 861 lower bound -210.372637708
loss is Autograd FloatNode with value -120.386505961 and 1 tape(s)
loss is -124.235551821
Iteration 862 lower bound -218.888041382
loss is Autograd FloatNode with value -123.560278698 and 1 tape(s)
loss is -121.125283948
Iteration 863 lower bound -222.243989267
loss is Autograd FloatNode with value -130.347728589 and 1 tape(s)
loss is -145.161642855
Iteration 864 lower bound -198.427708547
loss is Autograd FloatNode with value -123.933444278 and 1 tape(s)
loss is -131.648259654
Iteration 865 lower bound -212.168234021
loss is Autograd FloatNode with value -117.92366491 and 1 tape(s)
loss is -140.446246605
Iteration 866 lower bound -203.57836777
loss is Autograd FloatNode with value -129.973264054 and 1 tape(s)
loss is -130.301189285
Iteration 867 lower bound -214.005557966
loss is Autograd FloatNode with value -125.397665329 and 1 tape(s)
loss is -128.750439624
Iteration 868 lower bound -215.780620604
loss is Autograd FloatNode with value -140.591678454 and 1 tape(s)
loss is -125.013066598
Iteration 869 lower bound -219.637622228
loss is Autograd FloatNode with value -116.795391722 and 1 tape(s)
loss is -221.401681341
Iteration 870 lower bound -123.267135642
loss is Autograd FloatNode with value -122.057753998 and 1 tape(s)
loss is -125.446243327
Iteration 871 lower bound -219.386440971
loss is Autograd FloatNode with value -134.465715157 and 1 tape(s)
loss is -127.474217119
Iteration 872 lower bound -217.541985004
loss is Autograd FloatNode with value -124.712330809 and 1 tape(s)
loss is -123.881643502
Iteration 873 lower bound -221.285641875
loss is Autograd FloatNode with value -130.816302884 and 1 tape(s)
loss is -123.116779736
Iteration 874 lower bound -222.266618546
loss is Autograd FloatNode with value -124.532256101 and 1 tape(s)
loss is -132.763469452
Iteration 875 lower bound -212.662469707
loss is Autograd FloatNode with value -143.905089998 and 1 tape(s)
loss is -165.097332421
Iteration 876 lower bound -180.317710422
loss is Autograd FloatNode with value -122.091108031 and 1 tape(s)
loss is -121.709815574
Iteration 877 lower bound -223.513480469
loss is Autograd FloatNode with value -138.701775777 and 1 tape(s)
loss is -131.357259938
Iteration 878 lower bound -213.786430285
loss is Autograd FloatNode with value -137.285342262 and 1 tape(s)
loss is -126.748776557
Iteration 879 lower bound -217.987098717
loss is Autograd FloatNode with value -124.010012443 and 1 tape(s)
loss is -117.256623268
Iteration 880 lower bound -227.120810384
loss is Autograd FloatNode with value -120.449993217 and 1 tape(s)
loss is -122.71484763
Iteration 881 lower bound -221.390070288
loss is Autograd FloatNode with value -130.041986118 and 1 tape(s)
loss is -152.308744852
Iteration 882 lower bound -191.638183104
loss is Autograd FloatNode with value -127.873465038 and 1 tape(s)
loss is -142.761977124
Iteration 883 lower bound -201.106142693
loss is Autograd FloatNode with value -138.888129071 and 1 tape(s)
loss is -125.217132351
Iteration 884 lower bound -218.631119497
loss is Autograd FloatNode with value -130.136270559 and 1 tape(s)
loss is -134.11760039
Iteration 885 lower bound -209.517274272
loss is Autograd FloatNode with value -118.924428031 and 1 tape(s)
loss is -139.81738712
Iteration 886 lower bound -203.559583203
loss is Autograd FloatNode with value -123.659818846 and 1 tape(s)
loss is -127.352705868
Iteration 887 lower bound -215.909326021
loss is Autograd FloatNode with value -124.840908347 and 1 tape(s)
loss is -129.732056632
Iteration 888 lower bound -213.462924692
loss is Autograd FloatNode with value -134.686650028 and 1 tape(s)
loss is -130.726270765
Iteration 889 lower bound -212.373513145
loss is Autograd FloatNode with value -125.074514495 and 1 tape(s)
loss is -114.45162495
Iteration 890 lower bound -228.314283992
loss is Autograd FloatNode with value -121.806004315 and 1 tape(s)
loss is -114.181319234
Iteration 891 lower bound -228.32354144
loss is Autograd FloatNode with value -125.26215174 and 1 tape(s)
loss is -130.868525844
Iteration 892 lower bound -211.491530251
loss is Autograd FloatNode with value -120.676260344 and 1 tape(s)
loss is -126.43888307
Iteration 893 lower bound -215.813069762
loss is Autograd FloatNode with value -133.990781834 and 1 tape(s)
loss is -124.537501068
Iteration 894 lower bound -217.68290203
loss is Autograd FloatNode with value -123.446820705 and 1 tape(s)
loss is -118.088506473
Iteration 895 lower bound -224.065773974
loss is Autograd FloatNode with value -119.89453731 and 1 tape(s)
loss is -119.191400194
Iteration 896 lower bound -222.892568503
loss is Autograd FloatNode with value -131.134077451 and 1 tape(s)
loss is -117.960536449
Iteration 897 lower bound -224.219208906
loss is Autograd FloatNode with value -126.292138419 and 1 tape(s)
loss is -121.378752232
Iteration 898 lower bound -220.850198112
loss is Autograd FloatNode with value -134.718569081 and 1 tape(s)
loss is -145.305236513
Iteration 899 lower bound -196.964184645
loss is Autograd FloatNode with value -119.547603224 and 1 tape(s)
loss is -142.433616
Iteration 900 lower bound -199.96188889
loss is Autograd FloatNode with value -124.286156909 and 1 tape(s)
loss is -125.028920638
Iteration 901 lower bound -217.691523732
loss is Autograd FloatNode with value -138.011913719 and 1 tape(s)
loss is -132.578533199
Iteration 902 lower bound -210.523178045
loss is Autograd FloatNode with value -136.553008905 and 1 tape(s)
loss is -128.877617297
Iteration 903 lower bound -214.191238921
loss is Autograd FloatNode with value -127.35647954 and 1 tape(s)
loss is -133.083647852
Iteration 904 lower bound -209.855557332
loss is Autograd FloatNode with value -130.371212756 and 1 tape(s)
loss is -262.717747668
Iteration 905 lower bound -80.0425990313
loss is Autograd FloatNode with value -132.523339932 and 1 tape(s)
loss is -124.400449236
Iteration 906 lower bound -218.322432811
loss is Autograd FloatNode with value -116.229253492 and 1 tape(s)
loss is -123.659345937
Iteration 907 lower bound -219.073815168
loss is Autograd FloatNode with value -148.159054371 and 1 tape(s)
loss is -129.208439606
Iteration 908 lower bound -213.718441579
loss is Autograd FloatNode with value -137.536211573 and 1 tape(s)
loss is -124.444948438
Iteration 909 lower bound -218.460093979
loss is Autograd FloatNode with value -125.628226739 and 1 tape(s)
loss is -120.987171574
Iteration 910 lower bound -221.866292706
loss is Autograd FloatNode with value -137.646174137 and 1 tape(s)
loss is -134.532035099
Iteration 911 lower bound -208.228933177
loss is Autograd FloatNode with value -132.250715489 and 1 tape(s)
loss is -133.856901155
Iteration 912 lower bound -208.751359732
loss is Autograd FloatNode with value -120.52321488 and 1 tape(s)
loss is -128.534592278
Iteration 913 lower bound -213.788068264
loss is Autograd FloatNode with value -129.152285368 and 1 tape(s)
loss is -128.910639154
Iteration 914 lower bound -213.182159788
loss is Autograd FloatNode with value -120.905449486 and 1 tape(s)
loss is -120.191013521
Iteration 915 lower bound -221.675193218
loss is Autograd FloatNode with value -125.685737035 and 1 tape(s)
loss is -127.481712004
Iteration 916 lower bound -214.175579443
loss is Autograd FloatNode with value -119.551710838 and 1 tape(s)
loss is -125.329900191
Iteration 917 lower bound -216.180833502
loss is Autograd FloatNode with value -122.285357 and 1 tape(s)
loss is -118.402469804
Iteration 918 lower bound -222.974550589
loss is Autograd FloatNode with value -127.620784871 and 1 tape(s)
loss is -116.957421702
Iteration 919 lower bound -224.332784764
loss is Autograd FloatNode with value -123.881828231 and 1 tape(s)
loss is -132.942933318
Iteration 920 lower bound -208.216690523
loss is Autograd FloatNode with value -136.464057178 and 1 tape(s)
loss is -168.919176588
Iteration 921 lower bound -172.178317738
loss is Autograd FloatNode with value -117.35292733 and 1 tape(s)
loss is -118.366112171
Iteration 922 lower bound -222.418934297
loss is Autograd FloatNode with value -120.170647685 and 1 tape(s)
loss is -126.772378966
Iteration 923 lower bound -213.830659191
loss is Autograd FloatNode with value -125.727285733 and 1 tape(s)
loss is -129.157415713
Iteration 924 lower bound -211.463687005
loss is Autograd FloatNode with value -120.167520439 and 1 tape(s)
loss is -122.00386432
Iteration 925 lower bound -218.66071594
loss is Autograd FloatNode with value -128.579025353 and 1 tape(s)
loss is -126.550506499
Iteration 926 lower bound -214.159605945
loss is Autograd FloatNode with value -123.973658548 and 1 tape(s)
loss is -120.77134185
Iteration 927 lower bound -219.898801817
loss is Autograd FloatNode with value -123.280250076 and 1 tape(s)
loss is -124.635075988
Iteration 928 lower bound -215.997835842
loss is Autograd FloatNode with value -128.114028003 and 1 tape(s)
loss is -129.307298722
Iteration 929 lower bound -211.346241495
loss is Autograd FloatNode with value -122.983279517 and 1 tape(s)
loss is -118.754875889
Iteration 930 lower bound -221.874113252
loss is Autograd FloatNode with value -133.943747821 and 1 tape(s)
loss is -117.955325491
Iteration 931 lower bound -222.718584418
loss is Autograd FloatNode with value -127.942310309 and 1 tape(s)
loss is -120.670273344
Iteration 932 lower bound -219.911180022
loss is Autograd FloatNode with value -121.455727285 and 1 tape(s)
loss is -128.209862294
Iteration 933 lower bound -212.275283388
loss is Autograd FloatNode with value -122.084448205 and 1 tape(s)
loss is -123.784249456
Iteration 934 lower bound -216.660575511
loss is Autograd FloatNode with value -124.270698182 and 1 tape(s)
loss is -120.472969454
Iteration 935 lower bound -219.933644584
loss is Autograd FloatNode with value -120.923400602 and 1 tape(s)
loss is -119.248899297
Iteration 936 lower bound -221.142272448
loss is Autograd FloatNode with value -126.099819999 and 1 tape(s)
loss is -123.524076972
Iteration 937 lower bound -216.977105149
loss is Autograd FloatNode with value -116.422544285 and 1 tape(s)
loss is -127.739022974
Iteration 938 lower bound -212.759972346
loss is Autograd FloatNode with value -129.522842 and 1 tape(s)
loss is -131.34917513
Iteration 939 lower bound -209.306205041
loss is Autograd FloatNode with value -155.472910919 and 1 tape(s)
loss is -125.914915413
Iteration 940 lower bound -215.010075421
loss is Autograd FloatNode with value -125.195501725 and 1 tape(s)
loss is -120.842986386
Iteration 941 lower bound -219.725893063
loss is Autograd FloatNode with value -123.132049789 and 1 tape(s)
loss is -139.607466797
Iteration 942 lower bound -200.730887656
loss is Autograd FloatNode with value -122.37484882 and 1 tape(s)
loss is -121.664076059
Iteration 943 lower bound -218.422062976
loss is Autograd FloatNode with value -122.872755832 and 1 tape(s)
loss is -120.393302246
Iteration 944 lower bound -219.466461758
loss is Autograd FloatNode with value -124.41612853 and 1 tape(s)
loss is -122.3026952
Iteration 945 lower bound -217.382481522
loss is Autograd FloatNode with value -131.841813838 and 1 tape(s)
loss is -125.630212948
Iteration 946 lower bound -213.894049328
loss is Autograd FloatNode with value -123.067027774 and 1 tape(s)
loss is -122.162332698
Iteration 947 lower bound -217.055218876
loss is Autograd FloatNode with value -123.574194516 and 1 tape(s)
loss is -124.746891682
Iteration 948 lower bound -214.210539597
loss is Autograd FloatNode with value -121.646266955 and 1 tape(s)
loss is -124.530502985
Iteration 949 lower bound -214.211979707
loss is Autograd FloatNode with value -121.640895516 and 1 tape(s)
loss is -121.016388097
Iteration 950 lower bound -217.614369331
loss is Autograd FloatNode with value -118.021769 and 1 tape(s)
loss is -120.95797499
Iteration 951 lower bound -217.66495517
loss is Autograd FloatNode with value -124.49715409 and 1 tape(s)
loss is -143.70997928
Iteration 952 lower bound -195.03954914
loss is Autograd FloatNode with value -123.714272109 and 1 tape(s)
loss is -116.071616744
Iteration 953 lower bound -222.831613014
loss is Autograd FloatNode with value -125.819591948 and 1 tape(s)
loss is -123.346511072
Iteration 954 lower bound -215.819825674
loss is Autograd FloatNode with value -125.602315037 and 1 tape(s)
loss is -126.797830023
Iteration 955 lower bound -212.595838927
loss is Autograd FloatNode with value -117.326926618 and 1 tape(s)
loss is -126.586262582
Iteration 956 lower bound -213.072813754
loss is Autograd FloatNode with value -126.441220866 and 1 tape(s)
loss is -126.628728202
Iteration 957 lower bound -213.416967771
loss is Autograd FloatNode with value -119.408716723 and 1 tape(s)
loss is -129.684920346
Iteration 958 lower bound -210.720977304
loss is Autograd FloatNode with value -130.346399766 and 1 tape(s)
loss is -134.276475938
Iteration 959 lower bound -206.581612733
loss is Autograd FloatNode with value -117.681756137 and 1 tape(s)
loss is -130.321142105
Iteration 960 lower bound -210.969860031
loss is Autograd FloatNode with value -124.454610273 and 1 tape(s)
loss is -141.008169431
Iteration 961 lower bound -200.761481934
loss is Autograd FloatNode with value -126.591847573 and 1 tape(s)
loss is -126.143611012
Iteration 962 lower bound -216.163258496
loss is Autograd FloatNode with value -124.957898956 and 1 tape(s)
loss is -131.541666991
Iteration 963 lower bound -211.311899782
loss is Autograd FloatNode with value -133.013143794 and 1 tape(s)
loss is -122.654759983
Iteration 964 lower bound -220.689996215
loss is Autograd FloatNode with value -131.88340359 and 1 tape(s)
loss is -121.678087036
Iteration 965 lower bound -221.93539699
loss is Autograd FloatNode with value -134.35350511 and 1 tape(s)
loss is -124.476775266
Iteration 966 lower bound -219.288034937
loss is Autograd FloatNode with value -134.398926795 and 1 tape(s)
loss is -131.713784734
Iteration 967 lower bound -211.791480865
loss is Autograd FloatNode with value -125.521124124 and 1 tape(s)
loss is -122.354943773
Iteration 968 lower bound -220.904434334
loss is Autograd FloatNode with value -133.115523126 and 1 tape(s)
loss is -127.501664201
Iteration 969 lower bound -215.580567314
loss is Autograd FloatNode with value -145.394247732 and 1 tape(s)
loss is -127.059062068
Iteration 970 lower bound -215.979654676
loss is Autograd FloatNode with value -128.374058092 and 1 tape(s)
loss is -136.301310976
Iteration 971 lower bound -206.294531534
loss is Autograd FloatNode with value -128.400668656 and 1 tape(s)
loss is -128.96470719
Iteration 972 lower bound -213.175874375
loss is Autograd FloatNode with value -123.051487223 and 1 tape(s)
loss is -123.133404584
Iteration 973 lower bound -218.651425232
loss is Autograd FloatNode with value -122.257658955 and 1 tape(s)
loss is -122.738295722
Iteration 974 lower bound -218.72475974
loss is Autograd FloatNode with value -125.748641729 and 1 tape(s)
loss is -134.687805518
Iteration 975 lower bound -206.524459575
loss is Autograd FloatNode with value -125.785723673 and 1 tape(s)
loss is -121.729892041
Iteration 976 lower bound -219.394972814
loss is Autograd FloatNode with value -121.920470076 and 1 tape(s)
loss is -129.269364207
Iteration 977 lower bound -211.605532008
loss is Autograd FloatNode with value -123.824206075 and 1 tape(s)
loss is -132.757485696
Iteration 978 lower bound -208.029685289
loss is Autograd FloatNode with value -118.557138689 and 1 tape(s)
loss is -124.483311657
Iteration 979 lower bound -216.332890361
loss is Autograd FloatNode with value -121.894157987 and 1 tape(s)
loss is -116.593990001
Iteration 980 lower bound -224.351903177
loss is Autograd FloatNode with value -119.79813547 and 1 tape(s)
loss is -119.804023443
Iteration 981 lower bound -221.316223436
loss is Autograd FloatNode with value -115.983691523 and 1 tape(s)
loss is -118.250229031
Iteration 982 lower bound -223.112131809
loss is Autograd FloatNode with value -122.744161374 and 1 tape(s)
loss is -121.6973025
Iteration 983 lower bound -220.004832677
loss is Autograd FloatNode with value -122.798982955 and 1 tape(s)
loss is -130.702777342
Iteration 984 lower bound -211.24624902
loss is Autograd FloatNode with value -120.289505233 and 1 tape(s)
loss is -116.547821425
Iteration 985 lower bound -225.678333073
loss is Autograd FloatNode with value -116.109117226 and 1 tape(s)
loss is -117.754293189
Iteration 986 lower bound -224.716023524
loss is Autograd FloatNode with value -124.052179352 and 1 tape(s)
loss is -128.249779338
Iteration 987 lower bound -214.607258125
loss is Autograd FloatNode with value -122.621080195 and 1 tape(s)
loss is -115.681427545
Iteration 988 lower bound -227.502994751
loss is Autograd FloatNode with value -123.036619224 and 1 tape(s)
loss is -132.49243218
Iteration 989 lower bound -210.974585026
loss is Autograd FloatNode with value -125.063013404 and 1 tape(s)
loss is -125.993585265
Iteration 990 lower bound -217.704562834
loss is Autograd FloatNode with value -128.365906896 and 1 tape(s)
loss is -127.420483816
Iteration 991 lower bound -216.431236202
loss is Autograd FloatNode with value -132.672640034 and 1 tape(s)
loss is -156.913230173
Iteration 992 lower bound -186.878364847
loss is Autograd FloatNode with value -121.340492829 and 1 tape(s)
loss is -117.51269122
Iteration 993 lower bound -226.164966962
loss is Autograd FloatNode with value -134.645728228 and 1 tape(s)
loss is -130.79038293
Iteration 994 lower bound -212.807891414
loss is Autograd FloatNode with value -133.8551731 and 1 tape(s)
loss is -123.102411792
Iteration 995 lower bound -220.182871425
loss is Autograd FloatNode with value -142.335720252 and 1 tape(s)
loss is -122.943250533
Iteration 996 lower bound -219.938112345
loss is Autograd FloatNode with value -157.074735737 and 1 tape(s)
loss is -140.102913984
Iteration 997 lower bound -202.107927704
loss is Autograd FloatNode with value -121.750523242 and 1 tape(s)
loss is -120.557678329
Iteration 998 lower bound -220.293696757
loss is Autograd FloatNode with value -127.191673979 and 1 tape(s)
loss is -128.063149815
Iteration 999 lower bound -211.612909254
Optimizing variational parameters...
loss is Autograd FloatNode with value -20965.9241238 and 1 tape(s)
loss is -20986.2389109
Iteration 0 lower bound 21491.1685777
loss is Autograd FloatNode with value -10726.6463956 and 1 tape(s)
loss is -10666.8393663
Iteration 1 lower bound 11160.4690332
loss is Autograd FloatNode with value -4752.38335913 and 1 tape(s)
loss is -4745.95788929
Iteration 2 lower bound 5228.56721036
loss is Autograd FloatNode with value -2004.91417467 and 1 tape(s)
loss is -1988.46488593
Iteration 3 lower bound 2459.42543292
loss is Autograd FloatNode with value -944.675595904 and 1 tape(s)
loss is -946.30991732
Iteration 4 lower bound 1405.33151751
loss is Autograd FloatNode with value -652.405459976 and 1 tape(s)
loss is -650.506087284
Iteration 5 lower bound 1097.33700889
loss is Autograd FloatNode with value -659.788730807 and 1 tape(s)
loss is -660.106139772
Iteration 6 lower bound 1094.59487908
loss is Autograd FloatNode with value -757.786619369 and 1 tape(s)
loss is -752.623356164
Iteration 7 lower bound 1174.64658825
loss is Autograd FloatNode with value -817.718918124 and 1 tape(s)
loss is -823.834925055
Iteration 8 lower bound 1233.31140405
loss is Autograd FloatNode with value -823.381251748 and 1 tape(s)
loss is -822.904544784
Iteration 9 lower bound 1219.7609222
loss is Autograd FloatNode with value -765.268638743 and 1 tape(s)
loss is -766.844067199
Iteration 10 lower bound 1151.02826488
loss is Autograd FloatNode with value -678.010473037 and 1 tape(s)
loss is -678.119887919
Iteration 11 lower bound 1049.60509756
loss is Autograd FloatNode with value -608.924195104 and 1 tape(s)
loss is -605.116207282
Iteration 12 lower bound 963.852363511
loss is Autograd FloatNode with value -564.670369511 and 1 tape(s)
loss is -565.801387765
Iteration 13 lower bound 911.775155253
loss is Autograd FloatNode with value -551.438304358 and 1 tape(s)
loss is -554.631501095
Iteration 14 lower bound 887.802944464
loss is Autograd FloatNode with value -546.983246792 and 1 tape(s)
loss is -552.264372464
Iteration 15 lower bound 872.604086113
loss is Autograd FloatNode with value -535.675929047 and 1 tape(s)
loss is -534.830940457
Iteration 16 lower bound 842.320490689
loss is Autograd FloatNode with value -509.544401559 and 1 tape(s)
loss is -510.951712741
Iteration 17 lower bound 805.58686956
loss is Autograd FloatNode with value -458.32017393 and 1 tape(s)
loss is -457.460614317
Iteration 18 lower bound 739.277432412
loss is Autograd FloatNode with value -405.26621221 and 1 tape(s)
loss is -410.094847421
Iteration 19 lower bound 679.126341056
loss is Autograd FloatNode with value -371.80612986 and 1 tape(s)
loss is -367.668826226
Iteration 20 lower bound 623.951352912
loss is Autograd FloatNode with value -360.152731438 and 1 tape(s)
loss is -363.696101096
Iteration 21 lower bound 607.311744917
loss is Autograd FloatNode with value -385.680177429 and 1 tape(s)
loss is -370.700666979
Iteration 22 lower bound 601.710381221
loss is Autograd FloatNode with value -381.183450519 and 1 tape(s)
loss is -379.056620318
Iteration 23 lower bound 597.715355173
loss is Autograd FloatNode with value -350.639445225 and 1 tape(s)
loss is -357.598641133
Iteration 24 lower bound 564.103471667
loss is Autograd FloatNode with value -314.080462737 and 1 tape(s)
loss is -317.64148462
Iteration 25 lower bound 512.165540894
loss is Autograd FloatNode with value -294.787392902 and 1 tape(s)
loss is -303.769570726
Iteration 26 lower bound 486.386700993
loss is Autograd FloatNode with value -294.574142153 and 1 tape(s)
loss is -295.753003542
Iteration 27 lower bound 466.511603283
loss is Autograd FloatNode with value -297.211275739 and 1 tape(s)
loss is -318.846786767
Iteration 28 lower bound 477.875536921
loss is Autograd FloatNode with value -285.993252692 and 1 tape(s)
loss is -300.576095934
Iteration 29 lower bound 447.926984656
loss is Autograd FloatNode with value -296.32070144 and 1 tape(s)
loss is -292.378155127
Iteration 30 lower bound 428.063181237
loss is Autograd FloatNode with value -275.558450239 and 1 tape(s)
loss is -273.442009064
Iteration 31 lower bound 397.881992708
loss is Autograd FloatNode with value -260.128091906 and 1 tape(s)
loss is -263.087272897
Iteration 32 lower bound 376.569689213
loss is Autograd FloatNode with value -274.074282562 and 1 tape(s)
loss is -275.678871615
Iteration 33 lower bound 378.404319272
loss is Autograd FloatNode with value -291.167928408 and 1 tape(s)
loss is -282.877920747
Iteration 34 lower bound 375.391496204
loss is Autograd FloatNode with value -277.095489457 and 1 tape(s)
loss is -289.687573873
Iteration 35 lower bound 372.677028911
loss is Autograd FloatNode with value -275.257591912 and 1 tape(s)
loss is -272.280470695
Iteration 36 lower bound 346.026874188
loss is Autograd FloatNode with value -274.996325339 and 1 tape(s)
loss is -259.792102813
Iteration 37 lower bound 324.589154973
loss is Autograd FloatNode with value -245.722457245 and 1 tape(s)
loss is -238.954727404
Iteration 38 lower bound 295.16196408
loss is Autograd FloatNode with value -268.931429676 and 1 tape(s)
loss is -239.861564442
Iteration 39 lower bound 287.594780304
loss is Autograd FloatNode with value -255.348819386 and 1 tape(s)
loss is -268.682102124
Iteration 40 lower bound 308.354603623
loss is Autograd FloatNode with value -251.982445287 and 1 tape(s)
loss is -243.358212147
Iteration 41 lower bound 275.20005046
loss is Autograd FloatNode with value -257.483224706 and 1 tape(s)
loss is -251.203514266
Iteration 42 lower bound 275.536240803
loss is Autograd FloatNode with value -232.058264552 and 1 tape(s)
loss is -221.08325333
Iteration 43 lower bound 238.324522154
loss is Autograd FloatNode with value -235.712515166 and 1 tape(s)
loss is -231.379675647
Iteration 44 lower bound 241.654171463
loss is Autograd FloatNode with value -235.349717337 and 1 tape(s)
loss is -230.101526769
Iteration 45 lower bound 233.688157446
loss is Autograd FloatNode with value -222.590857648 and 1 tape(s)
loss is -225.528648829
Iteration 46 lower bound 222.572442408
loss is Autograd FloatNode with value -203.621563558 and 1 tape(s)
loss is -228.440148847
Iteration 47 lower bound 219.080344605
loss is Autograd FloatNode with value -211.194311172 and 1 tape(s)
loss is -203.629310078
Iteration 48 lower bound 187.73140392
loss is Autograd FloatNode with value -206.524995453 and 1 tape(s)
loss is -204.922732017
Iteration 49 lower bound 182.670322525
loss is Autograd FloatNode with value -198.84814878 and 1 tape(s)
loss is -205.308986678
Iteration 50 lower bound 176.820553469
loss is Autograd FloatNode with value -195.977848107 and 1 tape(s)
loss is -206.341057825
Iteration 51 lower bound 171.774655478
loss is Autograd FloatNode with value -197.253913189 and 1 tape(s)
loss is -206.679823446
Iteration 52 lower bound 166.344305865
loss is Autograd FloatNode with value -188.630427762 and 1 tape(s)
loss is -178.237774015
Iteration 53 lower bound 132.788347961
loss is Autograd FloatNode with value -194.123547886 and 1 tape(s)
loss is -195.668901114
Iteration 54 lower bound 145.468214806
loss is Autograd FloatNode with value -179.628251336 and 1 tape(s)
loss is -180.169470047
Iteration 55 lower bound 125.953953053
loss is Autograd FloatNode with value -183.775067906 and 1 tape(s)
loss is -163.077252397
Iteration 56 lower bound 105.119366702
loss is Autograd FloatNode with value -191.601400066 and 1 tape(s)
loss is -178.342396453
Iteration 57 lower bound 117.19763984
loss is Autograd FloatNode with value -179.79824688 and 1 tape(s)
loss is -158.135411799
Iteration 58 lower bound 94.5198807
loss is Autograd FloatNode with value -159.615089028 and 1 tape(s)
loss is -171.925551445
Iteration 59 lower bound 106.273843604
loss is Autograd FloatNode with value -161.016620687 and 1 tape(s)
loss is -191.68226752
Iteration 60 lower bound 124.071954061
loss is Autograd FloatNode with value -166.45350808 and 1 tape(s)
loss is -135.638158633
Iteration 61 lower bound 66.2576501806
loss is Autograd FloatNode with value -175.055334764 and 1 tape(s)
loss is -160.05503616
Iteration 62 lower bound 89.5702916553
loss is Autograd FloatNode with value -144.347876294 and 1 tape(s)
loss is -161.518790486
Iteration 63 lower bound 89.8996104033
loss is Autograd FloatNode with value -160.386811074 and 1 tape(s)
loss is -160.827962717
Iteration 64 lower bound 87.59775081
loss is Autograd FloatNode with value -140.629604922 and 1 tape(s)
loss is -145.219217899
Iteration 65 lower bound 70.4539076598
loss is Autograd FloatNode with value -132.773068811 and 1 tape(s)
loss is -142.280935136
Iteration 66 lower bound 65.6706730053
loss is Autograd FloatNode with value -160.862527822 and 1 tape(s)
loss is -144.612027071
Iteration 67 lower bound 66.0970005262
loss is Autograd FloatNode with value -143.396961829 and 1 tape(s)
loss is -151.157451318
Iteration 68 lower bound 70.9024802925
loss is Autograd FloatNode with value -136.672440426 and 1 tape(s)
loss is -158.151917671
Iteration 69 lower bound 76.1534711813
loss is Autograd FloatNode with value -144.272111397 and 1 tape(s)
loss is -150.254416906
Iteration 70 lower bound 66.5984099443
loss is Autograd FloatNode with value -138.422434223 and 1 tape(s)
loss is -144.656819698
Iteration 71 lower bound 59.4855039791
loss is Autograd FloatNode with value -137.20818439 and 1 tape(s)
loss is -130.566996557
Iteration 72 lower bound 43.8252877996
loss is Autograd FloatNode with value -139.482513616 and 1 tape(s)
loss is -130.499785471
Iteration 73 lower bound 42.0351826644
loss is Autograd FloatNode with value -139.286561139 and 1 tape(s)
loss is -132.841392438
Iteration 74 lower bound 42.7960069797
loss is Autograd FloatNode with value -130.061838892 and 1 tape(s)
loss is -132.312862216
Iteration 75 lower bound 41.1207320353
loss is Autograd FloatNode with value -150.163880159 and 1 tape(s)
loss is -125.318653562
Iteration 76 lower bound 33.068637326
loss is Autograd FloatNode with value -122.908913974 and 1 tape(s)
loss is -126.143355653
Iteration 77 lower bound 32.9164503294
loss is Autograd FloatNode with value -141.271318606 and 1 tape(s)
loss is -135.152284684
Iteration 78 lower bound 40.8058819011
loss is Autograd FloatNode with value -136.000288409 and 1 tape(s)
loss is -138.323472699
Iteration 79 lower bound 42.7974325979
loss is Autograd FloatNode with value -136.673870467 and 1 tape(s)
loss is -136.550643822
Iteration 80 lower bound 39.7049173279
loss is Autograd FloatNode with value -117.262638446 and 1 tape(s)
loss is -134.093220433
Iteration 81 lower bound 35.838143782
loss is Autograd FloatNode with value -129.197009591 and 1 tape(s)
loss is -129.786004666
Iteration 82 lower bound 29.9202719453
loss is Autograd FloatNode with value -141.473906008 and 1 tape(s)
loss is -120.694242916
Iteration 83 lower bound 19.184103458
loss is Autograd FloatNode with value -151.820643205 and 1 tape(s)
loss is -115.083190013
Iteration 84 lower bound 11.944031611
loss is Autograd FloatNode with value -115.051802956 and 1 tape(s)
loss is -128.384258349
Iteration 85 lower bound 24.1257039662
loss is Autograd FloatNode with value -128.659904308 and 1 tape(s)
loss is -127.251540622
Iteration 86 lower bound 21.6081801696
loss is Autograd FloatNode with value -113.805704942 and 1 tape(s)
loss is -125.495483894
Iteration 87 lower bound 18.3459631966
loss is Autograd FloatNode with value -118.305278475 and 1 tape(s)
loss is -139.091751371
Iteration 88 lower bound 30.141293524
loss is Autograd FloatNode with value -121.60615479 and 1 tape(s)
loss is -111.181454408
Iteration 89 lower bound 0.236434945181
loss is Autograd FloatNode with value -115.672170779 and 1 tape(s)
loss is -119.476301853
Iteration 90 lower bound 6.53686371384
loss is Autograd FloatNode with value -147.225666624 and 1 tape(s)
loss is -110.799089647
Iteration 91 lower bound -4.13122928508
loss is Autograd FloatNode with value -127.728711219 and 1 tape(s)
loss is -116.980397375
Iteration 92 lower bound 0.637927502159
loss is Autograd FloatNode with value -145.839568096 and 1 tape(s)
loss is -118.181015515
Iteration 93 lower bound 0.670671967961
loss is Autograd FloatNode with value -141.80000348 and 1 tape(s)
loss is -133.109615062
Iteration 94 lower bound 15.0297485336
loss is Autograd FloatNode with value -148.550950288 and 1 tape(s)
loss is -120.424646373
Iteration 95 lower bound 1.94350063568
loss is Autograd FloatNode with value -119.690865565 and 1 tape(s)
loss is -124.134817383
Iteration 96 lower bound 5.57891894105
loss is Autograd FloatNode with value -109.73715338 and 1 tape(s)
loss is -129.881040831
Iteration 97 lower bound 11.1450247362
loss is Autograd FloatNode with value -109.771556453 and 1 tape(s)
loss is -100.082401637
Iteration 98 lower bound -18.9101673353
loss is Autograd FloatNode with value -119.412657865 and 1 tape(s)
loss is -125.262779684
Iteration 99 lower bound 5.80037378661
loss is Autograd FloatNode with value -153.200890028 and 1 tape(s)
loss is -114.992801488
Iteration 100 lower bound -5.15857109527
loss is Autograd FloatNode with value -107.676896135 and 1 tape(s)
loss is -122.665185238
Iteration 101 lower bound 2.52994392187
loss is Autograd FloatNode with value -136.846904065 and 1 tape(s)
loss is -118.142679804
Iteration 102 lower bound -2.21105774916
loss is Autograd FloatNode with value -114.3675758 and 1 tape(s)
loss is -111.350689343
Iteration 103 lower bound -9.17220139714
loss is Autograd FloatNode with value -122.018042212 and 1 tape(s)
loss is -108.854961738
Iteration 104 lower bound -12.0951457957
loss is Autograd FloatNode with value -105.840777477 and 1 tape(s)
loss is -122.881600593
Iteration 105 lower bound 1.46487861127
loss is Autograd FloatNode with value -116.757086907 and 1 tape(s)
loss is -134.173705485
Iteration 106 lower bound 12.1848533908
loss is Autograd FloatNode with value -110.950865524 and 1 tape(s)
loss is -123.172727772
Iteration 107 lower bound 0.672040694807
loss is Autograd FloatNode with value -113.215747796 and 1 tape(s)
loss is -119.836658399
Iteration 108 lower bound -3.27451917875
loss is Autograd FloatNode with value -106.098449807 and 1 tape(s)
loss is -127.115688565
Iteration 109 lower bound 3.32745895361
loss is Autograd FloatNode with value -96.6682487595 and 1 tape(s)
loss is -133.756098265
Iteration 110 lower bound 9.18181522616
loss is Autograd FloatNode with value -103.623066542 and 1 tape(s)
loss is -109.837874426
Iteration 111 lower bound -15.7885734048
loss is Autograd FloatNode with value -103.682015931 and 1 tape(s)
loss is -104.352994736
Iteration 112 lower bound -22.5107410093
loss is Autograd FloatNode with value -113.271855408 and 1 tape(s)
loss is -100.353330425
Iteration 113 lower bound -27.9575916986
loss is Autograd FloatNode with value -138.781103314 and 1 tape(s)
loss is -101.515202564
Iteration 114 lower bound -28.0281882646
loss is Autograd FloatNode with value -108.188291904 and 1 tape(s)
loss is -96.0956349554
Iteration 115 lower bound -34.7240031542
loss is Autograd FloatNode with value -108.342628694 and 1 tape(s)
loss is -120.520488653
Iteration 116 lower bound -11.5301533797
loss is Autograd FloatNode with value -103.389749577 and 1 tape(s)
loss is -117.231811459
Iteration 117 lower bound -16.057942387
loss is Autograd FloatNode with value -97.098199965 and 1 tape(s)
loss is -112.400615806
Iteration 118 lower bound -22.2779943317
loss is Autograd FloatNode with value -92.9010379646 and 1 tape(s)
loss is -102.557771547
Iteration 119 lower bound -33.6908332837
loss is Autograd FloatNode with value -105.902084866 and 1 tape(s)
loss is -104.089294513
Iteration 120 lower bound -33.8340840423
loss is Autograd FloatNode with value -106.696734998 and 1 tape(s)
loss is -106.772561765
Iteration 121 lower bound -32.670476018
loss is Autograd FloatNode with value -98.3875951886 and 1 tape(s)
loss is -122.616347337
Iteration 122 lower bound -18.3147926321
loss is Autograd FloatNode with value -121.686835537 and 1 tape(s)
loss is -109.196876795
Iteration 123 lower bound -33.3074774923
loss is Autograd FloatNode with value -138.688475024 and 1 tape(s)
loss is -134.323219093
Iteration 124 lower bound -9.34333763858
loss is Autograd FloatNode with value -116.013437412 and 1 tape(s)
loss is -110.712307698
Iteration 125 lower bound -33.3673949945
loss is Autograd FloatNode with value -108.290291061 and 1 tape(s)
loss is -102.888917657
Iteration 126 lower bound -41.7525292193
loss is Autograd FloatNode with value -114.562820898 and 1 tape(s)
loss is -103.764744949
Iteration 127 lower bound -41.6746193684
loss is Autograd FloatNode with value -126.072746679 and 1 tape(s)
loss is -109.23519436
Iteration 128 lower bound -36.8556837828
loss is Autograd FloatNode with value -123.570427451 and 1 tape(s)
loss is -115.075694948
Iteration 129 lower bound -31.4706993979
loss is Autograd FloatNode with value -120.076876085 and 1 tape(s)
loss is -104.848811308
Iteration 130 lower bound -41.8704349107
loss is Autograd FloatNode with value -101.554323219 and 1 tape(s)
loss is -96.3216473923
Iteration 131 lower bound -50.3755950014
loss is Autograd FloatNode with value -91.6683471871 and 1 tape(s)
loss is -105.080511979
Iteration 132 lower bound -41.7037056399
loss is Autograd FloatNode with value -98.1213992198 and 1 tape(s)
loss is -103.276643551
Iteration 133 lower bound -43.9660192837
loss is Autograd FloatNode with value -97.2272000487 and 1 tape(s)
loss is -100.631077745
Iteration 134 lower bound -47.3795353535
loss is Autograd FloatNode with value -96.004614931 and 1 tape(s)
loss is -104.540245819
Iteration 135 lower bound -44.4893709425
loss is Autograd FloatNode with value -99.2851153109 and 1 tape(s)
loss is -110.04984427
Iteration 136 lower bound -40.1327001793
loss is Autograd FloatNode with value -117.18551881 and 1 tape(s)
loss is -106.253651394
Iteration 137 lower bound -45.2150375362
loss is Autograd FloatNode with value -93.434146462 and 1 tape(s)
loss is -101.495962081
Iteration 138 lower bound -51.043661637
loss is Autograd FloatNode with value -112.015206409 and 1 tape(s)
loss is -108.77073389
Iteration 139 lower bound -45.0005038409
loss is Autograd FloatNode with value -114.653410736 and 1 tape(s)
loss is -106.014494177
Iteration 140 lower bound -48.9802408835
loss is Autograd FloatNode with value -131.97339874 and 1 tape(s)
loss is -110.9819169
Iteration 141 lower bound -45.1604183855
loss is Autograd FloatNode with value -105.978077577 and 1 tape(s)
loss is -105.006130106
Iteration 142 lower bound -52.1197494967
loss is Autograd FloatNode with value -107.469995836 and 1 tape(s)
loss is -109.849424529
Iteration 143 lower bound -48.308365473
loss is Autograd FloatNode with value -101.18996316 and 1 tape(s)
loss is -110.706397796
Iteration 144 lower bound -48.4673179593
loss is Autograd FloatNode with value -117.738639759 and 1 tape(s)
loss is -111.966485014
Iteration 145 lower bound -48.3172215711
loss is Autograd FloatNode with value -111.106798189 and 1 tape(s)
loss is -107.005346408
Iteration 146 lower bound -54.337440153
loss is Autograd FloatNode with value -109.924961905 and 1 tape(s)
loss is -106.299789849
Iteration 147 lower bound -55.9806626672
loss is Autograd FloatNode with value -114.10723993 and 1 tape(s)
loss is -108.24762775
Iteration 148 lower bound -54.8939794023
loss is Autograd FloatNode with value -110.180706619 and 1 tape(s)
loss is -110.974830794
Iteration 149 lower bound -53.1283437024
loss is Autograd FloatNode with value -109.486479191 and 1 tape(s)
loss is -128.494263999
Iteration 150 lower bound -36.76552838
loss is Autograd FloatNode with value -100.448560919 and 1 tape(s)
loss is -103.520719109
Iteration 151 lower bound -62.9640598018
loss is Autograd FloatNode with value -108.256710255 and 1 tape(s)
loss is -116.577950129
Iteration 152 lower bound -51.2251061412
loss is Autograd FloatNode with value -106.781704009 and 1 tape(s)
loss is -116.980478691
Iteration 153 lower bound -52.059863633
loss is Autograd FloatNode with value -116.92673876 and 1 tape(s)
loss is -121.20555973
Iteration 154 lower bound -49.1268118206
loss is Autograd FloatNode with value -106.715275368 and 1 tape(s)
loss is -113.954278613
Iteration 155 lower bound -57.4516882714
loss is Autograd FloatNode with value -122.037749772 and 1 tape(s)
loss is -125.830694677
Iteration 156 lower bound -46.5222487028
loss is Autograd FloatNode with value -125.967304324 and 1 tape(s)
loss is -117.23540631
Iteration 157 lower bound -55.9481095433
loss is Autograd FloatNode with value -128.76677836 and 1 tape(s)
loss is -112.270695473
Iteration 158 lower bound -61.3444947255
loss is Autograd FloatNode with value -121.126995702 and 1 tape(s)
loss is -112.778945406
Iteration 159 lower bound -61.3223869839
loss is Autograd FloatNode with value -114.953203124 and 1 tape(s)
loss is -116.709937163
Iteration 160 lower bound -57.9095354838
loss is Autograd FloatNode with value -108.761929622 and 1 tape(s)
loss is -114.689200266
Iteration 161 lower bound -60.2864085815
loss is Autograd FloatNode with value -141.743305583 and 1 tape(s)
loss is -136.045764461
Iteration 162 lower bound -39.3227436103
loss is Autograd FloatNode with value -107.452872659 and 1 tape(s)
loss is -115.893866066
Iteration 163 lower bound -59.4734762866
loss is Autograd FloatNode with value -117.063371251 and 1 tape(s)
loss is -122.407417024
Iteration 164 lower bound -53.0859338874
loss is Autograd FloatNode with value -109.406234254 and 1 tape(s)
loss is -125.324973945
Iteration 165 lower bound -50.2014863814
loss is Autograd FloatNode with value -115.790825152 and 1 tape(s)
loss is -119.179857392
Iteration 166 lower bound -56.6578528433
loss is Autograd FloatNode with value -120.514694117 and 1 tape(s)
loss is -112.699575916
Iteration 167 lower bound -63.5970053096
loss is Autograd FloatNode with value -103.117404349 and 1 tape(s)
loss is -104.722238461
Iteration 168 lower bound -71.8512334993
loss is Autograd FloatNode with value -130.414248974 and 1 tape(s)
loss is -108.282138556
Iteration 169 lower bound -68.7198581731
loss is Autograd FloatNode with value -112.731699916 and 1 tape(s)
loss is -121.43847035
Iteration 170 lower bound -55.5408874134
loss is Autograd FloatNode with value -112.130457965 and 1 tape(s)
loss is -97.8805187372
Iteration 171 lower bound -79.1518909295
loss is Autograd FloatNode with value -120.283958423 and 1 tape(s)
loss is -120.556747849
Iteration 172 lower bound -56.5004199506
loss is Autograd FloatNode with value -125.945589486 and 1 tape(s)
loss is -117.294070862
Iteration 173 lower bound -59.9126711737
loss is Autograd FloatNode with value -105.696876617 and 1 tape(s)
loss is -117.905023383
Iteration 174 lower bound -59.3788278352
loss is Autograd FloatNode with value -97.8247365451 and 1 tape(s)
loss is -100.145515179
Iteration 175 lower bound -77.4609636699
loss is Autograd FloatNode with value -104.272279967 and 1 tape(s)
loss is -106.32501728
Iteration 176 lower bound -71.8347877401
loss is Autograd FloatNode with value -121.385763132 and 1 tape(s)
loss is -101.37353687
Iteration 177 lower bound -77.4407107135
loss is Autograd FloatNode with value -118.531128426 and 1 tape(s)
loss is -115.347144396
Iteration 178 lower bound -64.0461134716
loss is Autograd FloatNode with value -102.143520117 and 1 tape(s)
loss is -96.3683018757
Iteration 179 lower bound -83.4196909708
loss is Autograd FloatNode with value -112.880411917 and 1 tape(s)
loss is -112.749180694
Iteration 180 lower bound -67.536096239
loss is Autograd FloatNode with value -143.96277226 and 1 tape(s)
loss is -130.735598156
Iteration 181 lower bound -50.0439663497
loss is Autograd FloatNode with value -122.125186939 and 1 tape(s)
loss is -116.875451041
Iteration 182 lower bound -64.3016457655
loss is Autograd FloatNode with value -111.533299111 and 1 tape(s)
loss is -100.732059062
Iteration 183 lower bound -80.813427511
loss is Autograd FloatNode with value -105.108735704 and 1 tape(s)
loss is -103.47001318
Iteration 184 lower bound -78.4690591741
loss is Autograd FloatNode with value -104.629230447 and 1 tape(s)
loss is -126.478028889
Iteration 185 lower bound -55.9891439606
loss is Autograd FloatNode with value -111.325187166 and 1 tape(s)
loss is -123.167897139
Iteration 186 lower bound -59.9901406516
loss is Autograd FloatNode with value -107.546317615 and 1 tape(s)
loss is -114.780940004
Iteration 187 lower bound -68.9996832181
loss is Autograd FloatNode with value -103.361089377 and 1 tape(s)
loss is -104.233678735
Iteration 188 lower bound -80.1284360547
loss is Autograd FloatNode with value -116.694046173 and 1 tape(s)
loss is -115.947449165
Iteration 189 lower bound -69.1466862255
loss is Autograd FloatNode with value -125.790367646 and 1 tape(s)
loss is -104.751315792
Iteration 190 lower bound -80.9897528972
loss is Autograd FloatNode with value -95.4277886656 and 1 tape(s)
loss is -108.700372009
Iteration 191 lower bound -77.8421839123
loss is Autograd FloatNode with value -104.795342234 and 1 tape(s)
loss is -112.848232655
Iteration 192 lower bound -74.7575908988
loss is Autograd FloatNode with value -109.864766977 and 1 tape(s)
loss is -103.051604868
Iteration 193 lower bound -85.7167394407
loss is Autograd FloatNode with value -107.301486264 and 1 tape(s)
loss is -109.476412403
Iteration 194 lower bound -80.3418143298
loss is Autograd FloatNode with value -104.167601299 and 1 tape(s)
loss is -125.075589536
Iteration 195 lower bound -65.8035067233
loss is Autograd FloatNode with value -138.22961097 and 1 tape(s)
loss is -107.496064518
Iteration 196 lower bound -84.4786015852
loss is Autograd FloatNode with value -101.16762226 and 1 tape(s)
loss is -106.361022216
Iteration 197 lower bound -86.1693558801
loss is Autograd FloatNode with value -108.553786061 and 1 tape(s)
loss is -94.6284824374
Iteration 198 lower bound -98.5675332008
loss is Autograd FloatNode with value -103.687987606 and 1 tape(s)
loss is -117.74399725
Iteration 199 lower bound -76.0340063064
loss is Autograd FloatNode with value -115.3011618 and 1 tape(s)
loss is -115.150897355
Iteration 200 lower bound -79.4543215307
loss is Autograd FloatNode with value -103.742381164 and 1 tape(s)
loss is -101.723342007
Iteration 201 lower bound -93.6953055748
loss is Autograd FloatNode with value -108.694754305 and 1 tape(s)
loss is -112.599090856
Iteration 202 lower bound -83.7406677305
loss is Autograd FloatNode with value -107.921527142 and 1 tape(s)
loss is -114.772789232
Iteration 203 lower bound -82.5545779319
loss is Autograd FloatNode with value -105.015394227 and 1 tape(s)
loss is -108.101639804
Iteration 204 lower bound -90.2425619888
loss is Autograd FloatNode with value -108.839944534 and 1 tape(s)
loss is -108.967804843
Iteration 205 lower bound -90.5118059012
loss is Autograd FloatNode with value -127.334999002 and 1 tape(s)
loss is -127.983381645
Iteration 206 lower bound -72.4943921128
loss is Autograd FloatNode with value -114.815174525 and 1 tape(s)
loss is -110.726667378
Iteration 207 lower bound -90.3230140265
loss is Autograd FloatNode with value -109.472045627 and 1 tape(s)
loss is -115.063558076
Iteration 208 lower bound -86.6867847426
loss is Autograd FloatNode with value -110.5620701 and 1 tape(s)
loss is -105.97881695
Iteration 209 lower bound -96.5609361041
loss is Autograd FloatNode with value -107.445610588 and 1 tape(s)
loss is -106.713747502
Iteration 210 lower bound -96.5238007042
loss is Autograd FloatNode with value -119.291704777 and 1 tape(s)
loss is -121.332523463
Iteration 211 lower bound -82.5926629111
loss is Autograd FloatNode with value -119.984522295 and 1 tape(s)
loss is -125.075102393
Iteration 212 lower bound -79.4411357734
loss is Autograd FloatNode with value -134.200194149 and 1 tape(s)
loss is -111.14606758
Iteration 213 lower bound -93.9824893414
loss is Autograd FloatNode with value -115.652880869 and 1 tape(s)
loss is -126.493926862
Iteration 214 lower bound -78.3944668849
loss is Autograd FloatNode with value -121.335608529 and 1 tape(s)
loss is -129.123827502
Iteration 215 lower bound -75.6138421679
loss is Autograd FloatNode with value -116.688081563 and 1 tape(s)
loss is -107.86268945
Iteration 216 lower bound -96.9683940587
loss is Autograd FloatNode with value -100.15969461 and 1 tape(s)
loss is -132.222503534
Iteration 217 lower bound -72.8694723179
loss is Autograd FloatNode with value -112.438602366 and 1 tape(s)
loss is -117.775929588
Iteration 218 lower bound -87.7798760487
loss is Autograd FloatNode with value -124.676790633 and 1 tape(s)
loss is -128.093081881
Iteration 219 lower bound -77.8887362416
loss is Autograd FloatNode with value -105.72460304 and 1 tape(s)
loss is -124.061608586
Iteration 220 lower bound -82.2181682274
loss is Autograd FloatNode with value -127.590213458 and 1 tape(s)
loss is -119.176102489
Iteration 221 lower bound -87.6259053317
loss is Autograd FloatNode with value -123.98026657 and 1 tape(s)
loss is -107.869147766
Iteration 222 lower bound -99.2274183136
loss is Autograd FloatNode with value -117.876989357 and 1 tape(s)
loss is -139.670878549
Iteration 223 lower bound -67.6542483656
loss is Autograd FloatNode with value -118.188093679 and 1 tape(s)
loss is -130.353744076
Iteration 224 lower bound -77.2302445889
loss is Autograd FloatNode with value -103.922763242 and 1 tape(s)
loss is -109.280893359
Iteration 225 lower bound -98.7760960182
loss is Autograd FloatNode with value -112.448849181 and 1 tape(s)
loss is -124.763651066
Iteration 226 lower bound -83.9661930864
loss is Autograd FloatNode with value -121.783947495 and 1 tape(s)
loss is -159.490506081
Iteration 227 lower bound -49.8818667418
loss is Autograd FloatNode with value -120.0208831 and 1 tape(s)
loss is -125.176354453
Iteration 228 lower bound -84.8308085443
loss is Autograd FloatNode with value -129.054535716 and 1 tape(s)
loss is -115.295975739
Iteration 229 lower bound -95.1757131394
loss is Autograd FloatNode with value -116.136394132 and 1 tape(s)
loss is -107.419427508
Iteration 230 lower bound -103.437224909
loss is Autograd FloatNode with value -116.618708796 and 1 tape(s)
loss is -116.351141611
Iteration 231 lower bound -94.9104590374
loss is Autograd FloatNode with value -113.313706231 and 1 tape(s)
loss is -113.339688839
Iteration 232 lower bound -98.1132221815
loss is Autograd FloatNode with value -114.977402985 and 1 tape(s)
loss is -114.345475706
Iteration 233 lower bound -97.3101311659
loss is Autograd FloatNode with value -141.119652544 and 1 tape(s)
loss is -128.913181947
Iteration 234 lower bound -83.0636359915
loss is Autograd FloatNode with value -121.555871777 and 1 tape(s)
loss is -108.419867005
Iteration 235 lower bound -103.629550217
loss is Autograd FloatNode with value -114.840550151 and 1 tape(s)
loss is -108.552789292
Iteration 236 lower bound -103.424186338
loss is Autograd FloatNode with value -113.032014677 and 1 tape(s)
loss is -107.338411404
Iteration 237 lower bound -104.585368949
loss is Autograd FloatNode with value -116.018144226 and 1 tape(s)
loss is -100.555467596
Iteration 238 lower bound -111.286558277
loss is Autograd FloatNode with value -105.296461198 and 1 tape(s)
loss is -106.656128099
Iteration 239 lower bound -105.178735578
loss is Autograd FloatNode with value -102.13854303 and 1 tape(s)
loss is -104.578578078
Iteration 240 lower bound -107.463822435
loss is Autograd FloatNode with value -111.258594697 and 1 tape(s)
loss is -105.356542216
Iteration 241 lower bound -107.07520884
loss is Autograd FloatNode with value -109.203039809 and 1 tape(s)
loss is -110.702459926
Iteration 242 lower bound -102.259862843
loss is Autograd FloatNode with value -104.762064094 and 1 tape(s)
loss is -114.052075377
Iteration 243 lower bound -99.4267986358
loss is Autograd FloatNode with value -113.986697702 and 1 tape(s)
loss is -126.770648381
Iteration 244 lower bound -87.236788028
loss is Autograd FloatNode with value -129.47677315 and 1 tape(s)
loss is -129.960539019
Iteration 245 lower bound -84.7583880209
loss is Autograd FloatNode with value -144.281525665 and 1 tape(s)
loss is -108.664986945
Iteration 246 lower bound -106.411947376
loss is Autograd FloatNode with value -105.7062636 and 1 tape(s)
loss is -109.849228417
Iteration 247 lower bound -104.739020951
loss is Autograd FloatNode with value -100.478681048 and 1 tape(s)
loss is -112.131518768
Iteration 248 lower bound -102.16889283
loss is Autograd FloatNode with value -100.181692865 and 1 tape(s)
loss is -110.592134993
Iteration 249 lower bound -103.713552753
loss is Autograd FloatNode with value -112.189550179 and 1 tape(s)
loss is -119.771486155
Iteration 250 lower bound -94.8292855691
loss is Autograd FloatNode with value -103.797114851 and 1 tape(s)
loss is -116.475838799
Iteration 251 lower bound -98.4780865482
loss is Autograd FloatNode with value -106.442628938 and 1 tape(s)
loss is -112.381176679
Iteration 252 lower bound -103.03074129
loss is Autograd FloatNode with value -107.707797037 and 1 tape(s)
loss is -107.989879946
Iteration 253 lower bound -107.950192695
loss is Autograd FloatNode with value -101.89012509 and 1 tape(s)
loss is -110.817065337
Iteration 254 lower bound -105.642329526
loss is Autograd FloatNode with value -115.626760848 and 1 tape(s)
loss is -104.763423143
Iteration 255 lower bound -112.322704467
loss is Autograd FloatNode with value -101.127432467 and 1 tape(s)
loss is -107.826752653
Iteration 256 lower bound -109.831778761
loss is Autograd FloatNode with value -109.075868622 and 1 tape(s)
loss is -107.550201285
Iteration 257 lower bound -110.891252575
loss is Autograd FloatNode with value -119.750402369 and 1 tape(s)
loss is -101.864062483
Iteration 258 lower bound -117.388890054
loss is Autograd FloatNode with value -112.309144943 and 1 tape(s)
loss is -103.774105193
Iteration 259 lower bound -116.079228871
loss is Autograd FloatNode with value -113.732718918 and 1 tape(s)
loss is -108.787223119
Iteration 260 lower bound -111.575955714
loss is Autograd FloatNode with value -127.332431167 and 1 tape(s)
loss is -111.939632952
Iteration 261 lower bound -108.911533893
loss is Autograd FloatNode with value -111.359165924 and 1 tape(s)
loss is -115.323016442
Iteration 262 lower bound -105.625350412
loss is Autograd FloatNode with value -110.700584215 and 1 tape(s)
loss is -108.104032353
Iteration 263 lower bound -113.003808359
loss is Autograd FloatNode with value -112.287078856 and 1 tape(s)
loss is -123.848500146
Iteration 264 lower bound -97.4653074244
loss is Autograd FloatNode with value -114.853528815 and 1 tape(s)
loss is -107.383785959
Iteration 265 lower bound -114.254178485
loss is Autograd FloatNode with value -115.576946466 and 1 tape(s)
loss is -121.4697818
Iteration 266 lower bound -100.49184986
loss is Autograd FloatNode with value -109.68097691 and 1 tape(s)
loss is -104.842955471
Iteration 267 lower bound -117.388573855
loss is Autograd FloatNode with value -122.435806237 and 1 tape(s)
loss is -113.98777022
Iteration 268 lower bound -108.508819961
loss is Autograd FloatNode with value -110.554776525 and 1 tape(s)
loss is -117.971297554
Iteration 269 lower bound -104.655566266
loss is Autograd FloatNode with value -104.45428964 and 1 tape(s)
loss is -113.310468265
Iteration 270 lower bound -109.358532035
loss is Autograd FloatNode with value -104.437513773 and 1 tape(s)
loss is -114.65231306
Iteration 271 lower bound -108.125611161
loss is Autograd FloatNode with value -125.725811249 and 1 tape(s)
loss is -110.963381768
Iteration 272 lower bound -111.978902741
loss is Autograd FloatNode with value -126.963966232 and 1 tape(s)
loss is -107.406114187
Iteration 273 lower bound -115.293445548
loss is Autograd FloatNode with value -109.905948672 and 1 tape(s)
loss is -105.100421475
Iteration 274 lower bound -117.0222931
loss is Autograd FloatNode with value -103.980294031 and 1 tape(s)
loss is -103.171277457
Iteration 275 lower bound -118.567448452
loss is Autograd FloatNode with value -116.202448583 and 1 tape(s)
loss is -105.437863654
Iteration 276 lower bound -116.00054436
loss is Autograd FloatNode with value -102.640753671 and 1 tape(s)
loss is -93.2246003148
Iteration 277 lower bound -127.971931432
loss is Autograd FloatNode with value -98.9953739172 and 1 tape(s)
loss is -104.508699185
Iteration 278 lower bound -116.538237482
loss is Autograd FloatNode with value -109.853193995 and 1 tape(s)
loss is -109.800203656
Iteration 279 lower bound -111.410206096
loss is Autograd FloatNode with value -112.440477497 and 1 tape(s)
loss is -114.359824821
Iteration 280 lower bound -107.080001329
loss is Autograd FloatNode with value -96.264090399 and 1 tape(s)
loss is -102.309382917
Iteration 281 lower bound -119.471123505
loss is Autograd FloatNode with value -110.122251873 and 1 tape(s)
loss is -101.514432422
Iteration 282 lower bound -120.85003459
loss is Autograd FloatNode with value -105.825167906 and 1 tape(s)
loss is -107.419246027
Iteration 283 lower bound -115.528041523
loss is Autograd FloatNode with value -103.677048908 and 1 tape(s)
loss is -101.727335197
Iteration 284 lower bound -121.79245527
loss is Autograd FloatNode with value -101.703771836 and 1 tape(s)
loss is -98.8419909365
Iteration 285 lower bound -125.372299647
loss is Autograd FloatNode with value -109.86374035 and 1 tape(s)
loss is -100.831909154
Iteration 286 lower bound -124.231840574
loss is Autograd FloatNode with value -101.163050162 and 1 tape(s)
loss is -110.409819929
Iteration 287 lower bound -115.569981505
loss is Autograd FloatNode with value -104.875556072 and 1 tape(s)
loss is -119.804399567
Iteration 288 lower bound -107.269809348
loss is Autograd FloatNode with value -100.910698252 and 1 tape(s)
loss is -110.79523694
Iteration 289 lower bound -117.261796883
loss is Autograd FloatNode with value -102.730905968 and 1 tape(s)
loss is -127.273664548
Iteration 290 lower bound -101.923370999
loss is Autograd FloatNode with value -104.455658373 and 1 tape(s)
loss is -106.002885205
Iteration 291 lower bound -124.331564299
loss is Autograd FloatNode with value -117.328338287 and 1 tape(s)
loss is -112.411014671
Iteration 292 lower bound -118.983360227
loss is Autograd FloatNode with value -107.109436314 and 1 tape(s)
loss is -148.104582761
Iteration 293 lower bound -83.9837552393
loss is Autograd FloatNode with value -116.687729588 and 1 tape(s)
loss is -115.550320374
Iteration 294 lower bound -117.058192984
loss is Autograd FloatNode with value -111.528236092 and 1 tape(s)
loss is -102.589506272
Iteration 295 lower bound -130.366179463
loss is Autograd FloatNode with value -105.580181954 and 1 tape(s)
loss is -104.897666506
Iteration 296 lower bound -128.457271972
loss is Autograd FloatNode with value -103.04105336 and 1 tape(s)
loss is -109.527819439
Iteration 297 lower bound -124.391353196
loss is Autograd FloatNode with value -113.795532115 and 1 tape(s)
loss is -107.201919926
Iteration 298 lower bound -127.345980341
loss is Autograd FloatNode with value -109.55513744 and 1 tape(s)
loss is -104.598360182
Iteration 299 lower bound -130.49396151
loss is Autograd FloatNode with value -108.113525452 and 1 tape(s)
loss is -106.60877366
Iteration 300 lower bound -129.007748675
loss is Autograd FloatNode with value -111.104266274 and 1 tape(s)
loss is -110.337546672
Iteration 301 lower bound -125.779576165
loss is Autograd FloatNode with value -118.254776471 and 1 tape(s)
loss is -103.860651493
Iteration 302 lower bound -132.71118735
loss is Autograd FloatNode with value -112.115162811 and 1 tape(s)
loss is -100.305254198
Iteration 303 lower bound -136.511963333
loss is Autograd FloatNode with value -108.475799873 and 1 tape(s)
loss is -131.339105309
Iteration 304 lower bound -105.587405141
loss is Autograd FloatNode with value -103.846617376 and 1 tape(s)
loss is -106.372300525
Iteration 305 lower bound -130.750394287
loss is Autograd FloatNode with value -112.966462421 and 1 tape(s)
loss is -115.969452068
Iteration 306 lower bound -121.463174927
loss is Autograd FloatNode with value -104.8763055 and 1 tape(s)
loss is -112.027316435
Iteration 307 lower bound -125.733437603
loss is Autograd FloatNode with value -109.191731098 and 1 tape(s)
loss is -111.253072876
Iteration 308 lower bound -126.872120572
loss is Autograd FloatNode with value -107.922340024 and 1 tape(s)
loss is -112.627095012
Iteration 309 lower bound -125.910476312
loss is Autograd FloatNode with value -116.195809399 and 1 tape(s)
loss is -108.492780124
Iteration 310 lower bound -130.354309148
loss is Autograd FloatNode with value -112.122793294 and 1 tape(s)
loss is -108.115887218
Iteration 311 lower bound -131.046723603
loss is Autograd FloatNode with value -107.008794584 and 1 tape(s)
loss is -116.700271443
Iteration 312 lower bound -122.581389382
loss is Autograd FloatNode with value -123.886624754 and 1 tape(s)
loss is -121.387794363
Iteration 313 lower bound -118.194128057
loss is Autograd FloatNode with value -131.683572168 and 1 tape(s)
loss is -132.111279911
Iteration 314 lower bound -107.745285406
loss is Autograd FloatNode with value -99.4824967683 and 1 tape(s)
loss is -116.647907616
Iteration 315 lower bound -122.818229067
loss is Autograd FloatNode with value -116.88697363 and 1 tape(s)
loss is -120.197057477
Iteration 316 lower bound -119.091658812
loss is Autograd FloatNode with value -113.934902274 and 1 tape(s)
loss is -121.58040985
Iteration 317 lower bound -117.551997343
loss is Autograd FloatNode with value -110.67787261 and 1 tape(s)
loss is -110.691753662
Iteration 318 lower bound -128.451442098
loss is Autograd FloatNode with value -113.706491295 and 1 tape(s)
loss is -105.144387697
Iteration 319 lower bound -133.995338079
loss is Autograd FloatNode with value -116.865969492 and 1 tape(s)
loss is -120.321001566
Iteration 320 lower bound -118.774904427
loss is Autograd FloatNode with value -117.59921395 and 1 tape(s)
loss is -120.482154102
Iteration 321 lower bound -118.672131473
loss is Autograd FloatNode with value -101.337831365 and 1 tape(s)
loss is -100.647265694
Iteration 322 lower bound -138.681926451
loss is Autograd FloatNode with value -109.078259783 and 1 tape(s)
loss is -110.119294305
Iteration 323 lower bound -129.60002108
loss is Autograd FloatNode with value -106.910882377 and 1 tape(s)
loss is -110.460359348
Iteration 324 lower bound -129.712563439
loss is Autograd FloatNode with value -106.775153959 and 1 tape(s)
loss is -107.431871473
Iteration 325 lower bound -133.365010129
loss is Autograd FloatNode with value -107.861361852 and 1 tape(s)
loss is -113.46874273
Iteration 326 lower bound -128.083233434
loss is Autograd FloatNode with value -107.013859903 and 1 tape(s)
loss is -107.978409005
Iteration 327 lower bound -134.411561788
loss is Autograd FloatNode with value -117.173499338 and 1 tape(s)
loss is -113.850960748
Iteration 328 lower bound -129.510257373
loss is Autograd FloatNode with value -110.95317104 and 1 tape(s)
loss is -116.094554746
Iteration 329 lower bound -128.29284486
loss is Autograd FloatNode with value -123.204436067 and 1 tape(s)
loss is -107.905796794
Iteration 330 lower bound -137.518837671
loss is Autograd FloatNode with value -119.321380367 and 1 tape(s)
loss is -134.128672738
Iteration 331 lower bound -111.93337419
loss is Autograd FloatNode with value -114.139509038 and 1 tape(s)
loss is -113.703862567
Iteration 332 lower bound -133.048414252
loss is Autograd FloatNode with value -120.033478686 and 1 tape(s)
loss is -126.090933736
Iteration 333 lower bound -121.399142706
loss is Autograd FloatNode with value -115.401966156 and 1 tape(s)
loss is -103.530602852
Iteration 334 lower bound -144.759817178
loss is Autograd FloatNode with value -111.388436308 and 1 tape(s)
loss is -113.636800797
Iteration 335 lower bound -135.384862152
loss is Autograd FloatNode with value -116.198661571 and 1 tape(s)
loss is -116.022860014
Iteration 336 lower bound -133.676568301
loss is Autograd FloatNode with value -132.186797956 and 1 tape(s)
loss is -99.8644084114
Iteration 337 lower bound -150.040325958
loss is Autograd FloatNode with value -119.814984749 and 1 tape(s)
loss is -110.030370959
Iteration 338 lower bound -139.517576612
loss is Autograd FloatNode with value -111.819015973 and 1 tape(s)
loss is -104.616921309
Iteration 339 lower bound -144.59695684
loss is Autograd FloatNode with value -115.870647254 and 1 tape(s)
loss is -111.178030392
Iteration 340 lower bound -137.756964207
loss is Autograd FloatNode with value -110.217727873 and 1 tape(s)
loss is -125.398977692
Iteration 341 lower bound -123.187394925
loss is Autograd FloatNode with value -114.099036146 and 1 tape(s)
loss is -113.913041726
Iteration 342 lower bound -134.543661133
loss is Autograd FloatNode with value -105.656718134 and 1 tape(s)
loss is -117.235080582
Iteration 343 lower bound -131.220564403
loss is Autograd FloatNode with value -108.780181481 and 1 tape(s)
loss is -108.12841074
Iteration 344 lower bound -140.416548878
loss is Autograd FloatNode with value -118.041429939 and 1 tape(s)
loss is -117.453859936
Iteration 345 lower bound -131.1838989
loss is Autograd FloatNode with value -114.53620353 and 1 tape(s)
loss is -105.887750745
Iteration 346 lower bound -142.849922284
loss is Autograd FloatNode with value -109.857620979 and 1 tape(s)
loss is -112.970522739
Iteration 347 lower bound -135.853399672
loss is Autograd FloatNode with value -101.829276795 and 1 tape(s)
loss is -111.785917869
Iteration 348 lower bound -137.086488429
loss is Autograd FloatNode with value -112.520082226 and 1 tape(s)
loss is -104.773925474
Iteration 349 lower bound -144.250484357
loss is Autograd FloatNode with value -97.4664460875 and 1 tape(s)
loss is -107.407476956
Iteration 350 lower bound -141.727636329
loss is Autograd FloatNode with value -115.151941446 and 1 tape(s)
loss is -111.440115107
Iteration 351 lower bound -138.011555606
loss is Autograd FloatNode with value -118.463048662 and 1 tape(s)
loss is -108.030253477
Iteration 352 lower bound -141.638749348
loss is Autograd FloatNode with value -113.752581418 and 1 tape(s)
loss is -106.288829673
Iteration 353 lower bound -143.503986061
loss is Autograd FloatNode with value -120.938946921 and 1 tape(s)
loss is -129.810387314
Iteration 354 lower bound -119.819763122
loss is Autograd FloatNode with value -212.575037377 and 1 tape(s)
loss is -106.714683747
Iteration 355 lower bound -142.747889596
loss is Autograd FloatNode with value -112.187256731 and 1 tape(s)
loss is -101.42246218
Iteration 356 lower bound -148.437830338
loss is Autograd FloatNode with value -103.576071416 and 1 tape(s)
loss is -106.360992871
Iteration 357 lower bound -143.806103758
loss is Autograd FloatNode with value -105.574692937 and 1 tape(s)
loss is -109.810021207
Iteration 358 lower bound -140.741411451
loss is Autograd FloatNode with value -140.157464737 and 1 tape(s)
loss is -116.280996153
Iteration 359 lower bound -134.66391013
loss is Autograd FloatNode with value -108.486452621 and 1 tape(s)
loss is -104.884150682
Iteration 360 lower bound -146.852604195
loss is Autograd FloatNode with value -130.675039591 and 1 tape(s)
loss is -243.973000002
Iteration 361 lower bound -8.45371535856
loss is Autograd FloatNode with value -170.042120555 and 1 tape(s)
loss is -139.531464291
Iteration 362 lower bound -113.023870504
loss is Autograd FloatNode with value -147.02000572 and 1 tape(s)
loss is -139.558095416
Iteration 363 lower bound -112.934800024
loss is Autograd FloatNode with value -119.9510469 and 1 tape(s)
loss is -103.486235677
Iteration 364 lower bound -148.955170086
loss is Autograd FloatNode with value -123.112522128 and 1 tape(s)
loss is -173.4705485
Iteration 365 lower bound -78.6416519
loss is Autograd FloatNode with value -111.827011869 and 1 tape(s)
loss is -128.403072352
Iteration 366 lower bound -123.112356096
loss is Autograd FloatNode with value -107.198153472 and 1 tape(s)
loss is -130.572149554
Iteration 367 lower bound -120.470377024
loss is Autograd FloatNode with value -101.556270108 and 1 tape(s)
loss is -105.960613508
Iteration 368 lower bound -144.808594334
loss is Autograd FloatNode with value -106.401179493 and 1 tape(s)
loss is -113.540572382
Iteration 369 lower bound -137.185083942
loss is Autograd FloatNode with value -114.151352881 and 1 tape(s)
loss is -109.110641501
Iteration 370 lower bound -141.610594139
loss is Autograd FloatNode with value -106.887162101 and 1 tape(s)
loss is -112.997319861
Iteration 371 lower bound -137.763786639
loss is Autograd FloatNode with value -131.108258228 and 1 tape(s)
loss is -119.246505089
Iteration 372 lower bound -131.491077518
loss is Autograd FloatNode with value -112.779022478 and 1 tape(s)
loss is -107.202358535
Iteration 373 lower bound -142.808513321
loss is Autograd FloatNode with value -111.416221693 and 1 tape(s)
loss is -103.777515329
Iteration 374 lower bound -145.454504247
loss is Autograd FloatNode with value -98.6588870406 and 1 tape(s)
loss is -96.8364783565
Iteration 375 lower bound -151.664349875
loss is Autograd FloatNode with value -112.573416469 and 1 tape(s)
loss is -110.87086961
Iteration 376 lower bound -137.131995802
loss is Autograd FloatNode with value -113.673529525 and 1 tape(s)
loss is -104.624486902
Iteration 377 lower bound -142.953625264
loss is Autograd FloatNode with value -101.845955361 and 1 tape(s)
loss is -107.182996534
Iteration 378 lower bound -140.079443612
loss is Autograd FloatNode with value -112.621317791 and 1 tape(s)
loss is -112.491567028
Iteration 379 lower bound -134.650651285
loss is Autograd FloatNode with value -127.25415771 and 1 tape(s)
loss is -111.636013161
Iteration 380 lower bound -135.470052256
loss is Autograd FloatNode with value -107.837340382 and 1 tape(s)
loss is -130.523444818
Iteration 381 lower bound -116.665228597
loss is Autograd FloatNode with value -106.559819297 and 1 tape(s)
loss is -113.615676958
Iteration 382 lower bound -133.577908585
loss is Autograd FloatNode with value -119.026114343 and 1 tape(s)
loss is -108.654996386
Iteration 383 lower bound -138.483088975
loss is Autograd FloatNode with value -115.468723288 and 1 tape(s)
loss is -108.878879358
Iteration 384 lower bound -138.066246618
loss is Autograd FloatNode with value -109.270945242 and 1 tape(s)
loss is -106.050142323
Iteration 385 lower bound -140.605923262
loss is Autograd FloatNode with value -118.220114474 and 1 tape(s)
loss is -105.537789125
Iteration 386 lower bound -141.050895119
loss is Autograd FloatNode with value -120.598675416 and 1 tape(s)
loss is -102.983949717
Iteration 387 lower bound -143.613383402
loss is Autograd FloatNode with value -116.095637534 and 1 tape(s)
loss is -110.165608508
Iteration 388 lower bound -136.328934035
loss is Autograd FloatNode with value -100.372453329 and 1 tape(s)
loss is -103.609159749
Iteration 389 lower bound -142.784020726
loss is Autograd FloatNode with value -104.184624256 and 1 tape(s)
loss is -111.088015593
Iteration 390 lower bound -135.408650799
loss is Autograd FloatNode with value -106.063486981 and 1 tape(s)
loss is -114.633426628
Iteration 391 lower bound -132.200137645
loss is Autograd FloatNode with value -104.448868796 and 1 tape(s)
loss is -108.199331084
Iteration 392 lower bound -138.981002926
loss is Autograd FloatNode with value -114.931381897 and 1 tape(s)
loss is -109.543830148
Iteration 393 lower bound -138.062326885
loss is Autograd FloatNode with value -123.035577748 and 1 tape(s)
loss is -105.766648528
Iteration 394 lower bound -142.19819088
loss is Autograd FloatNode with value -109.090883098 and 1 tape(s)
loss is -101.482828708
Iteration 395 lower bound -146.534610327
loss is Autograd FloatNode with value -106.409435232 and 1 tape(s)
loss is -107.887003407
Iteration 396 lower bound -140.092167186
loss is Autograd FloatNode with value -107.996045785 and 1 tape(s)
loss is -120.748985549
Iteration 397 lower bound -127.322195881
loss is Autograd FloatNode with value -94.2557134996 and 1 tape(s)
loss is -108.975452754
Iteration 398 lower bound -139.268635242
loss is Autograd FloatNode with value -119.019387387 and 1 tape(s)
loss is -106.771421637
Iteration 399 lower bound -141.898806884
loss is Autograd FloatNode with value -107.873155468 and 1 tape(s)
loss is -112.08692115
Iteration 400 lower bound -136.799744711
loss is Autograd FloatNode with value -104.890916543 and 1 tape(s)
loss is -105.69280119
Iteration 401 lower bound -143.502291464
loss is Autograd FloatNode with value -109.181734515 and 1 tape(s)
loss is -110.057554894
Iteration 402 lower bound -139.525903363
loss is Autograd FloatNode with value -107.741109946 and 1 tape(s)
loss is -105.123432154
Iteration 403 lower bound -144.862927039
loss is Autograd FloatNode with value -108.187111034 and 1 tape(s)
loss is -106.674715451
Iteration 404 lower bound -143.830306545
loss is Autograd FloatNode with value -101.681279279 and 1 tape(s)
loss is -110.892909849
Iteration 405 lower bound -140.081450626
loss is Autograd FloatNode with value -107.576305844 and 1 tape(s)
loss is -106.409220259
Iteration 406 lower bound -145.108988714
loss is Autograd FloatNode with value -110.330687323 and 1 tape(s)
loss is -114.096182994
Iteration 407 lower bound -138.02124147
loss is Autograd FloatNode with value -117.467362896 and 1 tape(s)
loss is -95.629866287
Iteration 408 lower bound -157.129371896
loss is Autograd FloatNode with value -106.407191772 and 1 tape(s)
loss is -103.394857894
Iteration 409 lower bound -149.655135024
loss is Autograd FloatNode with value -124.015212347 and 1 tape(s)
loss is -111.29933116
Iteration 410 lower bound -142.0802037
loss is Autograd FloatNode with value -99.6798090533 and 1 tape(s)
loss is -101.881150381
Iteration 411 lower bound -151.686464559
loss is Autograd FloatNode with value -119.352732623 and 1 tape(s)
loss is -105.550105698
Iteration 412 lower bound -148.351094918
loss is Autograd FloatNode with value -103.470966491 and 1 tape(s)
loss is -106.488300928
Iteration 413 lower bound -147.631717056
loss is Autograd FloatNode with value -104.903781636 and 1 tape(s)
loss is -103.049683988
Iteration 414 lower bound -151.373102628
loss is Autograd FloatNode with value -104.489336347 and 1 tape(s)
loss is -106.894835161
Iteration 415 lower bound -147.778349097
loss is Autograd FloatNode with value -103.523973716 and 1 tape(s)
loss is -103.55000881
Iteration 416 lower bound -151.519715771
loss is Autograd FloatNode with value -125.256927799 and 1 tape(s)
loss is -116.748447891
Iteration 417 lower bound -138.789587736
loss is Autograd FloatNode with value -117.397655795 and 1 tape(s)
loss is -111.080039464
Iteration 418 lower bound -144.616978511
loss is Autograd FloatNode with value -115.379762324 and 1 tape(s)
loss is -122.900521346
Iteration 419 lower bound -132.857783162
loss is Autograd FloatNode with value -111.638398085 and 1 tape(s)
loss is -112.486709507
Iteration 420 lower bound -143.277196307
loss is Autograd FloatNode with value -104.456521461 and 1 tape(s)
loss is -106.243374774
Iteration 421 lower bound -149.614984931
loss is Autograd FloatNode with value -105.151156752 and 1 tape(s)
loss is -104.91378825
Iteration 422 lower bound -151.128954978
loss is Autograd FloatNode with value -111.083958238 and 1 tape(s)
loss is -113.087417252
Iteration 423 lower bound -143.187168078
loss is Autograd FloatNode with value -112.15516367 and 1 tape(s)
loss is -102.967208018
Iteration 424 lower bound -153.66932155
loss is Autograd FloatNode with value -108.57429395 and 1 tape(s)
loss is -109.315601607
Iteration 425 lower bound -147.70774509
loss is Autograd FloatNode with value -109.267000699 and 1 tape(s)
loss is -110.920061974
Iteration 426 lower bound -146.436082941
loss is Autograd FloatNode with value -113.100963327 and 1 tape(s)
loss is -111.997576699
Iteration 427 lower bound -145.69974729
loss is Autograd FloatNode with value -100.578929649 and 1 tape(s)
loss is -114.326878131
Iteration 428 lower bound -143.619857001
loss is Autograd FloatNode with value -105.557840142 and 1 tape(s)
loss is -105.197981948
Iteration 429 lower bound -153.098176439
loss is Autograd FloatNode with value -110.371976766 and 1 tape(s)
loss is -110.90096015
Iteration 430 lower bound -147.833958727
loss is Autograd FloatNode with value -108.502477098 and 1 tape(s)
loss is -115.618447046
Iteration 431 lower bound -143.626200551
loss is Autograd FloatNode with value -141.767809118 and 1 tape(s)
loss is -105.239555077
Iteration 432 lower bound -154.477869762
loss is Autograd FloatNode with value -105.416784658 and 1 tape(s)
loss is -106.02050954
Iteration 433 lower bound -153.430965794
loss is Autograd FloatNode with value -112.900378401 and 1 tape(s)
loss is -108.299755406
Iteration 434 lower bound -150.957264487
loss is Autograd FloatNode with value -105.643923872 and 1 tape(s)
loss is -111.404559785
Iteration 435 lower bound -147.655000625
loss is Autograd FloatNode with value -112.845693077 and 1 tape(s)
loss is -110.095902141
Iteration 436 lower bound -148.893369905
loss is Autograd FloatNode with value -110.036847629 and 1 tape(s)
loss is -101.9580317
Iteration 437 lower bound -157.08790441
loss is Autograd FloatNode with value -107.14279567 and 1 tape(s)
loss is -110.536528585
Iteration 438 lower bound -148.578369783
loss is Autograd FloatNode with value -106.420023216 and 1 tape(s)
loss is -124.7976351
Iteration 439 lower bound -134.410404487
loss is Autograd FloatNode with value -117.899481307 and 1 tape(s)
loss is -121.384684282
Iteration 440 lower bound -137.932942427
loss is Autograd FloatNode with value -105.81007876 and 1 tape(s)
loss is -115.87776802
Iteration 441 lower bound -143.449541487
loss is Autograd FloatNode with value -103.598024335 and 1 tape(s)
loss is -112.199492247
Iteration 442 lower bound -147.129461662
loss is Autograd FloatNode with value -110.642862628 and 1 tape(s)
loss is -121.8629062
Iteration 443 lower bound -137.670215727
loss is Autograd FloatNode with value -105.118507365 and 1 tape(s)
loss is -104.035220078
Iteration 444 lower bound -155.703426565
loss is Autograd FloatNode with value -111.263376527 and 1 tape(s)
loss is -122.354053328
Iteration 445 lower bound -137.625989518
loss is Autograd FloatNode with value -115.050844658 and 1 tape(s)
loss is -121.408523114
Iteration 446 lower bound -138.809725888
loss is Autograd FloatNode with value -103.327047834 and 1 tape(s)
loss is -99.9410404414
Iteration 447 lower bound -160.445151696
loss is Autograd FloatNode with value -107.858012475 and 1 tape(s)
loss is -106.719510686
Iteration 448 lower bound -153.94669638
loss is Autograd FloatNode with value -124.391414941 and 1 tape(s)
loss is -118.043901625
Iteration 449 lower bound -142.92044693
loss is Autograd FloatNode with value -104.191052928 and 1 tape(s)
loss is -111.285647303
Iteration 450 lower bound -149.792918406
loss is Autograd FloatNode with value -106.594702501 and 1 tape(s)
loss is -106.329972292
Iteration 451 lower bound -154.943206006
loss is Autograd FloatNode with value -103.62429243 and 1 tape(s)
loss is -102.034551842
Iteration 452 lower bound -159.44907865
loss is Autograd FloatNode with value -99.6281200848 and 1 tape(s)
loss is -107.589312022
Iteration 453 lower bound -154.198365532
loss is Autograd FloatNode with value -100.19841517 and 1 tape(s)
loss is -112.988489734
Iteration 454 lower bound -149.219836006
loss is Autograd FloatNode with value -109.156557786 and 1 tape(s)
loss is -99.053982515
Iteration 455 lower bound -163.759884069
loss is Autograd FloatNode with value -115.057356981 and 1 tape(s)
loss is -98.7158893294
Iteration 456 lower bound -164.591174544
loss is Autograd FloatNode with value -117.82782354 and 1 tape(s)
loss is -111.364534419
Iteration 457 lower bound -152.098373502
loss is Autograd FloatNode with value -104.865183133 and 1 tape(s)
loss is -122.542322105
Iteration 458 lower bound -140.79207559
loss is Autograd FloatNode with value -108.249756216 and 1 tape(s)
loss is -115.316915501
Iteration 459 lower bound -147.924465663
loss is Autograd FloatNode with value -107.338237136 and 1 tape(s)
loss is -104.45101336
Iteration 460 lower bound -158.75829011
loss is Autograd FloatNode with value -98.1399965314 and 1 tape(s)
loss is -102.207194696
Iteration 461 lower bound -161.042094224
loss is Autograd FloatNode with value -108.00051126 and 1 tape(s)
loss is -106.666816912
Iteration 462 lower bound -156.753910811
loss is Autograd FloatNode with value -104.674646595 and 1 tape(s)
loss is -135.06711003
Iteration 463 lower bound -128.64023364
loss is Autograd FloatNode with value -111.83710457 and 1 tape(s)
loss is -117.421891244
Iteration 464 lower bound -146.679226986
loss is Autograd FloatNode with value -108.882675653 and 1 tape(s)
loss is -103.260265048
Iteration 465 lower bound -161.065376749
loss is Autograd FloatNode with value -101.716897486 and 1 tape(s)
loss is -112.027955743
Iteration 466 lower bound -152.51499144
loss is Autograd FloatNode with value -96.2948059646 and 1 tape(s)
loss is -113.472186593
Iteration 467 lower bound -151.481195565
loss is Autograd FloatNode with value -103.219828145 and 1 tape(s)
loss is -109.585757518
Iteration 468 lower bound -156.003984053
loss is Autograd FloatNode with value -101.693634599 and 1 tape(s)
loss is -112.78837397
Iteration 469 lower bound -153.53635114
loss is Autograd FloatNode with value -122.605203315 and 1 tape(s)
loss is -107.364743361
Iteration 470 lower bound -159.790238761
loss is Autograd FloatNode with value -116.951429139 and 1 tape(s)
loss is -126.029092364
Iteration 471 lower bound -141.614600023
loss is Autograd FloatNode with value -113.317869158 and 1 tape(s)
loss is -108.916481065
Iteration 472 lower bound -159.127967606
loss is Autograd FloatNode with value -114.097277563 and 1 tape(s)
loss is -104.284955831
Iteration 473 lower bound -163.976204736
loss is Autograd FloatNode with value -109.614735334 and 1 tape(s)
loss is -105.675165824
Iteration 474 lower bound -162.715488898
loss is Autograd FloatNode with value -113.144391307 and 1 tape(s)
loss is -138.807857807
Iteration 475 lower bound -129.709915221
loss is Autograd FloatNode with value -108.903810201 and 1 tape(s)
loss is -104.975860565
Iteration 476 lower bound -163.735718435
loss is Autograd FloatNode with value -105.479081843 and 1 tape(s)
loss is -108.035896865
Iteration 477 lower bound -160.911900177
loss is Autograd FloatNode with value -131.620202852 and 1 tape(s)
loss is -127.613326949
Iteration 478 lower bound -141.563393793
loss is Autograd FloatNode with value -100.083491858 and 1 tape(s)
loss is -110.500726579
Iteration 479 lower bound -158.612014345
loss is Autograd FloatNode with value -110.934928987 and 1 tape(s)
loss is -109.981297543
Iteration 480 lower bound -159.160890083
loss is Autograd FloatNode with value -108.389792293 and 1 tape(s)
loss is -138.40556602
Iteration 481 lower bound -130.750825842
loss is Autograd FloatNode with value -107.679045171 and 1 tape(s)
loss is -117.525075025
Iteration 482 lower bound -151.744123532
loss is Autograd FloatNode with value -107.550721215 and 1 tape(s)
loss is -116.626260337
Iteration 483 lower bound -152.688302893
loss is Autograd FloatNode with value -111.186418875 and 1 tape(s)
loss is -103.523192786
Iteration 484 lower bound -165.838449712
loss is Autograd FloatNode with value -111.606765154 and 1 tape(s)
loss is -110.244863402
Iteration 485 lower bound -159.107242126
loss is Autograd FloatNode with value -113.983633219 and 1 tape(s)
loss is -99.810126867
Iteration 486 lower bound -169.427356003
loss is Autograd FloatNode with value -112.808686833 and 1 tape(s)
loss is -107.262354332
Iteration 487 lower bound -161.739091304
loss is Autograd FloatNode with value -115.322059426 and 1 tape(s)
loss is -108.25243077
Iteration 488 lower bound -160.416298206
loss is Autograd FloatNode with value -110.632028511 and 1 tape(s)
loss is -111.704664639
Iteration 489 lower bound -156.490756341
loss is Autograd FloatNode with value -101.720802633 and 1 tape(s)
loss is -115.681997032
Iteration 490 lower bound -152.099133153
loss is Autograd FloatNode with value -106.502584319 and 1 tape(s)
loss is -113.12783795
Iteration 491 lower bound -154.299884447
loss is Autograd FloatNode with value -105.840025517 and 1 tape(s)
loss is -108.943666102
Iteration 492 lower bound -158.125426001
loss is Autograd FloatNode with value -108.868857113 and 1 tape(s)
loss is -108.03844015
Iteration 493 lower bound -158.716196476
loss is Autograd FloatNode with value -119.681679163 and 1 tape(s)
loss is -111.147910771
Iteration 494 lower bound -155.393012954
loss is Autograd FloatNode with value -107.930148006 and 1 tape(s)
loss is -119.110776603
Iteration 495 lower bound -147.004286299
loss is Autograd FloatNode with value -104.391674835 and 1 tape(s)
loss is -105.094222125
Iteration 496 lower bound -160.815342399
loss is Autograd FloatNode with value -108.534977348 and 1 tape(s)
loss is -107.754447944
Iteration 497 lower bound -158.096267328
loss is Autograd FloatNode with value -107.506584371 and 1 tape(s)
loss is -112.434378367
Iteration 498 lower bound -153.453839553
loss is Autograd FloatNode with value -99.7802944547 and 1 tape(s)
loss is -96.7815707409
Iteration 499 lower bound -169.262115215
loss is Autograd FloatNode with value -115.466716546 and 1 tape(s)
loss is -111.043746859
Iteration 500 lower bound -155.310341852
loss is Autograd FloatNode with value -95.7018934016 and 1 tape(s)
loss is -102.711611569
Iteration 501 lower bound -163.715824795
loss is Autograd FloatNode with value -106.364482979 and 1 tape(s)
loss is -102.308690105
Iteration 502 lower bound -164.432416011
loss is Autograd FloatNode with value -106.370116681 and 1 tape(s)
loss is -108.861050033
Iteration 503 lower bound -158.235752245
loss is Autograd FloatNode with value -102.545161892 and 1 tape(s)
loss is -112.734361566
Iteration 504 lower bound -154.85292085
loss is Autograd FloatNode with value -112.958329093 and 1 tape(s)
loss is -119.87839639
Iteration 505 lower bound -148.304013842
loss is Autograd FloatNode with value -102.68552671 and 1 tape(s)
loss is -109.127765528
Iteration 506 lower bound -159.489756335
loss is Autograd FloatNode with value -110.88137354 and 1 tape(s)
loss is -106.275330283
Iteration 507 lower bound -162.904029117
loss is Autograd FloatNode with value -109.555747311 and 1 tape(s)
loss is -105.023480885
Iteration 508 lower bound -164.593939239
loss is Autograd FloatNode with value -104.176438868 and 1 tape(s)
loss is -105.875570083
Iteration 509 lower bound -164.124641146
loss is Autograd FloatNode with value -106.990018368 and 1 tape(s)
loss is -107.158110739
Iteration 510 lower bound -163.242809612
loss is Autograd FloatNode with value -109.302957854 and 1 tape(s)
loss is -114.137091834
Iteration 511 lower bound -156.694118074
loss is Autograd FloatNode with value -110.223787108 and 1 tape(s)
loss is -111.636637109
Iteration 512 lower bound -159.596172603
loss is Autograd FloatNode with value -121.630649677 and 1 tape(s)
loss is -109.654369349
Iteration 513 lower bound -161.915111972
loss is Autograd FloatNode with value -113.711111578 and 1 tape(s)
loss is -115.569810707
Iteration 514 lower bound -156.135814537
loss is Autograd FloatNode with value -118.136361631 and 1 tape(s)
loss is -115.785855708
Iteration 515 lower bound -156.095968359
loss is Autograd FloatNode with value -117.639395186 and 1 tape(s)
loss is -124.659006178
Iteration 516 lower bound -147.321783359
loss is Autograd FloatNode with value -117.135902407 and 1 tape(s)
loss is -147.853391952
Iteration 517 lower bound -124.207735585
loss is Autograd FloatNode with value -123.237799937 and 1 tape(s)
loss is -112.268406103
Iteration 518 lower bound -159.878411576
loss is Autograd FloatNode with value -112.544146154 and 1 tape(s)
loss is -135.878593245
Iteration 519 lower bound -136.03491111
loss is Autograd FloatNode with value -108.369724826 and 1 tape(s)
loss is -109.39386321
Iteration 520 lower bound -162.372763255
loss is Autograd FloatNode with value -108.727299044 and 1 tape(s)
loss is -110.843167814
Iteration 521 lower bound -160.795633706
loss is Autograd FloatNode with value -134.146546085 and 1 tape(s)
loss is -108.929926149
Iteration 522 lower bound -162.779826976
loss is Autograd FloatNode with value -103.155160062 and 1 tape(s)
loss is -118.450481686
Iteration 523 lower bound -152.723503618
loss is Autograd FloatNode with value -104.911746856 and 1 tape(s)
loss is -104.836137971
Iteration 524 lower bound -165.970244195
loss is Autograd FloatNode with value -118.63041551 and 1 tape(s)
loss is -140.2322081
Iteration 525 lower bound -130.329955008
loss is Autograd FloatNode with value -109.890091745 and 1 tape(s)
loss is -114.241836461
Iteration 526 lower bound -156.067585752
loss is Autograd FloatNode with value -103.568473916 and 1 tape(s)
loss is -108.226692086
Iteration 527 lower bound -161.965930442
loss is Autograd FloatNode with value -102.229238164 and 1 tape(s)
loss is -106.150174323
Iteration 528 lower bound -164.026061335
loss is Autograd FloatNode with value -101.191304361 and 1 tape(s)
loss is -156.40927524
Iteration 529 lower bound -113.846050029
loss is Autograd FloatNode with value -104.606344018 and 1 tape(s)
loss is -96.4896604803
Iteration 530 lower bound -173.974149852
loss is Autograd FloatNode with value -117.248296891 and 1 tape(s)
loss is -112.27738685
Iteration 531 lower bound -158.268155424
loss is Autograd FloatNode with value -106.908439486 and 1 tape(s)
loss is -99.190429572
Iteration 532 lower bound -171.240365047
loss is Autograd FloatNode with value -107.023296929 and 1 tape(s)
loss is -123.814890391
Iteration 533 lower bound -146.44737329
loss is Autograd FloatNode with value -103.216103968 and 1 tape(s)
loss is -104.655227754
Iteration 534 lower bound -165.520463057
loss is Autograd FloatNode with value -103.930245005 and 1 tape(s)
loss is -100.121869176
Iteration 535 lower bound -170.06841819
loss is Autograd FloatNode with value -121.012991052 and 1 tape(s)
loss is -106.53139274
Iteration 536 lower bound -163.751435671
loss is Autograd FloatNode with value -171.534652945 and 1 tape(s)
loss is -99.7640858432
Iteration 537 lower bound -170.378296356
loss is Autograd FloatNode with value -117.150204641 and 1 tape(s)
loss is -108.037632123
Iteration 538 lower bound -160.999094976
loss is Autograd FloatNode with value -107.986215043 and 1 tape(s)
loss is -100.846599492
Iteration 539 lower bound -167.104212358
loss is Autograd FloatNode with value -107.183867037 and 1 tape(s)
loss is -108.970429167
Iteration 540 lower bound -158.046732
loss is Autograd FloatNode with value -108.278817103 and 1 tape(s)
loss is -111.548044141
Iteration 541 lower bound -154.693610859
loss is Autograd FloatNode with value -113.197792127 and 1 tape(s)
loss is -107.259750553
Iteration 542 lower bound -158.404530616
loss is Autograd FloatNode with value -114.923979237 and 1 tape(s)
loss is -116.896279144
Iteration 543 lower bound -148.165174995
loss is Autograd FloatNode with value -109.955879712 and 1 tape(s)
loss is -103.051350745
Iteration 544 lower bound -161.319302635
loss is Autograd FloatNode with value -100.991458115 and 1 tape(s)
loss is -112.80971322
Iteration 545 lower bound -150.76117474
loss is Autograd FloatNode with value -118.086663017 and 1 tape(s)
loss is -111.293224951
Iteration 546 lower bound -151.712191412
loss is Autograd FloatNode with value -105.026778444 and 1 tape(s)
loss is -103.854772398
Iteration 547 lower bound -158.602273107
loss is Autograd FloatNode with value -112.053733197 and 1 tape(s)
loss is -105.351802369
Iteration 548 lower bound -156.648148875
loss is Autograd FloatNode with value -110.233123558 and 1 tape(s)
loss is -105.791912354
Iteration 549 lower bound -155.829274253
loss is Autograd FloatNode with value -118.854927835 and 1 tape(s)
loss is -114.595180368
Iteration 550 lower bound -146.848551122
loss is Autograd FloatNode with value -105.490263589 and 1 tape(s)
loss is -110.561481741
Iteration 551 lower bound -150.673811836
loss is Autograd FloatNode with value -112.084375167 and 1 tape(s)
loss is -114.403110813
Iteration 552 lower bound -146.833099503
loss is Autograd FloatNode with value -106.08287833 and 1 tape(s)
loss is -104.328989349
Iteration 553 lower bound -157.017924676
loss is Autograd FloatNode with value -122.190208239 and 1 tape(s)
loss is -115.967275163
Iteration 554 lower bound -145.67605964
loss is Autograd FloatNode with value -123.595123388 and 1 tape(s)
loss is -109.060531539
Iteration 555 lower bound -152.840711505
loss is Autograd FloatNode with value -112.867684661 and 1 tape(s)
loss is -118.668760101
Iteration 556 lower bound -143.410359232
loss is Autograd FloatNode with value -119.515579171 and 1 tape(s)
loss is -108.819419372
Iteration 557 lower bound -153.546915035
loss is Autograd FloatNode with value -113.858109369 and 1 tape(s)
loss is -106.988775253
Iteration 558 lower bound -155.649499745
loss is Autograd FloatNode with value -120.315928516 and 1 tape(s)
loss is -111.68729432
Iteration 559 lower bound -151.003714686
loss is Autograd FloatNode with value -127.98582735 and 1 tape(s)
loss is -114.29302149
Iteration 560 lower bound -148.340560345
loss is Autograd FloatNode with value -104.894820146 and 1 tape(s)
loss is -109.469327395
Iteration 561 lower bound -153.052554972
loss is Autograd FloatNode with value -104.638421992 and 1 tape(s)
loss is -105.723138273
Iteration 562 lower bound -156.910113041
loss is Autograd FloatNode with value -116.912352373 and 1 tape(s)
loss is -119.163144541
Iteration 563 lower bound -143.775924594
loss is Autograd FloatNode with value -104.658298763 and 1 tape(s)
loss is -101.115940464
Iteration 564 lower bound -162.163168567
loss is Autograd FloatNode with value -105.368909961 and 1 tape(s)
loss is -102.840848557
Iteration 565 lower bound -160.800932699
loss is Autograd FloatNode with value -105.153438265 and 1 tape(s)
loss is -115.673109299
Iteration 566 lower bound -148.476032161
loss is Autograd FloatNode with value -109.622924032 and 1 tape(s)
loss is -107.337870572
Iteration 567 lower bound -157.470234075
loss is Autograd FloatNode with value -106.041305263 and 1 tape(s)
loss is -102.430138952
Iteration 568 lower bound -163.160387043
loss is Autograd FloatNode with value -132.277009719 and 1 tape(s)
loss is -101.597540535
Iteration 569 lower bound -164.822308084
loss is Autograd FloatNode with value -110.825683123 and 1 tape(s)
loss is -116.515810038
Iteration 570 lower bound -150.372962706
loss is Autograd FloatNode with value -103.123167919 and 1 tape(s)
loss is -104.808149806
Iteration 571 lower bound -162.536743382
loss is Autograd FloatNode with value -107.623939408 and 1 tape(s)
loss is -102.387555201
Iteration 572 lower bound -165.596017863
loss is Autograd FloatNode with value -108.378873504 and 1 tape(s)
loss is -113.849797571
Iteration 573 lower bound -154.8448012
loss is Autograd FloatNode with value -114.534029652 and 1 tape(s)
loss is -114.975312638
Iteration 574 lower bound -154.478796211
loss is Autograd FloatNode with value -112.071780966 and 1 tape(s)
loss is -105.037963982
Iteration 575 lower bound -165.062524084
loss is Autograd FloatNode with value -109.381808249 and 1 tape(s)
loss is -143.591787821
Iteration 576 lower bound -126.985203632
loss is Autograd FloatNode with value -105.874664514 and 1 tape(s)
loss is -102.985779626
Iteration 577 lower bound -168.128784745
loss is Autograd FloatNode with value -108.676054675 and 1 tape(s)
loss is -126.258805251
Iteration 578 lower bound -145.35245783
loss is Autograd FloatNode with value -105.287807059 and 1 tape(s)
loss is -101.008096824
Iteration 579 lower bound -171.071659941
loss is Autograd FloatNode with value -113.180364129 and 1 tape(s)
loss is -110.841509239
Iteration 580 lower bound -161.750584974
loss is Autograd FloatNode with value -111.422567658 and 1 tape(s)
loss is -112.074300294
Iteration 581 lower bound -160.834491576
loss is Autograd FloatNode with value -108.945895596 and 1 tape(s)
loss is -116.201387325
Iteration 582 lower bound -156.948145179
loss is Autograd FloatNode with value -101.67373831 and 1 tape(s)
loss is -112.960412702
Iteration 583 lower bound -160.500388792
loss is Autograd FloatNode with value -126.837511554 and 1 tape(s)
loss is -113.111585968
Iteration 584 lower bound -160.745473449
loss is Autograd FloatNode with value -114.401455251 and 1 tape(s)
loss is -102.7976387
Iteration 585 lower bound -170.897244892
loss is Autograd FloatNode with value -103.379939506 and 1 tape(s)
loss is -108.054324672
Iteration 586 lower bound -165.441051216
loss is Autograd FloatNode with value -120.768180789 and 1 tape(s)
loss is -107.692581225
Iteration 587 lower bound -165.745003354
loss is Autograd FloatNode with value -103.072311972 and 1 tape(s)
loss is -112.242613169
Iteration 588 lower bound -161.002062299
loss is Autograd FloatNode with value -118.794137759 and 1 tape(s)
loss is -107.885174545
Iteration 589 lower bound -165.304931886
loss is Autograd FloatNode with value -112.66467544 and 1 tape(s)
loss is -122.70666374
Iteration 590 lower bound -150.182626002
loss is Autograd FloatNode with value -107.021946922 and 1 tape(s)
loss is -107.607497447
Iteration 591 lower bound -164.950264619
loss is Autograd FloatNode with value -117.505790829 and 1 tape(s)
loss is -117.852689699
Iteration 592 lower bound -154.510545019
loss is Autograd FloatNode with value -104.254970295 and 1 tape(s)
loss is -108.191425117
Iteration 593 lower bound -163.999247145
loss is Autograd FloatNode with value -108.78057262 and 1 tape(s)
loss is -132.306953373
Iteration 594 lower bound -139.821290972
loss is Autograd FloatNode with value -103.717524181 and 1 tape(s)
loss is -111.025555599
Iteration 595 lower bound -161.096314232
loss is Autograd FloatNode with value -117.622495066 and 1 tape(s)
loss is -111.394748906
Iteration 596 lower bound -160.778762853
loss is Autograd FloatNode with value -136.372075935 and 1 tape(s)
loss is -105.011216971
Iteration 597 lower bound -167.114441962
loss is Autograd FloatNode with value -108.38810551 and 1 tape(s)
loss is -106.518760145
Iteration 598 lower bound -165.191932944
loss is Autograd FloatNode with value -267.547234368 and 1 tape(s)
loss is -181.728523018
Iteration 599 lower bound -89.7391311505
loss is Autograd FloatNode with value -112.851215393 and 1 tape(s)
loss is -106.397612703
Iteration 600 lower bound -163.55624458
loss is Autograd FloatNode with value -108.046437731 and 1 tape(s)
loss is -107.732368816
Iteration 601 lower bound -160.940512597
loss is Autograd FloatNode with value -137.294741296 and 1 tape(s)
loss is -107.270364456
Iteration 602 lower bound -160.396949653
loss is Autograd FloatNode with value -104.888101907 and 1 tape(s)
loss is -103.901075359
Iteration 603 lower bound -162.249433625
loss is Autograd FloatNode with value -108.729184748 and 1 tape(s)
loss is -103.737639209
Iteration 604 lower bound -161.137927562
loss is Autograd FloatNode with value -106.905647291 and 1 tape(s)
loss is -99.1830427625
Iteration 605 lower bound -164.538812466
loss is Autograd FloatNode with value -111.477630651 and 1 tape(s)
loss is -100.270940906
Iteration 606 lower bound -162.482994777
loss is Autograd FloatNode with value -100.479421275 and 1 tape(s)
loss is -104.056206903
Iteration 607 lower bound -157.866992852
loss is Autograd FloatNode with value -101.468202724 and 1 tape(s)
loss is -106.280267468
Iteration 608 lower bound -155.060812506
loss is Autograd FloatNode with value -97.4719246995 and 1 tape(s)
loss is -100.844587721
Iteration 609 lower bound -160.140299155
loss is Autograd FloatNode with value -102.606272591 and 1 tape(s)
loss is -104.562816122
Iteration 610 lower bound -156.31416818
loss is Autograd FloatNode with value -101.916507552 and 1 tape(s)
loss is -101.87371478
Iteration 611 lower bound -159.055529241
loss is Autograd FloatNode with value -106.653970847 and 1 tape(s)
loss is -112.009515185
Iteration 612 lower bound -149.045023945
loss is Autograd FloatNode with value -101.170179687 and 1 tape(s)
loss is -103.743003019
Iteration 613 lower bound -157.466456549
loss is Autograd FloatNode with value -107.827180986 and 1 tape(s)
loss is -99.1249217967
Iteration 614 lower bound -162.351711078
loss is Autograd FloatNode with value -111.161237051 and 1 tape(s)
loss is -99.2638564262
Iteration 615 lower bound -162.460927716
loss is Autograd FloatNode with value -111.59136105 and 1 tape(s)
loss is -104.687947847
Iteration 616 lower bound -157.256989864
loss is Autograd FloatNode with value -104.180879734 and 1 tape(s)
loss is -122.080144592
Iteration 617 lower bound -140.099175972
loss is Autograd FloatNode with value -108.535558205 and 1 tape(s)
loss is -115.869981125
Iteration 618 lower bound -146.486182232
loss is Autograd FloatNode with value -114.225865263 and 1 tape(s)
loss is -110.383426834
Iteration 619 lower bound -152.162392957
loss is Autograd FloatNode with value -107.150410061 and 1 tape(s)
loss is -116.313471708
Iteration 620 lower bound -146.3214072
loss is Autograd FloatNode with value -106.352716157 and 1 tape(s)
loss is -111.339172037
Iteration 621 lower bound -151.541306186
loss is Autograd FloatNode with value -115.402385193 and 1 tape(s)
loss is -112.366456376
Iteration 622 lower bound -150.782636505
loss is Autograd FloatNode with value -113.299046829 and 1 tape(s)
loss is -109.127686334
Iteration 623 lower bound -154.267704035
loss is Autograd FloatNode with value -104.777347588 and 1 tape(s)
loss is -105.166564736
Iteration 624 lower bound -158.447845249
loss is Autograd FloatNode with value -103.24699282 and 1 tape(s)
loss is -104.747737539
Iteration 625 lower bound -159.189870373
loss is Autograd FloatNode with value -114.095781992 and 1 tape(s)
loss is -116.73389649
Iteration 626 lower bound -147.635384319
loss is Autograd FloatNode with value -104.28411668 and 1 tape(s)
loss is -105.796074639
Iteration 627 lower bound -158.998540184
loss is Autograd FloatNode with value -106.023168975 and 1 tape(s)
loss is -106.290832611
Iteration 628 lower bound -159.006915272
loss is Autograd FloatNode with value -99.9392884505 and 1 tape(s)
loss is -105.279199772
Iteration 629 lower bound -160.513503194
loss is Autograd FloatNode with value -105.353401135 and 1 tape(s)
loss is -99.3252962076
Iteration 630 lower bound -167.080465535
loss is Autograd FloatNode with value -106.23229673 and 1 tape(s)
loss is -101.406960654
Iteration 631 lower bound -165.569450438
loss is Autograd FloatNode with value -105.237361633 and 1 tape(s)
loss is -104.542266066
Iteration 632 lower bound -162.985116987
loss is Autograd FloatNode with value -103.893122011 and 1 tape(s)
loss is -117.787802918
Iteration 633 lower bound -150.324787327
loss is Autograd FloatNode with value -123.420717775 and 1 tape(s)
loss is -108.120266321
Iteration 634 lower bound -160.551694655
loss is Autograd FloatNode with value -115.596440142 and 1 tape(s)
loss is -108.395648244
Iteration 635 lower bound -160.552271361
loss is Autograd FloatNode with value -141.552668073 and 1 tape(s)
loss is -102.064007238
Iteration 636 lower bound -167.037910566
loss is Autograd FloatNode with value -105.998666786 and 1 tape(s)
loss is -113.528226382
Iteration 637 lower bound -155.186044019
loss is Autograd FloatNode with value -106.154223558 and 1 tape(s)
loss is -111.982973986
Iteration 638 lower bound -156.373751881
loss is Autograd FloatNode with value -95.5829703042 and 1 tape(s)
loss is -102.998932163
Iteration 639 lower bound -165.024720246
loss is Autograd FloatNode with value -111.460608874 and 1 tape(s)
loss is -130.136535768
Iteration 640 lower bound -137.760993513
loss is Autograd FloatNode with value -99.1679904899 and 1 tape(s)
loss is -104.161955103
Iteration 641 lower bound -163.652242333
loss is Autograd FloatNode with value -100.146722346 and 1 tape(s)
loss is -110.106002251
Iteration 642 lower bound -157.779900151
loss is Autograd FloatNode with value -110.127783129 and 1 tape(s)
loss is -114.614971348
Iteration 643 lower bound -153.503930075
loss is Autograd FloatNode with value -114.443105088 and 1 tape(s)
loss is -112.093038931
Iteration 644 lower bound -156.239223358
loss is Autograd FloatNode with value -106.624212225 and 1 tape(s)
loss is -102.477081137
Iteration 645 lower bound -165.960939679
loss is Autograd FloatNode with value -104.197778633 and 1 tape(s)
loss is -109.377306058
Iteration 646 lower bound -159.184259325
loss is Autograd FloatNode with value -112.939322814 and 1 tape(s)
loss is -110.525127894
Iteration 647 lower bound -158.199796048
loss is Autograd FloatNode with value -103.841406184 and 1 tape(s)
loss is -114.397332366
Iteration 648 lower bound -154.473892216
loss is Autograd FloatNode with value -100.336347732 and 1 tape(s)
loss is -108.792006358
Iteration 649 lower bound -160.268282042
loss is Autograd FloatNode with value -111.303195454 and 1 tape(s)
loss is -116.423890674
Iteration 650 lower bound -152.912635465
loss is Autograd FloatNode with value -103.706785702 and 1 tape(s)
loss is -113.392354116
Iteration 651 lower bound -156.409938497
loss is Autograd FloatNode with value -104.375837242 and 1 tape(s)
loss is -108.488403479
Iteration 652 lower bound -161.839251265
loss is Autograd FloatNode with value -101.810107937 and 1 tape(s)
loss is -123.69448082
Iteration 653 lower bound -147.153727472
loss is Autograd FloatNode with value -114.580076092 and 1 tape(s)
loss is -102.746170717
Iteration 654 lower bound -168.661878638
loss is Autograd FloatNode with value -100.220086121 and 1 tape(s)
loss is -109.325792553
Iteration 655 lower bound -162.674761478
loss is Autograd FloatNode with value -106.037862321 and 1 tape(s)
loss is -106.201897941
Iteration 656 lower bound -166.404780923
loss is Autograd FloatNode with value -109.546458837 and 1 tape(s)
loss is -105.98502573
Iteration 657 lower bound -167.262620613
loss is Autograd FloatNode with value -111.636189032 and 1 tape(s)
loss is -106.323186084
Iteration 658 lower bound -167.397824113
loss is Autograd FloatNode with value -105.869341077 and 1 tape(s)
loss is -107.040315803
Iteration 659 lower bound -167.100846835
loss is Autograd FloatNode with value -117.40798606 and 1 tape(s)
loss is -109.48154991
Iteration 660 lower bound -165.186600781
loss is Autograd FloatNode with value -104.189822021 and 1 tape(s)
loss is -113.035297159
Iteration 661 lower bound -161.937402828
loss is Autograd FloatNode with value -112.53364758 and 1 tape(s)
loss is -139.529933915
Iteration 662 lower bound -135.750277425
loss is Autograd FloatNode with value -104.202098097 and 1 tape(s)
loss is -114.122752426
Iteration 663 lower bound -161.428903751
loss is Autograd FloatNode with value -102.803181605 and 1 tape(s)
loss is -105.183293784
Iteration 664 lower bound -170.627764172
loss is Autograd FloatNode with value -107.669763394 and 1 tape(s)
loss is -119.101072891
Iteration 665 lower bound -157.043031635
loss is Autograd FloatNode with value -117.36617427 and 1 tape(s)
loss is -115.390332506
Iteration 666 lower bound -161.131483302
loss is Autograd FloatNode with value -113.932511299 and 1 tape(s)
loss is -113.656367134
Iteration 667 lower bound -163.279078664
loss is Autograd FloatNode with value -110.68363331 and 1 tape(s)
loss is -106.461635096
Iteration 668 lower bound -170.746782458
loss is Autograd FloatNode with value -115.895604297 and 1 tape(s)
loss is -117.931508488
Iteration 669 lower bound -159.414853872
loss is Autograd FloatNode with value -115.348477714 and 1 tape(s)
loss is -120.091902106
Iteration 670 lower bound -157.475002634
loss is Autograd FloatNode with value -112.23499711 and 1 tape(s)
loss is -120.610024785
Iteration 671 lower bound -157.084565485
loss is Autograd FloatNode with value -111.824298665 and 1 tape(s)
loss is -120.417948119
Iteration 672 lower bound -157.452112592
loss is Autograd FloatNode with value -104.023385116 and 1 tape(s)
loss is -112.506423183
Iteration 673 lower bound -165.594338074
loss is Autograd FloatNode with value -118.080641984 and 1 tape(s)
loss is -115.857953279
Iteration 674 lower bound -162.63649886
loss is Autograd FloatNode with value -112.443154563 and 1 tape(s)
loss is -111.571860884
Iteration 675 lower bound -166.967484013
loss is Autograd FloatNode with value -114.845410306 and 1 tape(s)
loss is -114.811869411
Iteration 676 lower bound -163.754683561
loss is Autograd FloatNode with value -115.779135618 and 1 tape(s)
loss is -110.356192304
Iteration 677 lower bound -168.259515873
loss is Autograd FloatNode with value -109.301195928 and 1 tape(s)
loss is -118.819100268
Iteration 678 lower bound -159.757597387
loss is Autograd FloatNode with value -117.642926627 and 1 tape(s)
loss is -119.935608294
Iteration 679 lower bound -158.745721728
loss is Autograd FloatNode with value -107.210386847 and 1 tape(s)
loss is -117.780756682
Iteration 680 lower bound -161.119459732
loss is Autograd FloatNode with value -107.265624346 and 1 tape(s)
loss is -104.893597664
Iteration 681 lower bound -174.306154436
loss is Autograd FloatNode with value -130.496773919 and 1 tape(s)
loss is -118.237075751
Iteration 682 lower bound -161.081312254
loss is Autograd FloatNode with value -107.43675968 and 1 tape(s)
loss is -116.872521239
Iteration 683 lower bound -162.366298949
loss is Autograd FloatNode with value -104.751770825 and 1 tape(s)
loss is -111.701364479
Iteration 684 lower bound -167.589826582
loss is Autograd FloatNode with value -104.670041562 and 1 tape(s)
loss is -112.299056439
Iteration 685 lower bound -167.176524159
loss is Autograd FloatNode with value -111.921380426 and 1 tape(s)
loss is -112.823710839
Iteration 686 lower bound -166.949897309
loss is Autograd FloatNode with value -135.370173391 and 1 tape(s)
loss is -112.209656603
Iteration 687 lower bound -167.876141876
loss is Autograd FloatNode with value -118.837496455 and 1 tape(s)
loss is -111.564741167
Iteration 688 lower bound -168.196955259
loss is Autograd FloatNode with value -136.050754551 and 1 tape(s)
loss is -124.886826556
Iteration 689 lower bound -154.464701232
loss is Autograd FloatNode with value -106.887526051 and 1 tape(s)
loss is -110.691251931
Iteration 690 lower bound -167.99190083
loss is Autograd FloatNode with value -117.52874092 and 1 tape(s)
loss is -115.99082873
Iteration 691 lower bound -162.22289435
loss is Autograd FloatNode with value -112.354087258 and 1 tape(s)
loss is -114.831068254
Iteration 692 lower bound -162.951077431
loss is Autograd FloatNode with value -109.264851969 and 1 tape(s)
loss is -111.483093582
Iteration 693 lower bound -166.06756973
loss is Autograd FloatNode with value -110.52579836 and 1 tape(s)
loss is -111.596599424
Iteration 694 lower bound -165.764104703
loss is Autograd FloatNode with value -112.261008104 and 1 tape(s)
loss is -112.727079891
Iteration 695 lower bound -164.481709261
loss is Autograd FloatNode with value -108.731530008 and 1 tape(s)
loss is -100.902549887
Iteration 696 lower bound -176.294241273
loss is Autograd FloatNode with value -107.631377272 and 1 tape(s)
loss is -107.175191618
Iteration 697 lower bound -169.984331391
loss is Autograd FloatNode with value -108.272607306 and 1 tape(s)
loss is -107.782813594
Iteration 698 lower bound -169.401764015
loss is Autograd FloatNode with value -111.926370641 and 1 tape(s)
loss is -122.832321438
Iteration 699 lower bound -154.456511231
loss is Autograd FloatNode with value -107.36874528 and 1 tape(s)
loss is -114.464299309
Iteration 700 lower bound -162.949865609
loss is Autograd FloatNode with value -108.81846465 and 1 tape(s)
loss is -113.528674458
Iteration 701 lower bound -163.981378471
loss is Autograd FloatNode with value -107.888683328 and 1 tape(s)
loss is -112.1216624
Iteration 702 lower bound -165.5673921
loss is Autograd FloatNode with value -115.955382731 and 1 tape(s)
loss is -112.931327346
Iteration 703 lower bound -165.049832009
loss is Autograd FloatNode with value -107.407620172 and 1 tape(s)
loss is -109.581481793
Iteration 704 lower bound -168.662533229
loss is Autograd FloatNode with value -111.168306849 and 1 tape(s)
loss is -101.228388963
Iteration 705 lower bound -177.293984951
loss is Autograd FloatNode with value -107.220809377 and 1 tape(s)
loss is -113.928319308
Iteration 706 lower bound -164.878580037
loss is Autograd FloatNode with value -109.684508322 and 1 tape(s)
loss is -107.524134396
Iteration 707 lower bound -171.615131987
loss is Autograd FloatNode with value -109.051054114 and 1 tape(s)
loss is -102.706272849
Iteration 708 lower bound -176.730527847
loss is Autograd FloatNode with value -101.825401941 and 1 tape(s)
loss is -101.912006605
Iteration 709 lower bound -177.775130253
loss is Autograd FloatNode with value -101.864339503 and 1 tape(s)
loss is -109.485680903
Iteration 710 lower bound -170.515617337
loss is Autograd FloatNode with value -111.118901144 and 1 tape(s)
loss is -105.752140828
Iteration 711 lower bound -174.675854933
loss is Autograd FloatNode with value -134.969916559 and 1 tape(s)
loss is -101.784102461
Iteration 712 lower bound -178.929251195
loss is Autograd FloatNode with value -104.425483447 and 1 tape(s)
loss is -109.975335733
Iteration 713 lower bound -170.743300357
loss is Autograd FloatNode with value -111.881763985 and 1 tape(s)
loss is -105.849344697
Iteration 714 lower bound -174.902378301
loss is Autograd FloatNode with value -109.836828071 and 1 tape(s)
loss is -96.8940617355
Iteration 715 lower bound -183.869113027
loss is Autograd FloatNode with value -105.927133681 and 1 tape(s)
loss is -107.637784515
Iteration 716 lower bound -173.040162731
loss is Autograd FloatNode with value -102.790033862 and 1 tape(s)
loss is -107.366236591
Iteration 717 lower bound -173.39721919
loss is Autograd FloatNode with value -105.74264915 and 1 tape(s)
loss is -105.168864181
Iteration 718 lower bound -175.762188934
loss is Autograd FloatNode with value -103.309854157 and 1 tape(s)
loss is -102.225708516
Iteration 719 lower bound -178.948250066
loss is Autograd FloatNode with value -110.279314824 and 1 tape(s)
loss is -124.409477149
Iteration 720 lower bound -157.121527833
loss is Autograd FloatNode with value -107.27818448 and 1 tape(s)
loss is -116.87994191
Iteration 721 lower bound -165.002372418
loss is Autograd FloatNode with value -104.161636538 and 1 tape(s)
loss is -109.179567717
Iteration 722 lower bound -173.038782922
loss is Autograd FloatNode with value -137.35467233 and 1 tape(s)
loss is -121.436166725
Iteration 723 lower bound -161.109445339
loss is Autograd FloatNode with value -104.259365086 and 1 tape(s)
loss is -119.75040654
Iteration 724 lower bound -163.075257815
loss is Autograd FloatNode with value -108.899020652 and 1 tape(s)
loss is -111.677519394
Iteration 725 lower bound -171.470453739
loss is Autograd FloatNode with value -106.100809295 and 1 tape(s)
loss is -103.934428781
Iteration 726 lower bound -179.551010731
loss is Autograd FloatNode with value -110.576842507 and 1 tape(s)
loss is -118.016333649
Iteration 727 lower bound -165.862488897
loss is Autograd FloatNode with value -124.960578389 and 1 tape(s)
loss is -111.484124711
Iteration 728 lower bound -172.745603196
loss is Autograd FloatNode with value -107.237704815 and 1 tape(s)
loss is -111.493197661
Iteration 729 lower bound -172.605506068
loss is Autograd FloatNode with value -124.187864738 and 1 tape(s)
loss is -108.99972639
Iteration 730 lower bound -175.151929277
loss is Autograd FloatNode with value -110.941445762 and 1 tape(s)
loss is -108.714653682
Iteration 731 lower bound -175.448935529
loss is Autograd FloatNode with value -108.378940989 and 1 tape(s)
loss is -119.66466181
Iteration 732 lower bound -164.530544397
loss is Autograd FloatNode with value -105.960327741 and 1 tape(s)
loss is -131.331437523
Iteration 733 lower bound -152.909461502
loss is Autograd FloatNode with value -109.274428672 and 1 tape(s)
loss is -105.027486647
Iteration 734 lower bound -179.297891518
loss is Autograd FloatNode with value -119.327846622 and 1 tape(s)
loss is -112.97600162
Iteration 735 lower bound -171.400212064
loss is Autograd FloatNode with value -111.705090816 and 1 tape(s)
loss is -110.90216006
Iteration 736 lower bound -173.4323647
loss is Autograd FloatNode with value -113.02367368 and 1 tape(s)
loss is -107.140119362
Iteration 737 lower bound -177.139480568
loss is Autograd FloatNode with value -117.71603106 and 1 tape(s)
loss is -100.951767649
Iteration 738 lower bound -183.241728219
loss is Autograd FloatNode with value -105.148976673 and 1 tape(s)
loss is -108.59941078
Iteration 739 lower bound -175.429686037
loss is Autograd FloatNode with value -115.367700569 and 1 tape(s)
loss is -107.211705431
Iteration 740 lower bound -176.734475977
loss is Autograd FloatNode with value -104.994829519 and 1 tape(s)
loss is -102.95802998
Iteration 741 lower bound -180.781866375
loss is Autograd FloatNode with value -110.147434611 and 1 tape(s)
loss is -105.38613179
Iteration 742 lower bound -178.285237027
loss is Autograd FloatNode with value -104.863010145 and 1 tape(s)
loss is -110.724385507
Iteration 743 lower bound -172.839940376
loss is Autograd FloatNode with value -105.323473832 and 1 tape(s)
loss is -108.876759724
Iteration 744 lower bound -174.625923562
loss is Autograd FloatNode with value -104.763612179 and 1 tape(s)
loss is -103.737312072
Iteration 745 lower bound -179.758775774
loss is Autograd FloatNode with value -103.749117163 and 1 tape(s)
loss is -105.735164396
Iteration 746 lower bound -177.688118764
loss is Autograd FloatNode with value -106.152828337 and 1 tape(s)
loss is -105.563895466
Iteration 747 lower bound -177.910213547
loss is Autograd FloatNode with value -105.558010464 and 1 tape(s)
loss is -103.311288048
Iteration 748 lower bound -180.398984159
loss is Autograd FloatNode with value -105.315121176 and 1 tape(s)
loss is -112.175280067
Iteration 749 lower bound -171.824929596
loss is Autograd FloatNode with value -100.638737578 and 1 tape(s)
loss is -112.787135
Iteration 750 lower bound -171.541969983
loss is Autograd FloatNode with value -121.326349885 and 1 tape(s)
loss is -110.160517539
Iteration 751 lower bound -174.638265481
loss is Autograd FloatNode with value -113.364132838 and 1 tape(s)
loss is -114.854633974
Iteration 752 lower bound -169.97745802
loss is Autograd FloatNode with value -104.882834521 and 1 tape(s)
loss is -104.848863624
Iteration 753 lower bound -180.050573414
loss is Autograd FloatNode with value -111.87163356 and 1 tape(s)
loss is -104.296518569
Iteration 754 lower bound -180.712811529
loss is Autograd FloatNode with value -104.264558777 and 1 tape(s)
loss is -109.357017264
Iteration 755 lower bound -175.78550185
loss is Autograd FloatNode with value -105.916661327 and 1 tape(s)
loss is -111.726554101
Iteration 756 lower bound -173.604843917
loss is Autograd FloatNode with value -110.538259785 and 1 tape(s)
loss is -113.677650716
Iteration 757 lower bound -171.871828846
loss is Autograd FloatNode with value -102.21129409 and 1 tape(s)
loss is -106.920198588
Iteration 758 lower bound -178.932259815
loss is Autograd FloatNode with value -100.765336811 and 1 tape(s)
loss is -104.619445264
Iteration 759 lower bound -181.660871165
loss is Autograd FloatNode with value -102.65392774 and 1 tape(s)
loss is -114.771526141
Iteration 760 lower bound -172.037028228
loss is Autograd FloatNode with value -108.061399064 and 1 tape(s)
loss is -113.528332804
Iteration 761 lower bound -173.83807302
loss is Autograd FloatNode with value -111.533199954 and 1 tape(s)
loss is -113.399407306
Iteration 762 lower bound -174.534687833
loss is Autograd FloatNode with value -108.524704434 and 1 tape(s)
loss is -113.425156669
Iteration 763 lower bound -175.016352252
loss is Autograd FloatNode with value -119.390349253 and 1 tape(s)
loss is -104.328549198
Iteration 764 lower bound -184.625730333
loss is Autograd FloatNode with value -106.953606776 and 1 tape(s)
loss is -108.456960056
Iteration 765 lower bound -180.830961183
loss is Autograd FloatNode with value -111.70685879 and 1 tape(s)
loss is -112.060544083
Iteration 766 lower bound -177.608108598
loss is Autograd FloatNode with value -110.734093755 and 1 tape(s)
loss is -107.923940531
Iteration 767 lower bound -182.065919424
loss is Autograd FloatNode with value -104.910812888 and 1 tape(s)
loss is -114.504310608
Iteration 768 lower bound -175.649427771
loss is Autograd FloatNode with value -117.464721371 and 1 tape(s)
loss is -108.215649979
Iteration 769 lower bound -182.152164338
loss is Autograd FloatNode with value -109.163526695 and 1 tape(s)
loss is -151.939041086
Iteration 770 lower bound -138.568748803
loss is Autograd FloatNode with value -105.172353032 and 1 tape(s)
loss is -112.528389186
Iteration 771 lower bound -178.060160505
loss is Autograd FloatNode with value -120.016069587 and 1 tape(s)
loss is -120.275705213
Iteration 772 lower bound -170.410898411
loss is Autograd FloatNode with value -111.349720353 and 1 tape(s)
loss is -115.000897851
Iteration 773 lower bound -175.559323851
loss is Autograd FloatNode with value -110.846334546 and 1 tape(s)
loss is -108.049802632
Iteration 774 lower bound -182.393244412
loss is Autograd FloatNode with value -109.376471353 and 1 tape(s)
loss is -110.345718986
Iteration 775 lower bound -180.116820183
loss is Autograd FloatNode with value -112.206213462 and 1 tape(s)
loss is -118.426035966
Iteration 776 lower bound -172.12051695
loss is Autograd FloatNode with value -110.825404435 and 1 tape(s)
loss is -109.392332817
Iteration 777 lower bound -181.300053512
loss is Autograd FloatNode with value -114.084052663 and 1 tape(s)
loss is -104.017782614
Iteration 778 lower bound -186.864713762
loss is Autograd FloatNode with value -106.571301375 and 1 tape(s)
loss is -106.722269826
Iteration 779 lower bound -184.339956643
loss is Autograd FloatNode with value -119.681545295 and 1 tape(s)
loss is -125.516640276
Iteration 780 lower bound -165.702741586
loss is Autograd FloatNode with value -113.577511657 and 1 tape(s)
loss is -110.697487923
Iteration 781 lower bound -180.661249965
loss is Autograd FloatNode with value -114.83511931 and 1 tape(s)
loss is -112.576909801
Iteration 782 lower bound -178.915296115
loss is Autograd FloatNode with value -109.867862357 and 1 tape(s)
loss is -122.017495692
Iteration 783 lower bound -169.505610722
loss is Autograd FloatNode with value -108.739808805 and 1 tape(s)
loss is -112.911727388
Iteration 784 lower bound -178.784484162
loss is Autograd FloatNode with value -108.265616792 and 1 tape(s)
loss is -119.416677821
Iteration 785 lower bound -172.535040525
loss is Autograd FloatNode with value -111.861909282 and 1 tape(s)
loss is -113.203456125
Iteration 786 lower bound -179.009538743
loss is Autograd FloatNode with value -114.524250301 and 1 tape(s)
loss is -111.076446932
Iteration 787 lower bound -181.421462241
loss is Autograd FloatNode with value -115.029067873 and 1 tape(s)
loss is -112.681393733
Iteration 788 lower bound -180.034963242
loss is Autograd FloatNode with value -109.339432395 and 1 tape(s)
loss is -122.283350796
Iteration 789 lower bound -170.605830889
loss is Autograd FloatNode with value -106.526405986 and 1 tape(s)
loss is -114.786162907
Iteration 790 lower bound -178.384031551
loss is Autograd FloatNode with value -108.052506906 and 1 tape(s)
loss is -100.437904533
Iteration 791 lower bound -193.16112736
loss is Autograd FloatNode with value -113.815915359 and 1 tape(s)
loss is -111.741412279
Iteration 792 lower bound -182.287635634
loss is Autograd FloatNode with value -117.291011101 and 1 tape(s)
loss is -118.441762882
Iteration 793 lower bound -175.836256389
loss is Autograd FloatNode with value -113.720080281 and 1 tape(s)
loss is -118.424516338
Iteration 794 lower bound -175.957300702
loss is Autograd FloatNode with value -112.219217811 and 1 tape(s)
loss is -116.614711192
Iteration 795 lower bound -177.78016406
loss is Autograd FloatNode with value -166.723030709 and 1 tape(s)
loss is -113.713725892
Iteration 796 lower bound -180.720947977
loss is Autograd FloatNode with value -116.376561797 and 1 tape(s)
loss is -121.611902119
Iteration 797 lower bound -172.149917094
loss is Autograd FloatNode with value -116.921532101 and 1 tape(s)
loss is -110.116226373
Iteration 798 lower bound -182.88989046
loss is Autograd FloatNode with value -119.308496181 and 1 tape(s)
loss is -109.570291263
Iteration 799 lower bound -182.628907397
loss is Autograd FloatNode with value -113.198866648 and 1 tape(s)
loss is -119.089716973
Iteration 800 lower bound -172.275806221
loss is Autograd FloatNode with value -113.024367918 and 1 tape(s)
loss is -116.509228019
Iteration 801 lower bound -174.056818562
loss is Autograd FloatNode with value -108.930584772 and 1 tape(s)
loss is -111.730078432
Iteration 802 lower bound -178.059576522
loss is Autograd FloatNode with value -110.505572346 and 1 tape(s)
loss is -108.156316518
Iteration 803 lower bound -180.926908408
loss is Autograd FloatNode with value -107.924336152 and 1 tape(s)
loss is -106.551011736
Iteration 804 lower bound -182.044663913
loss is Autograd FloatNode with value -113.113318793 and 1 tape(s)
loss is -118.01990719
Iteration 805 lower bound -170.241241644
loss is Autograd FloatNode with value -109.958085479 and 1 tape(s)
loss is -107.695842863
Iteration 806 lower bound -180.288138431
loss is Autograd FloatNode with value -118.760849442 and 1 tape(s)
loss is -111.939105577
Iteration 807 lower bound -175.725071785
loss is Autograd FloatNode with value -107.647115027 and 1 tape(s)
loss is -106.379835518
Iteration 808 lower bound -180.906934491
loss is Autograd FloatNode with value -107.60026659 and 1 tape(s)
loss is -126.299541576
Iteration 809 lower bound -160.697013487
loss is Autograd FloatNode with value -105.235853265 and 1 tape(s)
loss is -101.887086857
Iteration 810 lower bound -184.878391493
loss is Autograd FloatNode with value -115.796545525 and 1 tape(s)
loss is -99.0892588609
Iteration 811 lower bound -187.5088082
loss is Autograd FloatNode with value -102.570376484 and 1 tape(s)
loss is -102.695717586
Iteration 812 lower bound -183.692140293
loss is Autograd FloatNode with value -105.018088732 and 1 tape(s)
loss is -108.360247272
Iteration 813 lower bound -177.949683512
loss is Autograd FloatNode with value -114.091431141 and 1 tape(s)
loss is -108.440137983
Iteration 814 lower bound -177.938330296
loss is Autograd FloatNode with value -121.616284899 and 1 tape(s)
loss is -109.154782488
Iteration 815 lower bound -177.262246454
loss is Autograd FloatNode with value -110.113577778 and 1 tape(s)
loss is -111.980772001
Iteration 816 lower bound -174.245400694
loss is Autograd FloatNode with value -108.351295684 and 1 tape(s)
loss is -144.606589361
Iteration 817 lower bound -141.491319453
loss is Autograd FloatNode with value -107.291384229 and 1 tape(s)
loss is -131.233248932
Iteration 818 lower bound -154.781277894
loss is Autograd FloatNode with value -117.06992381 and 1 tape(s)
loss is -125.337260106
Iteration 819 lower bound -160.775807065
loss is Autograd FloatNode with value -112.463397449 and 1 tape(s)
loss is -110.788946
Iteration 820 lower bound -175.418236431
loss is Autograd FloatNode with value -102.704565594 and 1 tape(s)
loss is -109.441625777
Iteration 821 lower bound -176.870735573
loss is Autograd FloatNode with value -114.464498533 and 1 tape(s)
loss is -123.31710024
Iteration 822 lower bound -163.27597728
loss is Autograd FloatNode with value -117.857220352 and 1 tape(s)
loss is -110.7476117
Iteration 823 lower bound -176.189518385
loss is Autograd FloatNode with value -110.293441548 and 1 tape(s)
loss is -109.155714024
Iteration 824 lower bound -178.156683046
loss is Autograd FloatNode with value -112.696465485 and 1 tape(s)
loss is -110.814151278
Iteration 825 lower bound -176.818925084
loss is Autograd FloatNode with value -115.233768284 and 1 tape(s)
loss is -115.494006681
Iteration 826 lower bound -172.465095844
loss is Autograd FloatNode with value -116.70717264 and 1 tape(s)
loss is -110.889153628
Iteration 827 lower bound -177.323304508
loss is Autograd FloatNode with value -117.21074319 and 1 tape(s)
loss is -125.031602517
Iteration 828 lower bound -163.413478269
loss is Autograd FloatNode with value -117.521533097 and 1 tape(s)
loss is -118.937747625
Iteration 829 lower bound -169.753734085
loss is Autograd FloatNode with value -111.999938045 and 1 tape(s)
loss is -112.889890542
Iteration 830 lower bound -176.089890151
loss is Autograd FloatNode with value -111.349901403 and 1 tape(s)
loss is -118.759542072
Iteration 831 lower bound -170.524830806
loss is Autograd FloatNode with value -122.470286181 and 1 tape(s)
loss is -115.019919326
Iteration 832 lower bound -174.601567523
loss is Autograd FloatNode with value -110.300396816 and 1 tape(s)
loss is -117.660537703
Iteration 833 lower bound -172.050335048
loss is Autograd FloatNode with value -113.542526024 and 1 tape(s)
loss is -104.906820448
Iteration 834 lower bound -184.914628475
loss is Autograd FloatNode with value -125.331780289 and 1 tape(s)
loss is -118.2666821
Iteration 835 lower bound -171.598579288
loss is Autograd FloatNode with value -120.037504932 and 1 tape(s)
loss is -121.72350048
Iteration 836 lower bound -168.202842427
loss is Autograd FloatNode with value -116.354718777 and 1 tape(s)
loss is -134.099662615
Iteration 837 lower bound -155.871095013
loss is Autograd FloatNode with value -128.990272088 and 1 tape(s)
loss is -125.815353559
Iteration 838 lower bound -164.197109689
loss is Autograd FloatNode with value -116.976885617 and 1 tape(s)
loss is -112.010920494
Iteration 839 lower bound -177.876046063
loss is Autograd FloatNode with value -102.022627104 and 1 tape(s)
loss is -107.065161608
Iteration 840 lower bound -182.722552935
loss is Autograd FloatNode with value -109.60730181 and 1 tape(s)
loss is -113.672986292
Iteration 841 lower bound -176.168869714
loss is Autograd FloatNode with value -108.487471108 and 1 tape(s)
loss is -112.39789804
Iteration 842 lower bound -177.498266218
loss is Autograd FloatNode with value -114.123959615 and 1 tape(s)
loss is -108.517633873
Iteration 843 lower bound -181.605479573
loss is Autograd FloatNode with value -117.145241681 and 1 tape(s)
loss is -113.124469279
Iteration 844 lower bound -177.280377484
loss is Autograd FloatNode with value -115.842783409 and 1 tape(s)
loss is -108.678072032
Iteration 845 lower bound -182.021772179
loss is Autograd FloatNode with value -119.609235911 and 1 tape(s)
loss is -112.940729684
Iteration 846 lower bound -177.996892083
loss is Autograd FloatNode with value -114.631384647 and 1 tape(s)
loss is -114.169428024
Iteration 847 lower bound -176.883199876
loss is Autograd FloatNode with value -115.270001676 and 1 tape(s)
loss is -110.517651034
Iteration 848 lower bound -180.386920634
loss is Autograd FloatNode with value -143.498514162 and 1 tape(s)
loss is -132.118553656
Iteration 849 lower bound -158.732443015
loss is Autograd FloatNode with value -127.547838672 and 1 tape(s)
loss is -103.843904597
Iteration 850 lower bound -186.397825457
loss is Autograd FloatNode with value -112.070434051 and 1 tape(s)
loss is -114.856431236
Iteration 851 lower bound -174.523789832
loss is Autograd FloatNode with value -122.051494454 and 1 tape(s)
loss is -122.573534856
Iteration 852 lower bound -166.103700844
loss is Autograd FloatNode with value -106.076856219 and 1 tape(s)
loss is -106.655559697
Iteration 853 lower bound -181.456702482
loss is Autograd FloatNode with value -120.07798569 and 1 tape(s)
loss is -115.081787134
Iteration 854 lower bound -172.609976246
loss is Autograd FloatNode with value -145.493558478 and 1 tape(s)
loss is -118.648719182
Iteration 855 lower bound -168.67297929
loss is Autograd FloatNode with value -102.855484699 and 1 tape(s)
loss is -111.405505031
Iteration 856 lower bound -175.319999383
loss is Autograd FloatNode with value -120.884510126 and 1 tape(s)
loss is -134.551274261
Iteration 857 lower bound -151.76899351
loss is Autograd FloatNode with value -107.266818208 and 1 tape(s)
loss is -116.247531923
Iteration 858 lower bound -169.842070411
loss is Autograd FloatNode with value -106.062116042 and 1 tape(s)
loss is -99.2341218464
Iteration 859 lower bound -186.815616019
loss is Autograd FloatNode with value -120.866874132 and 1 tape(s)
loss is -114.795486174
Iteration 860 lower bound -171.346739127
loss is Autograd FloatNode with value -108.268081935 and 1 tape(s)
loss is -109.491189481
Iteration 861 lower bound -176.685480465
loss is Autograd FloatNode with value -112.957908106 and 1 tape(s)
loss is -108.099067651
Iteration 862 lower bound -178.275289442
loss is Autograd FloatNode with value -110.77304861 and 1 tape(s)
loss is -115.794723432
Iteration 863 lower bound -170.91116396
loss is Autograd FloatNode with value -108.159077801 and 1 tape(s)
loss is -104.216100914
Iteration 864 lower bound -182.9037129
loss is Autograd FloatNode with value -107.033626163 and 1 tape(s)
loss is -106.855122419
Iteration 865 lower bound -180.754400398
loss is Autograd FloatNode with value -108.674212615 and 1 tape(s)
loss is -110.421230958
Iteration 866 lower bound -177.76905697
loss is Autograd FloatNode with value -110.379141357 and 1 tape(s)
loss is -105.822146495
Iteration 867 lower bound -183.03844063
loss is Autograd FloatNode with value -114.697361299 and 1 tape(s)
loss is -117.192890118
Iteration 868 lower bound -172.226343876
loss is Autograd FloatNode with value -111.814831584 and 1 tape(s)
loss is -110.072992516
Iteration 869 lower bound -179.900665248
loss is Autograd FloatNode with value -134.242750236 and 1 tape(s)
loss is -109.465410657
Iteration 870 lower bound -181.165243092
loss is Autograd FloatNode with value -113.25334986 and 1 tape(s)
loss is -109.969982541
Iteration 871 lower bound -180.788558794
loss is Autograd FloatNode with value -110.114295319 and 1 tape(s)
loss is -115.953771432
Iteration 872 lower bound -174.937892156
loss is Autograd FloatNode with value -112.78531741 and 1 tape(s)
loss is -118.651717417
Iteration 873 lower bound -172.437610218
loss is Autograd FloatNode with value -113.634335904 and 1 tape(s)
loss is -114.636209531
Iteration 874 lower bound -176.719761572
loss is Autograd FloatNode with value -116.553692258 and 1 tape(s)
loss is -110.272732978
Iteration 875 lower bound -181.15141078
loss is Autograd FloatNode with value -115.176482877 and 1 tape(s)
loss is -113.619879927
Iteration 876 lower bound -177.841446757
loss is Autograd FloatNode with value -124.274450457 and 1 tape(s)
loss is -123.393526281
Iteration 877 lower bound -168.093945123
loss is Autograd FloatNode with value -108.426020985 and 1 tape(s)
loss is -107.060085967
Iteration 878 lower bound -184.491061034
loss is Autograd FloatNode with value -118.886603382 and 1 tape(s)
loss is -114.932140625
Iteration 879 lower bound -176.683375367
loss is Autograd FloatNode with value -114.989853529 and 1 tape(s)
loss is -122.254528528
Iteration 880 lower bound -169.354550495
loss is Autograd FloatNode with value -115.356106051 and 1 tape(s)
loss is -104.486096994
Iteration 881 lower bound -187.129217411
loss is Autograd FloatNode with value -104.110758028 and 1 tape(s)
loss is -112.878825383
Iteration 882 lower bound -178.800633942
loss is Autograd FloatNode with value -129.899967893 and 1 tape(s)
loss is -111.672414963
Iteration 883 lower bound -180.009545409
loss is Autograd FloatNode with value -110.496225782 and 1 tape(s)
loss is -110.333575249
Iteration 884 lower bound -181.314953902
loss is Autograd FloatNode with value -105.118166787 and 1 tape(s)
loss is -108.17899057
Iteration 885 lower bound -183.450553172
loss is Autograd FloatNode with value -129.423609478 and 1 tape(s)
loss is -110.566966845
Iteration 886 lower bound -181.083404909
loss is Autograd FloatNode with value -109.524409702 and 1 tape(s)
loss is -109.461684357
Iteration 887 lower bound -182.188766
loss is Autograd FloatNode with value -114.505588881 and 1 tape(s)
loss is -103.2048344
Iteration 888 lower bound -188.50436124
loss is Autograd FloatNode with value -112.406933745 and 1 tape(s)
loss is -116.063792684
Iteration 889 lower bound -175.551057253
loss is Autograd FloatNode with value -103.926782564 and 1 tape(s)
loss is -112.201854035
Iteration 890 lower bound -179.377008248
loss is Autograd FloatNode with value -108.72588019 and 1 tape(s)
loss is -107.270279979
Iteration 891 lower bound -184.366240122
loss is Autograd FloatNode with value -115.84661936 and 1 tape(s)
loss is -102.01185744
Iteration 892 lower bound -189.709702282
loss is Autograd FloatNode with value -99.8198024034 and 1 tape(s)
loss is -104.664141138
Iteration 893 lower bound -187.028655965
loss is Autograd FloatNode with value -105.318602579 and 1 tape(s)
loss is -110.640473884
Iteration 894 lower bound -181.047659132
loss is Autograd FloatNode with value -114.527952025 and 1 tape(s)
loss is -113.70672422
Iteration 895 lower bound -178.058859372
loss is Autograd FloatNode with value -108.184313226 and 1 tape(s)
loss is -109.629615405
Iteration 896 lower bound -182.064900604
loss is Autograd FloatNode with value -105.288489135 and 1 tape(s)
loss is -111.490775807
Iteration 897 lower bound -180.204355395
loss is Autograd FloatNode with value -111.119342084 and 1 tape(s)
loss is -130.838982144
Iteration 898 lower bound -160.991732848
loss is Autograd FloatNode with value -111.652372994 and 1 tape(s)
loss is -105.385186058
Iteration 899 lower bound -186.631752477
loss is Autograd FloatNode with value -99.9148770811 and 1 tape(s)
loss is -108.86408532
Iteration 900 lower bound -183.451994248
loss is Autograd FloatNode with value -114.511286459 and 1 tape(s)
loss is -111.906268921
Iteration 901 lower bound -180.836009244
loss is Autograd FloatNode with value -109.94214996 and 1 tape(s)
loss is -119.797723581
Iteration 902 lower bound -173.283572858
loss is Autograd FloatNode with value -105.959389061 and 1 tape(s)
loss is -110.565831688
Iteration 903 lower bound -182.897607774
loss is Autograd FloatNode with value -115.151940942 and 1 tape(s)
loss is -217.522056355
Iteration 904 lower bound -76.2275041743
loss is Autograd FloatNode with value -104.063491948 and 1 tape(s)
loss is -118.621006045
Iteration 905 lower bound -175.38487794
loss is Autograd FloatNode with value -121.968591511 and 1 tape(s)
loss is -109.975168295
Iteration 906 lower bound -184.46441021
loss is Autograd FloatNode with value -109.647840091 and 1 tape(s)
loss is -119.613600976
Iteration 907 lower bound -175.137529572
loss is Autograd FloatNode with value -116.663086178 and 1 tape(s)
loss is -113.077763948
Iteration 908 lower bound -181.964272052
loss is Autograd FloatNode with value -122.187523154 and 1 tape(s)
loss is -117.599914154
Iteration 909 lower bound -177.664869606
loss is Autograd FloatNode with value -109.288901073 and 1 tape(s)
loss is -105.748578406
Iteration 910 lower bound -189.561115361
loss is Autograd FloatNode with value -117.749595262 and 1 tape(s)
loss is -119.493847884
Iteration 911 lower bound -175.827925896
loss is Autograd FloatNode with value -105.539872146 and 1 tape(s)
loss is -109.244700297
Iteration 912 lower bound -186.043384638
loss is Autograd FloatNode with value -108.741690459 and 1 tape(s)
loss is -112.511825182
Iteration 913 lower bound -182.830336927
loss is Autograd FloatNode with value -116.278410595 and 1 tape(s)
loss is -156.093359093
Iteration 914 lower bound -139.440021477
loss is Autograd FloatNode with value -111.644073659 and 1 tape(s)
loss is -117.482453467
Iteration 915 lower bound -178.17306454
loss is Autograd FloatNode with value -114.362324882 and 1 tape(s)
loss is -129.016282534
Iteration 916 lower bound -166.650861584
loss is Autograd FloatNode with value -112.713824616 and 1 tape(s)
loss is -116.403624267
Iteration 917 lower bound -179.25162651
loss is Autograd FloatNode with value -106.755305209 and 1 tape(s)
loss is -104.905942472
Iteration 918 lower bound -190.742783338
loss is Autograd FloatNode with value -109.112484677 and 1 tape(s)
loss is -120.4302792
Iteration 919 lower bound -175.372822908
loss is Autograd FloatNode with value -115.179585273 and 1 tape(s)
loss is -121.185646246
Iteration 920 lower bound -174.794609114
loss is Autograd FloatNode with value -107.793803827 and 1 tape(s)
loss is -110.683224047
Iteration 921 lower bound -185.481167115
loss is Autograd FloatNode with value -110.377841086 and 1 tape(s)
loss is -114.837702893
Iteration 922 lower bound -181.221627224
loss is Autograd FloatNode with value -149.387855348 and 1 tape(s)
loss is -110.805400937
Iteration 923 lower bound -185.040425562
loss is Autograd FloatNode with value -103.360079752 and 1 tape(s)
loss is -109.866871229
Iteration 924 lower bound -186.392184403
loss is Autograd FloatNode with value -116.938525503 and 1 tape(s)
loss is -118.32647973
Iteration 925 lower bound -178.394479978
loss is Autograd FloatNode with value -124.858307488 and 1 tape(s)
loss is -157.33380896
Iteration 926 lower bound -139.788847841
loss is Autograd FloatNode with value -206.963104164 and 1 tape(s)
loss is -209.580378984
Iteration 927 lower bound -87.7383970703
loss is Autograd FloatNode with value -253.150524922 and 1 tape(s)
loss is -256.869797546
Iteration 928 lower bound -39.8713224178
loss is Autograd FloatNode with value -176.369726055 and 1 tape(s)
loss is -126.771475582
Iteration 929 lower bound -168.901999116
loss is Autograd FloatNode with value -112.045930073 and 1 tape(s)
loss is -101.091664879
Iteration 930 lower bound -192.468947607
loss is Autograd FloatNode with value -104.511132296 and 1 tape(s)
loss is -104.122474351
Iteration 931 lower bound -187.598634317
loss is Autograd FloatNode with value -103.754511912 and 1 tape(s)
loss is -110.947441357
Iteration 932 lower bound -179.303270853
loss is Autograd FloatNode with value -109.481831925 and 1 tape(s)
loss is -103.07626199
Iteration 933 lower bound -185.965944141
loss is Autograd FloatNode with value -103.590662022 and 1 tape(s)
loss is -105.517934685
Iteration 934 lower bound -182.486845548
loss is Autograd FloatNode with value -108.04398479 and 1 tape(s)
loss is -111.272384066
Iteration 935 lower bound -176.03197559
loss is Autograd FloatNode with value -110.933529733 and 1 tape(s)
loss is -108.037240553
Iteration 936 lower bound -178.653904494
loss is Autograd FloatNode with value -106.380104503 and 1 tape(s)
loss is -101.490484377
Iteration 937 lower bound -184.698992039
loss is Autograd FloatNode with value -106.592654704 and 1 tape(s)
loss is -105.494308537
Iteration 938 lower bound -180.361335319
loss is Autograd FloatNode with value -111.66440604 and 1 tape(s)
loss is -98.1121847195
Iteration 939 lower bound -187.619062364
loss is Autograd FloatNode with value -111.394465382 and 1 tape(s)
loss is -101.123740169
Iteration 940 lower bound -184.516898112
loss is Autograd FloatNode with value -108.533639062 and 1 tape(s)
loss is -106.971230875
Iteration 941 lower bound -178.534775397
loss is Autograd FloatNode with value -100.463342331 and 1 tape(s)
loss is -102.659240502
Iteration 942 lower bound -182.733947297
loss is Autograd FloatNode with value -105.602703932 and 1 tape(s)
loss is -106.305879614
Iteration 943 lower bound -179.199559914
loss is Autograd FloatNode with value -105.390373052 and 1 tape(s)
loss is -106.471555344
Iteration 944 lower bound -179.23445373
loss is Autograd FloatNode with value -112.370968452 and 1 tape(s)
loss is -105.294915794
Iteration 945 lower bound -180.736845864
loss is Autograd FloatNode with value -122.491001387 and 1 tape(s)
loss is -108.661416865
Iteration 946 lower bound -177.650829342
loss is Autograd FloatNode with value -106.833969363 and 1 tape(s)
loss is -131.185657637
Iteration 947 lower bound -155.128699301
loss is Autograd FloatNode with value -110.108411017 and 1 tape(s)
loss is -106.622547904
Iteration 948 lower bound -179.722021771
loss is Autograd FloatNode with value -102.950929178 and 1 tape(s)
loss is -114.462708794
Iteration 949 lower bound -171.958025295
loss is Autograd FloatNode with value -106.686395185 and 1 tape(s)
loss is -107.631063387
Iteration 950 lower bound -178.986300223
loss is Autograd FloatNode with value -104.848549491 and 1 tape(s)
loss is -111.037585854
Iteration 951 lower bound -175.838196488
loss is Autograd FloatNode with value -123.618532617 and 1 tape(s)
loss is -108.497176039
Iteration 952 lower bound -178.739474854
loss is Autograd FloatNode with value -111.098915914 and 1 tape(s)
loss is -111.776093668
Iteration 953 lower bound -175.472765952
loss is Autograd FloatNode with value -111.418594251 and 1 tape(s)
loss is -102.736936556
Iteration 954 lower bound -184.448044884
loss is Autograd FloatNode with value -109.926569778 and 1 tape(s)
loss is -110.528554523
Iteration 955 lower bound -176.529085799
loss is Autograd FloatNode with value -107.787324729 and 1 tape(s)
loss is -116.013998153
Iteration 956 lower bound -170.87423669
loss is Autograd FloatNode with value -114.034725137 and 1 tape(s)
loss is -109.703035467
Iteration 957 lower bound -177.050370379
loss is Autograd FloatNode with value -100.111752176 and 1 tape(s)
loss is -100.244134527
Iteration 958 lower bound -186.34235156
loss is Autograd FloatNode with value -99.2811675864 and 1 tape(s)
loss is -103.233557003
Iteration 959 lower bound -183.405302318
loss is Autograd FloatNode with value -108.442196493 and 1 tape(s)
loss is -108.896986883
Iteration 960 lower bound -177.974984348
loss is Autograd FloatNode with value -105.559088222 and 1 tape(s)
loss is -107.642332553
Iteration 961 lower bound -179.54604221
loss is Autograd FloatNode with value -103.657158662 and 1 tape(s)
loss is -106.736429891
Iteration 962 lower bound -180.881503608
loss is Autograd FloatNode with value -103.350081293 and 1 tape(s)
loss is -112.061701673
Iteration 963 lower bound -176.006856282
loss is Autograd FloatNode with value -104.989010284 and 1 tape(s)
loss is -105.406449307
Iteration 964 lower bound -183.272975723
loss is Autograd FloatNode with value -111.181635725 and 1 tape(s)
loss is -108.301148401
Iteration 965 lower bound -180.985069887
loss is Autograd FloatNode with value -106.836264765 and 1 tape(s)
loss is -106.497675257
Iteration 966 lower bound -183.330389155
loss is Autograd FloatNode with value -112.247003015 and 1 tape(s)
loss is -110.443188186
Iteration 967 lower bound -179.902473941
loss is Autograd FloatNode with value -106.619482324 and 1 tape(s)
loss is -106.707558254
Iteration 968 lower bound -184.052798324
loss is Autograd FloatNode with value -112.522746724 and 1 tape(s)
loss is -106.175809693
Iteration 969 lower bound -185.080599395
loss is Autograd FloatNode with value -109.37998102 and 1 tape(s)
loss is -116.022784749
Iteration 970 lower bound -175.637106047
loss is Autograd FloatNode with value -106.99384829 and 1 tape(s)
loss is -100.654674219
Iteration 971 lower bound -191.418490606
loss is Autograd FloatNode with value -103.248772994 and 1 tape(s)
loss is -105.383591342
Iteration 972 lower bound -187.128824509
loss is Autograd FloatNode with value -110.788610652 and 1 tape(s)
loss is -103.655187263
Iteration 973 lower bound -189.302823102
loss is Autograd FloatNode with value -108.551378934 and 1 tape(s)
loss is -112.012726804
Iteration 974 lower bound -181.302308974
loss is Autograd FloatNode with value -203.750039282 and 1 tape(s)
loss is -110.881996656
Iteration 975 lower bound -182.752352014
loss is Autograd FloatNode with value -113.253389927 and 1 tape(s)
loss is -104.801485615
Iteration 976 lower bound -187.649809862
loss is Autograd FloatNode with value -118.883560103 and 1 tape(s)
loss is -106.236526463
Iteration 977 lower bound -185.166017481
loss is Autograd FloatNode with value -123.836605752 and 1 tape(s)
loss is -108.442477267
Iteration 978 lower bound -181.984790592
loss is Autograd FloatNode with value -119.00026032 and 1 tape(s)
loss is -107.093512548
Iteration 979 lower bound -182.432732992
loss is Autograd FloatNode with value -124.634162456 and 1 tape(s)
loss is -114.039422525
Iteration 980 lower bound -174.550060509
loss is Autograd FloatNode with value -120.633185108 and 1 tape(s)
loss is -123.143223671
Iteration 981 lower bound -164.606886127
loss is Autograd FloatNode with value -115.149686283 and 1 tape(s)
loss is -118.740445648
Iteration 982 lower bound -168.121238595
loss is Autograd FloatNode with value -111.800908577 and 1 tape(s)
loss is -110.872861215
Iteration 983 lower bound -175.253974612
loss is Autograd FloatNode with value -117.114331398 and 1 tape(s)
loss is -111.469352371
Iteration 984 lower bound -174.064565051
loss is Autograd FloatNode with value -115.92148198 and 1 tape(s)
loss is -106.77353391
Iteration 985 lower bound -178.13486525
loss is Autograd FloatNode with value -118.384504574 and 1 tape(s)
loss is -113.468250736
Iteration 986 lower bound -170.942889801
loss is Autograd FloatNode with value -105.957823858 and 1 tape(s)
loss is -116.198585316
Iteration 987 lower bound -167.843702635
loss is Autograd FloatNode with value -117.59424878 and 1 tape(s)
loss is -109.021413757
Iteration 988 lower bound -174.855414771
loss is Autograd FloatNode with value -121.683004914 and 1 tape(s)
loss is -111.955375062
Iteration 989 lower bound -171.767982485
loss is Autograd FloatNode with value -111.528978892 and 1 tape(s)
loss is -109.205394582
Iteration 990 lower bound -174.418256315
loss is Autograd FloatNode with value -158.682740427 and 1 tape(s)
loss is -110.10353579
Iteration 991 lower bound -173.55804594
loss is Autograd FloatNode with value -113.989145179 and 1 tape(s)
loss is -110.362227753
Iteration 992 lower bound -172.907711354
loss is Autograd FloatNode with value -108.800328993 and 1 tape(s)
loss is -106.593333603
Iteration 993 lower bound -175.907332073
loss is Autograd FloatNode with value -110.43279926 and 1 tape(s)
loss is -104.906716892
Iteration 994 lower bound -177.030910567
loss is Autograd FloatNode with value -105.705782698 and 1 tape(s)
loss is -106.850055313
Iteration 995 lower bound -174.717567044
loss is Autograd FloatNode with value -108.267749088 and 1 tape(s)
loss is -105.423591762
Iteration 996 lower bound -175.94745477
loss is Autograd FloatNode with value -107.998665341 and 1 tape(s)
loss is -109.639735869
Iteration 997 lower bound -171.546970029
loss is Autograd FloatNode with value -101.402090588 and 1 tape(s)
loss is -135.071618354
Iteration 998 lower bound -146.058957853
loss is Autograd FloatNode with value -108.958255265 and 1 tape(s)
loss is -105.301444609
Iteration 999 lower bound -175.910846054
